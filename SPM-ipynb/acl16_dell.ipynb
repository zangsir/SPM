{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load classification/ts_classifier.py\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "class ts_classifier(object):\n",
    "\t\n",
    "\tdef __init__(self,plotter=False):\n",
    "\t\t'''\n",
    "\t\tpreds is a list of predictions that will be made.\n",
    "\t\tplotter indicates whether to plot each nearest neighbor as it is found.\n",
    "\t\t'''\n",
    "\t\tself.preds=[]\n",
    "\t\tself.plotter=plotter\n",
    "\t\n",
    "\tdef predict(self,train,test,w,progress=False):\n",
    "\t\t'''\n",
    "\t\t1-nearest neighbor classification algorithm using LB_Keogh lower \n",
    "\t\tbound as similarity measure. Option to use DTW distance instead\n",
    "\t\tbut is much slower.\n",
    "\t\t'''\n",
    "\t\tfor ind,i in enumerate(test):\n",
    "\t\t\tif progress:\n",
    "\t\t\t\tprint str(ind+1)+' points classified'\n",
    "\t\t\tmin_dist=float('inf')\n",
    "\t\t\tclosest_seq=[]\n",
    "\t\n",
    "\t\t\tfor j in train:\n",
    "\t\t\t\tif self.LB_Keogh(i,j[:-1],5)<min_dist:\n",
    "\t\t\t\t\tdist=self.DTWDistance(i,j[:-1],w)\n",
    "\t\t\t\t\tif dist<min_dist:\n",
    "\t\t\t\t\t\tmin_dist=dist\n",
    "\t\t\t\t\t\tclosest_seq=j\n",
    "\t\t\tself.preds.append(closest_seq[-1])\n",
    "\t\t\t\n",
    "\t\t\tif self.plotter: \n",
    "\t\t\t\tplt.plot(i)\n",
    "\t\t\t\tplt.plot(closest_seq[:-1])\n",
    "\t\t\t\tplt.legend(['Test Series','Nearest Neighbor in Training Set'])\n",
    "\t\t\t\tplt.title('Nearest Neighbor in Training Set - Prediction ='+str(closest_seq[-1]))\n",
    "\t\t\t\tplt.show()\n",
    "\t    \n",
    "\t    \n",
    "\tdef performance(self,true_results):\n",
    "\t\t'''\n",
    "\t\tIf the actual test set labels are known, can determine classification\n",
    "\t\taccuracy.\n",
    "\t\t'''\n",
    "\t\treturn classification_report(true_results,self.preds)\n",
    "\t\n",
    "\tdef get_preds(self):\n",
    "\t\treturn self.preds\n",
    "\t\n",
    "\t\n",
    "\tdef DTWDistance(self,s1,s2,w=None):\n",
    "\t\t'''\n",
    "\t\tCalculates dynamic time warping Euclidean distance between two\n",
    "\t\tsequences. Option to enforce locality constraint for window w.\n",
    "\t\t'''\n",
    "\t\tDTW={}\n",
    "    \n",
    "\t\tif w:\n",
    "\t\t\tw = max(w, abs(len(s1)-len(s2)))\n",
    "    \n",
    "\t\t\tfor i in range(-1,len(s1)):\n",
    "\t\t\t\tfor j in range(-1,len(s2)):\n",
    "\t\t\t\t\tDTW[(i, j)] = float('inf')\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t    for i in range(len(s1)):\n",
    "\t\t        DTW[(i, -1)] = float('inf')\n",
    "\t\t    for i in range(len(s2)):\n",
    "\t\t        DTW[(-1, i)] = float('inf')\n",
    "\t\t\n",
    "\t\tDTW[(-1, -1)] = 0\n",
    "\t\n",
    "\t\tfor i in range(len(s1)):\n",
    "\t\t\tif w:\n",
    "\t\t\t\tfor j in range(max(0, i-w), min(len(s2), i+w)):\n",
    "\t\t\t\t\tdist= (s1[i]-s2[j])**2\n",
    "\t\t\t\t\tDTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor j in range(len(s2)):\n",
    "\t\t\t\t\tdist= (s1[i]-s2[j])**2\n",
    "\t\t\t\t\tDTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\t\t\t\n",
    "\t\treturn np.sqrt(DTW[len(s1)-1, len(s2)-1])\n",
    "\t   \n",
    "\tdef LB_Keogh(self,s1,s2,r):\n",
    "\t\t'''\n",
    "\t\tCalculates LB_Keough lower bound to dynamic time warping. Linear\n",
    "\t\tcomplexity compared to quadratic complexity of dtw.\n",
    "\t\t'''\n",
    "\t\tLB_sum=0\n",
    "\t\tfor ind,i in enumerate(s1):\n",
    "\t        \n",
    "\t\t\tlower_bound=min(s2[(ind-r if ind-r>=0 else 0):(ind+r)])\n",
    "\t\t\tupper_bound=max(s2[(ind-r if ind-r>=0 else 0):(ind+r)])\n",
    "\t        \n",
    "\t\t\tif i>upper_bound:\n",
    "\t\t\t\tLB_sum=LB_sum+(i-upper_bound)**2\n",
    "\t\t\telif i<lower_bound:\n",
    "\t\t\t\tLB_sum=LB_sum+(i-lower_bound)**2\n",
    "\t    \n",
    "\t\treturn np.sqrt(LB_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAACL16-tsclust.ipynb                image2.pdf\r\n",
      "README.md                            image3.pdf\r\n",
      "acl16.ipynb                          imagetot.pdf\r\n",
      "\u001b[1m\u001b[34mclassification\u001b[m\u001b[m/                      saxpy.py\r\n",
      "\u001b[1m\u001b[34mclustering\u001b[m\u001b[m/                          saxpy.pyc\r\n",
      "\u001b[1m\u001b[34mdatasets\u001b[m\u001b[m/                            time-series-Clustering-shuo15.ipynb\r\n",
      "dendrogram.png                       \u001b[1m\u001b[34mtoneData\u001b[m\u001b[m/\r\n",
      "image1.pdf                           \u001b[1m\u001b[34mtoneSub\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clas=ts_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non-OOP demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "def DTWDistance(s1, s2,w):\n",
    "    DTW={}\n",
    "    \n",
    "    w = max(w, abs(len(s1)-len(s2)))\n",
    "    \n",
    "    for i in range(-1,len(s1)):\n",
    "        for j in range(-1,len(s2)):\n",
    "            DTW[(i, j)] = float('inf')\n",
    "    DTW[(-1, -1)] = 0\n",
    "  \n",
    "    for i in range(len(s1)):\n",
    "        for j in range(max(0, i-w), min(len(s2), i+w)):\n",
    "            dist= (s1[i]-s2[j])**2\n",
    "            DTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\t\t\n",
    "    return sqrt(DTW[len(s1)-1, len(s2)-1])\n",
    "\n",
    "\n",
    "def LB_Keogh(s1,s2,r):\n",
    "    LB_sum=0\n",
    "    for ind,i in enumerate(s1):\n",
    "        \n",
    "        lower_bound=min(s2[(ind-r if ind-r>=0 else 0):(ind+r)])\n",
    "        upper_bound=max(s2[(ind-r if ind-r>=0 else 0):(ind+r)])\n",
    "        \n",
    "        if i>upper_bound:\n",
    "            LB_sum=LB_sum+(i-upper_bound)**2\n",
    "        elif i<lower_bound:\n",
    "            LB_sum=LB_sum+(i-lower_bound)**2\n",
    "    \n",
    "    return sqrt(LB_sum)\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "def euclid_dist(t1,t2):\n",
    "    return sqrt(sum((t1-t2)**2))\n",
    "\n",
    "\n",
    "#see tutorial\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#knn with DTW using LB-Keogh\n",
    "def knn(train,test,w):\n",
    "    preds=[]\n",
    "    #index, line value\n",
    "    for ind,i in enumerate(test):\n",
    "        min_dist=float('inf')\n",
    "        closest_seq=[]\n",
    "        #print ind\n",
    "        for j in train:\n",
    "            if LB_Keogh(i[:-1],j[:-1],5)<min_dist:\n",
    "                dist=DTWDistance(i[:-1],j[:-1],w)\n",
    "                if dist<min_dist:\n",
    "                    min_dist=dist\n",
    "                    closest_seq=j\n",
    "        preds.append(closest_seq[-1])\n",
    "    prec = precision_score(test[:,-1],preds, average='macro')\n",
    "    recall= recall_score(test[:,-1],preds, average='macro')\n",
    "    f1=f1_score(test[:,-1],preds, average='macro')\n",
    "\n",
    "    return (prec,recall,f1)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "#knn with Euclidean dist\n",
    "def knn_euclid(train,test):\n",
    "    preds=[]\n",
    "    #index, line value\n",
    "    for ind,i in enumerate(test):\n",
    "        min_dist=float('inf')\n",
    "        closest_seq=[]\n",
    "        #print ind\n",
    "        for j in train:\n",
    "            dist=euclid_dist(i[:-1],j[:-1])\n",
    "            if dist<min_dist:\n",
    "                min_dist=dist\n",
    "                closest_seq=j\n",
    "        preds.append(closest_seq[-1])\n",
    "    prec = precision_score(test[:,-1],preds, average='macro')\n",
    "    recall= recall_score(test[:,-1],preds, average='macro')\n",
    "    f1=f1_score(test[:,-1],preds, average='macro')\n",
    "\n",
    "    return (prec,recall,f1)\n",
    "#classification_report(test[:,-1],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = np.genfromtxt('datasets/train.csv', delimiter='\\t')\n",
    "test = np.genfromtxt('datasets/test.csv', delimiter='\\t')\n",
    "s = knn_euclid(train,test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89295320453420646, 0.87999999999999989, 0.86567390383305109)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# knn on our tone data - euclidean and dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_data(data,test_size):\n",
    "    test_ind = random.sample(range(len(data)),test_size)\n",
    "    whole_ind = range(len(data))\n",
    "    train_ind = [x for x in whole_ind if x not in test_ind]\n",
    "    test = np.array([data[x] for x in test_ind])\n",
    "    train = np.array([data[x] for x in train_ind])\n",
    "    return test, train\n",
    "\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath=\"toneData/\"\n",
    "allfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "onlyfiles=[f for f in allfiles if f.endswith('csv')]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toneData/allxudn-3speakers-sorttone.csv\n",
      "scores: (0.9278979954216906, 0.93482122715993687, 0.92970715055695297)\n",
      "total score: (0.9278979954216906, 0.93482122715993687, 0.92970715055695297)\n",
      "scores: (0.94390980776409106, 0.94393996960486326, 0.94378333600631481)\n",
      "total score: (1.8718078031857817, 1.8787611967648001, 1.8734904865632678)\n",
      "scores: (0.91754646002357676, 0.92192397751374888, 0.91911243618020022)\n",
      "total score: (2.7893542632093586, 2.800685174278549, 2.7926029227434679)\n",
      "scores: (0.95533626707638863, 0.95577321494635592, 0.95532303243878203)\n",
      "total score: (3.7446905302857472, 3.756458389224905, 3.7479259551822501)\n",
      "scores: (0.92969907407407404, 0.92966494555164148, 0.92896712812851001)\n",
      "total score: (4.6743896043598214, 4.6861233347765463, 4.6768930833107598)\n",
      "scores: (0.93599087433715633, 0.93936778065523907, 0.93369275078666081)\n",
      "total score: (5.6103804786969782, 5.6254911154317853, 5.6105858340974208)\n",
      "scores: (0.93876968020643969, 0.9382868937048503, 0.93828370046348619)\n",
      "total score: (6.5491501589034176, 6.5637780091366356, 6.5488695345609074)\n",
      "scores: (0.92294722354912717, 0.92319785696031542, 0.92197499823106432)\n",
      "total score: (7.472097382452545, 7.4869758660969508, 7.4708445327919719)\n",
      "scores: (0.93009488005610608, 0.93046150811912431, 0.92983752484659932)\n",
      "total score: (8.4021922625086507, 8.4174373742160746, 8.400682057638571)\n",
      "scores: (0.93088178667693489, 0.93066069824156072, 0.93072239771047671)\n",
      "total score: (9.3330740491855853, 9.3480980724576348, 9.3314044553490483)\n",
      "[0.93330740491855857, 0.93480980724576346, 0.93314044553490483]\n",
      "=======================================\n",
      "toneData/concatSynth1-sorttone.csv\n",
      "scores: (0.80095443684153356, 0.7883211990702762, 0.79208371526038779)\n",
      "total score: (0.80095443684153356, 0.7883211990702762, 0.79208371526038779)\n",
      "scores: (0.82300066165273544, 0.81873172514619885, 0.82010062259422878)\n",
      "total score: (1.623955098494269, 1.6070529242164751, 1.6121843378546166)\n",
      "scores: (0.8066626915800712, 0.80813480300668239, 0.80600825346917793)\n",
      "total score: (2.43061779007434, 2.4151877272231577, 2.4181925913237947)\n",
      "scores: (0.81728309033733559, 0.81613022567517579, 0.81374057396577471)\n",
      "total score: (3.2479008804116756, 3.2313179528983333, 3.2319331652895693)\n",
      "scores: (0.75742998868794065, 0.7557402355821804, 0.75532171278086502)\n",
      "total score: (4.0053308690996161, 3.9870581884805136, 3.9872548780704342)\n",
      "scores: (0.84810479375696768, 0.8497152560083594, 0.84645436776744232)\n",
      "total score: (4.853435662856584, 4.8367734444888733, 4.833709245837877)\n",
      "scores: (0.80334801967866487, 0.79731201127477724, 0.79770115344238679)\n",
      "total score: (5.6567836825352487, 5.6340854557636506, 5.6314103992802638)\n",
      "scores: (0.82654826675359416, 0.82757648953301133, 0.82603038718608546)\n",
      "total score: (6.4833319492888428, 6.4616619452966617, 6.457440786466349)\n",
      "scores: (0.86656618467210933, 0.86499928642785784, 0.86349848685779773)\n",
      "total score: (7.3498981339609522, 7.3266612317245192, 7.3209392733241465)\n",
      "scores: (0.80664183330521277, 0.80691173905459623, 0.80664682539682531)\n",
      "total score: (8.1565399672661645, 8.1335729707791149, 8.1275860987209718)\n",
      "[0.81565399672661643, 0.81335729707791149, 0.81275860987209714]\n",
      "=======================================\n",
      "toneData/poly-normed-bark-30p-sorttone.csv\n",
      "scores: (0.74513569303762206, 0.74238031914893621, 0.74201082229359017)\n",
      "total score: (0.74513569303762206, 0.74238031914893621, 0.74201082229359017)\n",
      "scores: (0.70370092300383458, 0.70389829142488713, 0.70009896091044033)\n",
      "total score: (1.4488366160414565, 1.4462786105738235, 1.4421097832040304)\n",
      "scores: (0.78075888810171312, 0.79077035590911304, 0.78088238176977465)\n",
      "total score: (2.2295955041431696, 2.2370489664829365, 2.2229921649738049)\n",
      "scores: (0.68876480582622701, 0.69311558116069394, 0.6906356002638866)\n",
      "total score: (2.9183603099693967, 2.9301645476436304, 2.9136277652376914)\n",
      "scores: (0.71605269213069489, 0.72314036210877641, 0.7169134971016039)\n",
      "total score: (3.6344130021000915, 3.6533049097524071, 3.6305412623392952)\n",
      "scores: (0.70157701762946734, 0.70287210512620346, 0.69714588538117939)\n",
      "total score: (4.3359900197295591, 4.356177014878611, 4.327687147720475)\n",
      "scores: (0.71874565118996947, 0.71539974162742015, 0.71370164227307087)\n",
      "total score: (5.0547356709195288, 5.0715767565060315, 5.0413887899935457)\n",
      "scores: (0.76894967777320722, 0.76850125393432411, 0.76717171717171717)\n",
      "total score: (5.8236853486927362, 5.8400780104403553, 5.8085605071652626)\n",
      "scores: (0.73643465835983901, 0.74671052631578949, 0.73711334828916819)\n",
      "total score: (6.5601200070525749, 6.5867885367561447, 6.5456738554544307)\n",
      "scores: (0.74901180631403752, 0.75073653198653201, 0.74281961751609693)\n",
      "total score: (7.3091318133666121, 7.3375250687426767, 7.2884934729705275)\n",
      "[0.73091318133666117, 0.73375250687426763, 0.72884934729705275]\n",
      "=======================================\n",
      "toneData/row-yixu-hertz-sorttone.csv\n",
      "scores: (0.94825895875591615, 0.94944761668321753, 0.9472713726198686)\n",
      "total score: (0.94825895875591615, 0.94944761668321753, 0.9472713726198686)\n",
      "scores: (0.92582417582417587, 0.92482088989441935, 0.9251851175862198)\n",
      "total score: (1.8740831345800921, 1.874268506577637, 1.8724564902060883)\n",
      "scores: (0.96725670163170163, 0.97158101045296164, 0.96877364981080138)\n",
      "total score: (2.8413398362117936, 2.8458495170305986, 2.8412301400168896)\n",
      "scores: (0.94675438596491235, 0.95025613714749446, 0.9482837069253931)\n",
      "total score: (3.788094222176706, 3.7961056541780929, 3.7895138469422829)\n",
      "scores: (0.96542666373174857, 0.9636877989576641, 0.96440361371554029)\n",
      "total score: (4.7535208859084541, 4.7597934531357566, 4.7539174606578234)\n",
      "scores: (0.94582768744354107, 0.94726135446474435, 0.94598545344327944)\n",
      "total score: (5.6993485733519949, 5.7070548076005014, 5.6999029141011031)\n",
      "scores: (0.93983814471919469, 0.94148629148629148, 0.94047619047619047)\n",
      "total score: (6.6391867180711897, 6.6485410990867928, 6.6403791045772937)\n",
      "scores: (0.96686953911825524, 0.96453313193265311, 0.96555645179359628)\n",
      "total score: (7.6060562571894446, 7.6130742310194464, 7.6059355563708904)\n",
      "scores: (0.94434212008194762, 0.94024580986240647, 0.94112422531875417)\n",
      "total score: (8.5503983772713923, 8.5533200408818537, 8.5470597816896436)\n",
      "scores: (0.94322505184144234, 0.93972746331236889, 0.94031573146617398)\n",
      "total score: (9.4936234291128354, 9.4930475041942231, 9.4873755131558184)\n",
      "[0.94936234291128352, 0.94930475041942231, 0.9487375513155818]\n",
      "=======================================\n",
      "toneData/row-yixunorm-bk-sorttone.csv\n",
      "scores: (0.88701023391812861, 0.8847063102382251, 0.88499363724890145)\n",
      "total score: (0.88701023391812861, 0.8847063102382251, 0.88499363724890145)\n",
      "scores: (0.94092242503259449, 0.93743816012806391, 0.93881884787415371)\n",
      "total score: (1.827932658950723, 1.822144470366289, 1.8238124851230553)\n",
      "scores: (0.91438437723267452, 0.91445272479755235, 0.91429677325248226)\n",
      "total score: (2.7423170361833975, 2.7365971951638413, 2.7381092583755375)\n",
      "scores: (0.92813780879583474, 0.92923460750245035, 0.92836746586746588)\n",
      "total score: (3.6704548449792322, 3.6658318026662915, 3.6664767242430036)\n",
      "scores: (0.92499999999999993, 0.92417342024900162, 0.92442546582900764)\n",
      "total score: (4.5954548449792325, 4.590005222915293, 4.5909021900720113)\n",
      "scores: (0.90355906845216072, 0.90696141132509345, 0.9047972976562334)\n",
      "total score: (5.4990139134313933, 5.4969666342403869, 5.4956994877282446)\n",
      "scores: (0.92143540669856461, 0.9193498817966903, 0.91995691995691997)\n",
      "total score: (6.4204493201299577, 6.4163165160370772, 6.4156564076851641)\n",
      "scores: (0.95746880570409987, 0.95705128205128209, 0.95660510181826997)\n",
      "total score: (7.3779181258340572, 7.373367798088359, 7.3722615095034341)\n",
      "scores: (0.93277608915906796, 0.92765551528849399, 0.92830921649935105)\n",
      "total score: (8.3106942149931253, 8.3010233133768523, 8.3005707260027854)\n",
      "scores: (0.93417190775681336, 0.93838729776250696, 0.93517139990674791)\n",
      "total score: (9.2448661227499382, 9.239410611139359, 9.2357421259095336)\n",
      "[0.92448661227499385, 0.92394106111393592, 0.9235742125909534]\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "num_iter=10\n",
    "\n",
    "def addv(a,b):\n",
    "    return tuple(map(sum, zip(a,b)))\n",
    "    \n",
    "\n",
    "#analysis:kmeans with euclidean distance with 5 types of representation feature files\n",
    "\n",
    "score_dict={}\n",
    "for file in onlyfiles:\n",
    "    total_score=(0,0,0)\n",
    "    fileName=mypath+file\n",
    "    print fileName\n",
    "    data = np.genfromtxt(fileName, delimiter=',')\n",
    "    for i in range(num_iter):\n",
    "        test,train=split_data(data,200)\n",
    "        scores = knn_euclid(train,test)\n",
    "        print \"scores:\",scores\n",
    "        total_score=addv(total_score,scores)\n",
    "        print \"total score:\",total_score\n",
    "    ave_score=[x/num_iter for x in total_score]\n",
    "    print ave_score\n",
    "    score_dict[file]=ave_score\n",
    "    print \"=======================================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.94936234291128352, 0.94930475041942231, 0.9487375513155818]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dict['row-yixu-hertz-sorttone.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAX classificaiton knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros(shape=(5,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[3,1]=1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ],\n",
       "       [ 0. ,  0. ],\n",
       "       [ 0. ,  0. ],\n",
       "       [ 0. ,  1.2],\n",
       "       [ 0. ,  0. ]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from saxpy import SAX\n",
    "def min_dist_sax(t1String,t2String,word,alpha,eps=0.000001):\n",
    "    s=SAX(word,alpha,eps)\n",
    "    return s.compare_strings(t1String,t2String)\n",
    "\n",
    "\n",
    "def convert_sax(ts,word,alpha,eps=0.000001):\n",
    "    s=SAX(word,alpha,eps)\n",
    "    (t1String, t1Indices) = s.to_letter_rep(ts)\n",
    "    return t1String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sdgh1'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='sdgh'\n",
    "a+'1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert all data to sax\n",
    "def data_sax(data,word,alpha):\n",
    "    data_sax=[]\n",
    "    for ts in data:\n",
    "        ts_string=convert_sax(ts[:-1],word,alpha)\n",
    "        ts_string+=str(int(ts[-1]))\n",
    "        data_sax.append(ts_string)\n",
    "    return data_sax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=data_sax(data,word,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aabcddd1', 'aabcddc1', 'abccddd1', 'aabcddc1', 'aabbcdd1', 'aabcddd1', 'aacddcb1', 'aabcddd1', 'aacddcc1', 'aabcddd1', 'aaabcdd1', 'aabcddd1', 'aabccdd1', 'aabcddd1', 'aabcddd1', 'aabbcdd1', 'adddbba1', 'aabccdd1', 'acdddba1', 'aabbcdd1', 'aabccdd1', 'aacddcc1', 'bbcddba1', 'aabcddc1', 'aabcddd1', 'aabcddd1', 'baaacdd1', 'dbbcbaa1', 'aabcddd1', 'aabcddd1', 'dcbbabc1', 'aabcddd1', 'bbbcdda1', 'ccddbaa1', 'aabcddd1', 'aacdddc1', 'aabccdc1', 'aaabddd1', 'abccccd1', 'aabcddd1', 'aacddcc1', 'dbabdca1', 'aabcddd1', 'aabcddd1', 'aabcddd1', 'aabcddd1', 'dddbaaa1', 'aaccddd1', 'aaabddd1', 'aabcddc1', 'aabcddd1', 'aabcddd1', 'aabcddd1', 'aabcddd1', 'abbbcdd1', 'aabcddd1', 'aabcddd1', 'aabcddd1', 'aabcddd1', 'aabcddd1', 'aabcddd1', 'aabcddd1', 'aabcddd1', 'abddccc1', 'aabcddd1', 'abbbcdd1', 'aabcddd1', 'aabcddd1', 'aabbcdd1', 'aabcddd1', 'aabcddd1', 'aabcddd1', 'acddcba1', 'bbddcaa1', 'abddcbb1', 'abbccdd1', 'aacddca1', 'dccdcaa1', 'abcddcc1', 'aabcddd1', 'aaacddd1', 'aacddcc1', 'abccbdd1', 'aabcdda1', 'abdddcb1', 'aabcddd1', 'aabcddd1', 'dcbbbaa1', 'aabcddd1', 'aabcddd1', 'acdcccc1', 'aabcddd1', 'aabbddd1', 'aabcddd1', 'abcddcc1', 'aabcddd1', 'abccdcb1', 'aaacddd1', 'aabddda1', 'aabcddd1']\n"
     ]
    }
   ],
   "source": [
    "print a[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.27248860e-02,  -5.98698290e-02,  -5.62488890e-02,\n",
       "        -5.17472450e-02,  -4.83555100e-02,  -4.37595120e-02,\n",
       "        -3.71938240e-02,  -2.98960330e-02,  -2.23343880e-02,\n",
       "        -1.44712130e-02,  -7.18623600e-03,  -2.55626000e-04,\n",
       "         6.09065600e-03,   1.12446530e-02,   1.56460630e-02,\n",
       "         1.87748920e-02,   2.13038610e-02,   2.34514510e-02,\n",
       "         2.51449490e-02,   2.68146640e-02,   2.84535490e-02,\n",
       "         2.98095120e-02,   3.09127900e-02,   3.17744060e-02,\n",
       "         3.17543630e-02,   3.12349470e-02,   3.01104630e-02,\n",
       "         2.75978310e-02,   2.42377950e-02,   1.96863470e-02,\n",
       "         1.00000000e+00])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n"
     ]
    }
   ],
   "source": [
    "print len(all_sax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4895636945092345"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_dist_sax(all_sax[2][0][:-1],all_sax[2][988][:-1],5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def dist_matrix_sax(tsdata,word,alpha):\n",
    "    size=len(tsdata)\n",
    "    dist_matrix=np.zeros(shape=(size,size))\n",
    "    for i in tsdata:\n",
    "        for j in tsdata:\n",
    "            dist=min_dist_sax(i[:-1],j[:-1],word,alpha)\n",
    "            dist_matrix[i,j]=dist\n",
    "    return dist_matrix\n",
    "            "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def dist_matrix_sax_tt(train,test,word,alpha):\n",
    "    \n",
    "    dist_matrix=np.zeros(shape=(len(train),len(test)))\n",
    "    for i in train:\n",
    "        for j in test:\n",
    "            dist=min_dist_sax(i[:-1],j[:-1],word,alpha)\n",
    "            dist_matrix[i,j]=dist\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_sax(train,test,word,alpha):\n",
    "    preds=[]\n",
    "    #index, line value\n",
    "    for ind,i in enumerate(test):\n",
    "        min_dist=float('inf')\n",
    "        closest_seq=[]\n",
    "        #HeRE i and j are just two strings 'abcd1' and 'abcc2' e.g.\n",
    "        for j in train:\n",
    "            dist=min_dist_sax(i[:-1],j[:-1],word,alpha)\n",
    "            if dist<min_dist:\n",
    "                min_dist=dist\n",
    "                closest_seq=j\n",
    "                #print 'j',j\n",
    "        preds.append(closest_seq[-1])\n",
    "    #print 'preds',preds\n",
    "    gtruth=[x[-1] for x in test]\n",
    "    prec = precision_score(gtruth,preds, average='macro')\n",
    "    recall= recall_score(gtruth,preds, average='macro')\n",
    "    f1=f1_score(gtruth,preds, average='macro')\n",
    "\n",
    "    return (prec,recall,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert all data to sax\n",
    "def data_sax(data,word,alpha):\n",
    "    data_sax=[]\n",
    "    for ts in data:\n",
    "        ts_string=convert_sax(ts[:-1],word,alpha)\n",
    "        ts_string+=str(int(ts[-1]))\n",
    "        data_sax.append(ts_string)\n",
    "    return data_sax\n",
    "\n",
    "#try different parameter combinations for a data file (such as D1 data or bk data file)\n",
    "def generate_sax_data(data):\n",
    "    all_sax=[]\n",
    "    all_pars=[]\n",
    "    for word in range(8,15):\n",
    "        for alpha in range(3,7):\n",
    "            a=data_sax(data,word,alpha)\n",
    "            all_sax.append(a)\n",
    "            all_pars.append((word,alpha))\n",
    "    return all_sax,all_pars\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toneSub/row-yixunorm-bk-sorttone.csv\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath=\"toneSub/\"\n",
    "allfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "onlyfiles=[f for f in allfiles if f.endswith('csv')]\n",
    "all_data=[]\n",
    "for file in onlyfiles:\n",
    "    total_score=(0,0,0)\n",
    "    fileName=mypath+file\n",
    "    print fileName\n",
    "    data = np.genfromtxt(fileName, delimiter=',')\n",
    "    all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#there are several data files, stored in all_data. for each data file in all data, you can generate multiple sax files\n",
    "#by permutating the word and alpha values using the generate_sax_data() function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated file from 1 data file(s)\n",
      "sax parameters: (8, 3)\n",
      "scores: (0.056250000000000001, 0.25, 0.091836734693877542)\n",
      "scores: (0.056250000000000001, 0.25, 0.091836734693877542)\n",
      "total score: (0.056250000000000001, 0.25, 0.091836734693877542)\n",
      "[0.056250000000000001, 0.25, 0.091836734693877542]\n",
      "=======================================\n",
      "sax parameters: (8, 4)\n",
      "scores: (0.056250000000000001, 0.25, 0.091836734693877542)\n",
      "scores: (0.056250000000000001, 0.25, 0.091836734693877542)\n",
      "total score: (0.056250000000000001, 0.25, 0.091836734693877542)\n",
      "[0.056250000000000001, 0.25, 0.091836734693877542]\n",
      "=======================================\n",
      "sax parameters: (8, 5)\n",
      "scores: (0.22758037225042299, 0.26111111111111113, 0.11879251700680271)\n",
      "scores: (0.22758037225042299, 0.26111111111111113, 0.11879251700680271)\n",
      "total score: (0.22758037225042299, 0.26111111111111113, 0.11879251700680271)\n",
      "[0.22758037225042299, 0.26111111111111113, 0.11879251700680271]\n",
      "=======================================\n",
      "sax parameters: (8, 6)\n",
      "scores: (0.26984588543181154, 0.31206948188080263, 0.22427140255009109)\n",
      "scores: (0.26984588543181154, 0.31206948188080263, 0.22427140255009109)\n",
      "total score: (0.26984588543181154, 0.31206948188080263, 0.22427140255009109)\n",
      "[0.26984588543181154, 0.31206948188080263, 0.22427140255009109]\n",
      "=======================================\n",
      "sax parameters: (9, 3)\n",
      "scores: (0.068750000000000006, 0.25, 0.10784313725490198)\n",
      "scores: (0.068750000000000006, 0.25, 0.10784313725490198)\n",
      "total score: (0.068750000000000006, 0.25, 0.10784313725490198)\n",
      "[0.068750000000000006, 0.25, 0.10784313725490198]\n",
      "=======================================\n",
      "sax parameters: (9, 4)\n",
      "scores: (0.071249999999999994, 0.25, 0.11089494163424124)\n",
      "scores: (0.071249999999999994, 0.25, 0.11089494163424124)\n",
      "total score: (0.071249999999999994, 0.25, 0.11089494163424124)\n",
      "[0.071249999999999994, 0.25, 0.11089494163424124]\n",
      "=======================================\n",
      "sax parameters: (9, 5)\n",
      "scores: (0.28423390081421168, 0.28061224489795916, 0.16288316946211681)\n",
      "scores: (0.28423390081421168, 0.28061224489795916, 0.16288316946211681)\n",
      "total score: (0.28423390081421168, 0.28061224489795916, 0.16288316946211681)\n",
      "[0.28423390081421168, 0.28061224489795916, 0.16288316946211681]\n",
      "=======================================\n",
      "sax parameters: (9, 6)\n"
     ]
    }
   ],
   "source": [
    "num_iter=1\n",
    "score_dict_sax={}\n",
    "for data_file in all_data:\n",
    "    all_sax,all_pars=generate_sax_data(data_file)\n",
    "    print 'generated file from ' + str(len(all_data)) + ' data file(s)'\n",
    "    for i in range(len(all_sax)):\n",
    "        data=all_sax[i]\n",
    "        data_pars=all_pars[i]\n",
    "        total_score=(0,0,0)\n",
    "        print \"sax parameters:\",data_pars\n",
    "        #fileName=mypath+file\n",
    "        #print fileName\n",
    "        #data = np.genfromtxt(fileName, delimiter=',')\n",
    "        for i in range(num_iter):\n",
    "            best_so_far=(0,0,0)\n",
    "            test,train=split_data(data,200)\n",
    "            scores = knn_sax(train,test,data_pars[0],data_pars[1])\n",
    "            print 'scores:',scores\n",
    "            if scores[-1]>best_so_far[-1]:\n",
    "                best_so_far=scores                \n",
    "            print \"scores:\",best_so_far\n",
    "            total_score=addv(total_score,scores)\n",
    "            print \"total score:\",total_score\n",
    "        ave_score=[x/num_iter for x in total_score]\n",
    "        print ave_score\n",
    "        #score_dict_sax[file]=ave_score\n",
    "        print \"=======================================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
