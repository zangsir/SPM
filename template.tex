% File 'template.tex'

\documentclass[12pt]{report}







\usepackage{url}
\usepackage[numbers,sort]{natbib}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
%\usepackage{algorithmic}

% If there are any other \usepackage commands, put them here


%\usepackage{cite}
\usepackage{mathtools}

\usepackage{courier}
\usepackage{authblk} 
\usepackage[ margin=1.8in]{geometry}
\usepackage{listings}
\usepackage{color}
\usepackage{verbatim}
\usepackage{fancyhdr}
 \usepackage{hyperref}
 
 \usepackage{xcolor}

\usepackage[noend]{algpseudocode}
\usepackage{titlesec}









\newtheorem{theorem}{Theorem}[chapter]
\newenvironment{proof}[0]{\textit{Proof.}}{}
\newcommand{\qed}{\hfill $\Box$}

% To comment out multiple lines of text.
\long\def\comment#1{}




\newcommand{\figref}[1]{\figurename~\ref{#1}}
%----------------------------------------------------------------------------
%----------------------------------------------------------------------------
\renewcommand\Authfont{\small}
\renewcommand\Affilfont{\itshape\footnotesize}
%----------------------------------------------------------------------------
\renewcommand{\baselinestretch}{1.1}
 \renewcommand{\familydefault}{\rmdefault}
 
 
 
\usepackage{guthesis}




\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = red, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = blue %Colour of citations
}



\title{Mining Linguistic Tone Patterns Using Fundamental Frequency Time-Series Data}

\author{Shuo Zhang}

\previousdegree{B.S., M.A., M.S.}

\thisdegree{Doctor of Philosophy}  % or Doctor of Philosophy, etc.

\thisdiscipline{Linguistics}

\thesistype{Dissertation}     % or Dissertation

% defense or approval date, not today's date...
\thesisday{27}
\thesismonth{June}
\thesisyear{2017}

\professor{Amir \ Zeldes}
\secondprofessor{Elizabeth \ Zsiga}   % Only if you have 2 major professors!

\fulltitle{Full Title}

\indexwords{tone, time-series data mining, machine learning, prosody}

\dean{Timothy A.\ Barbari}

\memberi{George I.\ Wilson}
\memberii{First I.\ Last}
% Use \memberiii, \memberiv, \memberv for up to 3 more members if needed.

\begin{document}

\pagenumbering{roman}

\maketitle    % Creates title page, copyright page if any, and approval page.

\begin{abstract}
With the rapid advancement in computing powers, recent years have seen the availability of large scale corpora of speech audio data, and within it, fundamental frequency ($F_0$) time-series data of speech prosody. However, the wealth of this $F_0$ data is yet to be mined for knowledges that have many potential theoretical and practical applications in prosody-related tasks. Due to the nature of speech prosody data, Speech Prosody Mining (SPM) in a large prosody corpus faces classic time-series data mining challenges such as high dimensionality and high time complexity in distance computation (e.g., Dynamic Time Warping). In the meantime, the analysis and understanding of speech prosody subsequence patterns demands novel analytical methods that leverage a variety of algorithms and data structures in the computational linguistics and computer science toolkits, prompting us to develop creative solutions in order to extract meaning in large prosody databases.

In this dissertation, we conceptualize SPM in a time-series data mining framework by focusing on a specific task in speech prosody: the analysis and machine learning of Mandarin tones. The dissertation is divided into five parts, each further divided into several chapters. In Part I, we review the necessary background and previous works related to the production, perception, and modeling of Mandarin tones. In Part II, we report the data collection used in this work, and we describe the speech processing and data preprocessing steps in some detail. 

Part III and IV consists of the core segments of the thesis, where we develop novel methods for mining tone unigram and N-gram data. In Part III we investigate the use of time-series symbolic representation in improving the unsupervised learning of tones. In Part IV, we first show how to improve a state-of-the-art motif discovery algorithm to produce more meaningful rankings in the retrieval of previously unknown tone N-gram patterns. In the next chapter, we investigate the most exciting problem at the heart of tone modeling: how well can we predict the tone N-gram contour shape types in spontaneous speech by using a variety of features from various linguistic domains, such as syntax, morphology, discourse, and phonology? The results shed light on the nature of how these factors contribute to the realization of speech prosody in tone production from an information theoretic perspective. In the final part, we describe applications of these methods including generalization to other tone languages and developing softwares for the retrieval and analysis of speech prosody . In the end we discuss the extension of the current work to a general framework of corpus-based large-scale intonation analysis based on the research derived from this dissertation. 


\end{abstract}


%\chapter*{Dedication}

%The Dedication is optional.


\pseudochapter{Acknowledgments}

I would like to thank my advisor, Professor Amir Zeldes and Professor Elizabeth Zsiga, for being fantastic mentors over my PhD years. I'd also like to thank Dr Zeldes, Dr.Zsiga, and Dr. George Wilson for their guidance as my committee members. In my parallel careers in computational linguistics and music information retrieval, I awe a great deal to my advisor and colleagues at the Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain, especially Professor Xavier Serra, Sankalp Gulati, and Rafael Caro Repetto. Finally, I couldn't have finished my PhD without the support of my family and my life partner, Mia. 

%\pseudochapter{Preface}

%A preface is not an introduction, and most theses do not need them.


\tableofcontents

\listoffigures  % Optional - Omit this line if you don't want a list of figures.
\listoftables   % Optional - Omit this line if you don't want a list of tables.

\newpage

\pagenumbering{arabic}  % Ordinary pages have Arabic numerals.

\newpage
\part{Introduction and Background}

\newpage
\chapter{Introduction}



\section{Introduction}

% nature of this paper is data mining; focusing on tone task, extension to other languages, not other SP tasks for now; disclaimer
With the rapid advancement in computing powers, recent years have seen the availability of large-scale corpora of speech audio data, and within it, fundamental frequency ($F_0$) time-series data of speech prosody. However, the wealth of this $F_0$ data is yet to be mined for knowledge that has potential theoretical implications and practical applications in prosody-related tasks. Due to the nature of speech prosody data, Speech Prosody Mining (SPM) in a large prosody corpus faces classic time-series data mining challenges such as high dimensionality and high time complexity in distance computation (e.g., Dynamic Time Warping). In the meantime, the analysis and understanding of speech prosody subsequence patterns demand novel analytical methods that leverage a variety of algorithms and data structures in the computational linguistics and computer science toolkits. This prompts us to develop creative solutions in order to extract meaning in large prosody databases.


\section{Research Questions and Goals} \label{rq}
%explain the theme design and title change, research question change, framework

We purposefully limit the scope of the current project to tone tasks due to its importance, clearly defined evaluation, and the difficulty and complexity of this task in its own right. In the primary investigations of the dissertation, we will focus on Mandarin tones\footnote{In this dissertation, we will use Mandarin to refer to standard Mandarin Chinese spoken in mainland China, as opposed to Taiwanese Mandarin.} in order to develop methodologies best adapted to the data mining of tones. In the latter part of the dissertation, we extend the evaluation and application to other tone languages (Thai). Finally, we propose a general framework for working with SPM tasks. 

We conceptualize the dissertation within a (time-series) data mining research framework by addressing important issues and tasks in applying time-series data mining to the speech prosody domain. The principal research questions can be divided into two parts: 

(1) What is the most effective set of time-series data mining methodologies for the computation of speech prosody time-series data? This part is concerned with finding the optimal set of time-series representations, distance measures and other methods for computing time-series similarity in the speech prosody domain (as evaluated on supervised and unsupervised tone learning tasks).

(2) How can we develop methods for analyzing tone N-gram patterns in a large database? This research question can be further divided into three parts:

(2a) How can we develop methods to extract previously unknown patterns from a tone N-gram database? (from tone contour shapes to tone categories\footnote{In this part, we are first and foremost interested in finding and grouping similar tone N-gram contour shapes, regardless of their categorical memberships. This task is designed to complement the next task, where we start from a given tone N-gram category and explore its actual realized contour shape types in spontaneous speech, i.e., "from categories to contour shapes".})

(2b) Given a specific tone N-gram category, how can we develop methods for automatically characterizing the different types of tone contour shapes realized in spontaneous speech data? (from categories to contour shapes)

(2c) Given (2b), how well can we predict tone contour shape types realized in spontaneous speech, using features/predictors from relevant linguistic domains such as syntax, phonology, morphology, and discourse? What can we learn from this regarding the source of variability problem, as well as the psycholinguistic computational modeling of tone production and perception?

\section{Organization of the dissertation}
The dissertation is divided into five parts, each further divided into several chapters. In Part I, we review the necessary background and previous works related to the production, perception, and modeling of Mandarin tones. In Part II, we report the data collection used in this work, and we describe the speech processing and data preprocessing steps in detail. 

Part III and IV comprise the core segments of the thesis, where we develop novel methods for mining tone unigram and N-gram data to address the research questions proposed above. In Part III we investigate the use of time-series symbolic representation for improving the unsupervised learning of tones. In Part IV, we first show how to improve a state-of-the-art motif discovery algorithm to produce more meaningful rankings in the retrieval of previously unknown tone N-gram patterns. In the next chapter, we investigate the most exciting problem at the heart of tone modeling: how well can we predict the tone N-gram contour shape types in spontaneous speech by using a variety of features from various linguistic domains, such as syntax, morphology, discourse, and phonology? The results shed light on the nature of how these factors contribute to the realization of speech prosody in tone production from an information theoretic perspective. Moreover, in both chapters of Part IV, we will develop creative solutions to investigate these problems, drawing from methodologies in areas such as motif discovery, network (graph) analysis, machine learning, and information retrieval. In the final part, we describe applications of these methods developed in previous parts, including generalization to other tone languages and developing software for the retrieval and analysis of speech prosody . In the end we discuss the extension of the current work to a general framework of corpus-based large-scale intonation analysis based on the research derived from this dissertation. 



%main contribution of this thesis: data mining speech prosody, motif discovery in SPM, symbolic, etc. first to subject SP data to formal and comprehensive evaluation of tsdm



\section{Contribution of this thesis}
It is important to note that since its inception, we have always had a clear intent to carry out the dissertation project within a main methodology framework of \textit{data mining}, instead of tone recognition in the context of speech recognition\footnote{Despite this statement, we must recognize that the current study does in fact benefit from the domain knowledge of tone recognition, and its end result could be eventually useful for improving applications such as tone recognition.}. There are several reasons for this design. First, we note that previous works have invested numerous effort into the Mandarin tone recognition task, especially the supervised learning of tones for improving tone recognition accuracy. In contrast, the main goal of the current data mining framework is knowledge discovery in large speech prosody time-series data sets (with indirect applications in improving tone recognition). In other words, we are interested in the \textit{how} and \textit{why} in the understanding and analysis of tone N-gram patterns, instead of directly focusing on obtaining better tone recognition accuracy. Second, tone recognition research is best combined with segmental recognition that targets speech recognition as its final goal, as exemplified in \cite{Chang2000}. In contrast, the current project targets speech intonation pattern discovery by focusing on time-series data from only the $F_0$ dimension.  Third, whereas the machine learning and automatic recognition of tones have been studied in a quite exhaustive manner (see Surendran dissertation \cite{Surendran2007}), the time-series data mining approach is a novel approach in speech prosody research, which is the original contribution of the current project.  Fourth, we aim to develop methods not only applicable to Mandarin tone time-series data, but generalizable to other tone languages and other SPM tasks. These features of our approach are also reflected in our careful and precise formulation of the title of the thesis.



In sum, the contribution of this dissertation is two-fold. First, we aim to contribute a set of methodologies associated with the data mining of speech prosody, as the analysis of speech prosody and tones has not been previously carried out within a time-series mining framework (to the best of our knowledge). Second, the size of the data being analyzed is also much bigger than those found in typical speech prosody analysis works \cite{Surendran2007}. This allows us to discover novel and robust knowledge while developing new methods to address the challenges posed by mining this data. As data mining is being used ubiquitously to advance human knowledge in virtually all scientific fields and application domains, this approach harnesses the power in speech prosody big data, and contributes a set of novel technologies for researchers in speech technology, speech prosody, and linguistics. Finally, it is worth pointing out that to the best of our knowledge, most proposed tasks carried out in this dissertation are novel (especially in the specific ways they are formulated in this domain and the methodologies associated) and have not been attempted in previous works by others. This simultaneously gives us the \textit{challenge} to develop novel methods to solve these tasks, and the \textit{opportunity} for us to consider the implications of the results obtained from these novel experiments.






\newpage
\chapter{Background and previous works}
%tone recognition task

This thesis is concerned with the understanding and analysis of speech prosody time-series - especially focusing on Mandarin tones. In this chapter we provide the general background and literature review regarding the significance and challenges in the computational modeling of tones.

 \section{How important is tone?}
 Until recently, the state-of-the-art speech recognition of tone languages typically discard tone information altogether. There have been many discussions on why this is so \cite{Surendran2007}, but it is mainly attributed to the high error rate of tone recognition algorithms that supersedes the benefit of including tone information. Recent development in tone recognition, however, reveals the importance of tone information in speech recognition from a information theoretic point of view. In \cite{Surendran2004}, the functional load of tones is found to be at least as high as vowels while lower than the consonants. Here, the functional load of tones (FL) is defined as the information we lose if the phonological system loses the contrast posed by tones: 

 %%%%%%%%%%%%%%%%%%%%%%%% E Q U A T I O N %%%%%%%%%%%%%%%%%%%%%
 
\begin{equation}
FL (tone) = \frac {H(M_u)-H(M_u^{-tone})} {H(M_u)}
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



where $M_u$ is a sequence of units of type U in Mandarin, U being either a syllable or word in the entropy function H(.) calculation. $M_u^{-tone}$ refers to such a sequence without tone contrast, and H(.) is the standard entropy function of the system (i.e., a well defined \textit{language}). FL is defined as the functional load of tones. Intuitively, it characterizes how much information the system loses if the tone contrast is lost, therefore how important a contrast is within a phonological system. Table \ref{table:models} shows the functional load of tones versus other (segmental) contrasts in Mandarin. 

%%results
\begin{table}[h]
 \caption{Functional Load of tones vs other contrasts in Mandarin}
 \label{table:models}
 \begin{center}
 \begin{tabular}{|c || c | c|}
  \hline
  x & $FL_{syll}$(x) & $FL_{word}$(x) \\
  \hline
  Consonants & 0.235 & 0.081\\
  Tones & 0.108 & 0.021\\
  Vowels & 0.091 & 0.022\\
  Stops & 0.029 & 0.006\\
  Fricatives & 0.021 & 0.005\\
  \hline
  Place&0.065&0.014\\
  Manner&0.034&0.006\\
  Aspiration&0.002&0.0003\\
  \hline
 \end{tabular}
\end{center}

\end{table}



This analysis captures the importance of tones in Mandarin speech recognition systems. However, it should also be interpreted critically. First, it has the implicit assumption of taking a pure phonological point of view while ignoring all other information that can be used to recognize words and syllables, such as sequence-based language models in speech recognition (which is why Mandarin speech recognition can perform above 90\% accuracy without any tone information \cite{Chang2000}). In this regard, the \cite{Surendran2004} analysis fails to capture the importance of tones viewed from a broader perspective of information theory and entropy.

Second, results like \cite{Chang2000} also calls for an analysis of how important tone is for Mandarin speech recognition in humans. It is often an implicit assumption in tone recognition literature that humans are always able to perform with reasonably high accuracy in tone recognition \cite{Hirose1999}, even when contextual tonal, segmental, and other information is unavailable. However, speech experiments have revealed that native Mandarin speakers could perform below chance in isolated syllable tone recognition tasks when additional information usually available in speech is removed \cite{Xu1994}, depending on the specific experimental conditions. This is also supported by additional experimental evidence that humans are able to perform with greater than 90\% accuracy in speech understanding tasks with tone information removed in Mandarin (i.e., monotone $f_0$ is imposed synthetically)\cite{Patel2010}. 

Therefore, it is worthwhile to investigate this problem from an information theory point of view at a broader perspective (which from the above discussion, would reveal that it is much less important than  \cite{Surendran2004}   have suggested). The implication of such an analysis would be that, we cannot expect a machine to perform perfectly on isolated syllable tone recognition when humans cannot do it in the first place. Meanwhile, it suggests the importance to better understand acoustic and non-acoustic contextual information beyond the information present in the acoustic signal of isolated syllables.

%include more on the Kaifu Lee paper of how can tone help.














 \section{Why is tone recognition hard?}
In the canonical forms of Mandarin tone system, four tone categories are present: high-level (High tone), rising (Rising tone), low-dipping (Low tone) and falling (Falling tone). Following convention, these are also referred to as tone 1, 2, 3, and 4. \figref{fig:4tones-levow} shows the canonical contours of four Mandarin tones. In running speech, however, the contour shapes often become much distorted from canonical shapes, making it difficult to identify correct tone categories. Therefore, the challenge of tone recognition is to identify sources of variability and to exploit this knowledge to restore the underlying tone category. In spontaneous speech, there are many local and broader factors that play a role in producing the final tone contour shapes. These factors are usually rather convoluted and confounded and are therefore hard to identify. It requires carefully designed control experiments to reveal the effect and function of each contributing factor. 

As an example, \figref{fig:qvss} shows how a tone-controlled production experiment reveals variability of tone contour shapes in statement vs. question sentences with varying focus position (data from \cite{Liu2006}) . Looking at this simple example, which is far less complex than real spontaneous speech data, we can begin to see the reason why tone recognition is hard. First, we can see clearly that even though these are all Rising tones, most tones in this sentence have a rather flat shape, resembling the High tone. This is in contrast with \figref{fig:allhigh}, where a sentence is spoken with all high tones. Second, the variability of the tone shapes is dependent on the sentence focus and modality conditions. Ideally, these factors must also be taken into account in the recognition of tones from real spontaneous speech, where this type of uniform tone combination is highly unlikely. 

In this section, we review previous works on the source of variability problem from both speech production and prosodic modeling perspective.


%%%%%%%%%%%%%%%%%%%%%%a figure
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.5]{4tone-levow.png}}}
 \caption{Mandarin 4 tones canonical contour shapes (adapted from \cite{Levow2006})}
 \label{fig:4tones-levow}
\end{figure}

%%%%%%%%%%%%%%%%%%%%a figure
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.5]{allrise.png}}}
 \caption{Experimentally controlled production of all Rising tones in statement (solid lines) vs question sentences with varying focus position (adapted from  \cite{Liu2006})}
 \label{fig:qvss}
\end{figure}


%%%%%%%%%%%%%%%%%%%%a figure
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.5]{allhigh.png}}}
 \caption{Experimentally controlled production of all High tones in statement (solid lines) vs question sentences with varying focus position (adapted from [Liu et al 2006])}
 \label{fig:allhigh}
\end{figure}



\subsection{Sources of variability: Evidence from speech perception and production}
\cite{Gauthier2007} identified two major sources for the extensive overlaps among the contour shapes of different tone categories in running speech. The first is the difference in the pitch range of individual speakers and the second is the variability introduced by tonal context in connected speech \cite{Xu1997}. In tone recognition, the speaker difference is usually removed by normalization. The tonal context, as mentioned above, is where the majority of the research effort has been devoted to, with a focus on identifying and isolating sources of variability. 

Recent works on speech production and perception have made substantial progress on identifying sources of variability in tone production, by carrying out experiments with carefully controlled conditions and designed data sets \cite{Xu2014}. Such knowledge were also exploited to improve tone recognition accuracy\cite{Surendran2005, Liu2006}. These developments have led to the context-dependent (CI) models. 

In particular, experimental works have identified two levels of variability in continuous tone production: First, a \textit{local context} refers to the distortion of tones from its canonical shapes due to the co-articulation with adjacent tones. Second, a \textit{broad context} refers to the further modification of tone contours on the intonation level (i.e., on a larger prosodic unit than the syllable) \cite{Wang2011}. Examples of factors related to the broad context include topic, focus, and modality/mood of a sentence. Here we review works on both the local and the broad context in tone production, and when possible, their application in the machine learning of tones.




%does everything fit into local and broad context?
\subsubsection{Local context}
The local context of tone production is concerned with the behavior of tone contour $f_0$ trajectories with regard to its immediate environment, i.e., adjacent syllables. To study only the local context, experiments are often conducted with two principles in mind: first, to examine the effect of neighboring tones, speech production tasks are designed to reflect all different combinations of tones as target words. Second, to minimize the effect of higher level intonation, participants are asked to read the target words embedded in carrier sentences with careful speech and neutral focus. Several important results emerge from these studies of the local context. 

(1) \textbf{Local "conflicting" context distorts tone contour shapes in incompatible environments.} \cite{Xu1994} studied the variability of the tone contour shapes due to coarticulation, depending on the nature of the tonal context. By grouping tone environments into "compatible" vs "conflicting" contexts, it was observed that in a context where adjacent tonal values agree (a "compatible" context, such as when the High tone "HH" ending with "H" is followed by a High-Falling tone "HL" beginning also with "H")\footnote{The "H"(High) and "L"(Low) refer to phonological compositional representation of tones, where for example, a rising tone is represented as "LH" with two pitch targets: low and high. }, the deviation was relatively small. In a context where adjacent tonal values disagree (a "conflicting" context, such as when the said High tone is followed by a Low-Rising tone "LH" starting with "L"), the deviation was much greater, sometimes even to the extent of changing the direction of a dynamic tone.\footnote{The authors refer to tones with moving targets as "dynamic tone" (such as a low-rising tone), vs. static tone, where the tone has stable pitch targets (such as a high tone). } 

The author also examined the perception of co-articulated tones when tones are presented out of context in isolation. The results suggest that identification of tones produced in the compatible context was highly accurate with or without the original tonal context. Tone identification for those produced in a conflicting context remained accurate only when the tones were presented with the original context. Without the original context, i.e., in isolation or in artificially altered tonal context, tone identification accuracy dropped below chance. As discussed above, this result provides important counter-evidence to the "myth" in tone recognition literature that human listeners are always able to recognize tones with high accuracy, even when they're distorted and in isolation. 





(2) \textbf{Carry-over effect is greater than anticipatory effect in tone co-articulation.} In a pair of consecutively articulated syllables, does the tone shape of the first syllable have more impact on the tone shape of the second syllable, or vice versa? \cite{Xu1997} paid attention to the distortion of tones due to anticipatory and carry-over effects by examining the bigrams of $f_0$ contours in pairwise syllable sequences. Anticipatory effect is defined as the change of the tone contour shapes in the current syllable in anticipation of the next. Carryover effect is seen as the change of tone contour shapes in the current syllable due to the prolonged effect of the preceding tone. Using balanced nonsense sequences produced in different carrier sentences with balanced tonal structures, this study establishes a baseline for local contextual tonal variation in Mandarin. It is found that anticipatory and carry-over tonal influences differ both in magnitude and in nature. Carry-over effects are mostly assimilatory: the starting $f_0$ of a tone is assimilated to the offset value of a previous tone. Anticipatory effects, on the other hand, are mostly dissimilatory: a low onset value of a tone raises the maximum $f_0$ value of a preceding tone. While the magnitude of the carry-over effect is large, anticipatory effects are relatively small. This conclusion has been cited many times subsequently by tone recognition researchers, whose own data analysis also showed support for this asymmetry over and over again\cite{Surendran2007, Zhang2004, Levow2005}. There are also many machine learning approaches that take this effect into consideration in tone modeling.  

%need more comments
(3) \textbf{Physiological constraints of tone co-articulation. } \cite{Xu2002} studied the maximum speed of pitch change in human speech production, which contributes to the understanding of the underlying mechanism for tone co-articulation and its implication for tone modeling.  In this experiment, subjects (native speakers of English and Mandarin) produced rapid successions of pitch shifts by imitating synthesized model pitch undulation patterns. Results show that excursion time is nearly twice as long as response time in completing a pitch shift. Comparisons of this experimental data with real speech data suggest that the maximum speed of pitch change is often approached in speech, and the role of physiological constraints in tone production is greater than previously appreciated. 

(4) \textbf{$f_0$ peak delay.} Fundamental frequency ($f_0$) peak delay refers to the phenomenon that $f_0$ peaks sometimes occur after the syllable it is associated with, either lexically or prosodically. \cite{Xu2001} investigated peak delay and its relationship with tone, tonal context, and speech rate. Depending on speech rate, the author found that peak delay occurred regularly in Rising(R) tones and variably in High(H) tones. In general, peak delay occurs when there is a sharp $f_0$ rise near the end of a syllable, regardless of the cause of the rise. The author concluded that much of the variability in the shape and alignment of $f_0$ contours in Mandarin is attributable to the interaction of underlying pitch targets with tonal contexts and articulatory constraints, rather than due to actual misalignment between underlying pitch units and segmental units.





%To me, as interesting as this paper is, the biggest implication of the results is the question I have been asking for a long time: can human listeners correctly identify the tones independently in isolation without using any other information, such as lexical and semantic information in the context and in the segments? The answer in no. The further implication of this answer is simply that we cannot expect machines to do this in continuous recognition of tones in an independent manner. This is a fundamental conundrum of this task. We should perhaps try to establish an upper limit, given human performance, and try to perform an experiment to determine this limit. Humans, when performing this task in a regular context, has the advantage of incorporating other information in lexical statistical properties of n-grams and of semantic, syntactic, etc., information, that in speech recognition is not always the easiest to acquire with high accuracy.












\subsubsection{Broad context}


(1)\textbf{Focus in the temporal domain. }\cite{Xu2004} showed that focus not only affects the syllable under focus, but also extensively affects the pitch range of non-focused regions in a sentence, suggesting a wide effect of focus on the temporal domain. Results from this study show that in a declarative sentence, focus is realized not only by expanding the pitch range of the focused item, but also by compressing the pitch range of post-focus items, and possibly requiring that the pitch range of pre-focus items remain neutral. The authors proposed that the domain of a single, narrow focus consists of three temporal zones (pre-focus, on-focus, post-focus), with distinct pitch range adjustment for each. This proposal has received positive support when it was later applied to a machine learning model that improved tone recognition accuracy by incorporating focus information\cite{Surendran2005}. \cite{Liu2006} also used focus as an effective input feature to a decision-tree based classifier to predict the modality of a sentence from the prosodic domain (question vs. statement).

%this is important, include the detailed description
In \cite{Xu1999} , the author further examined how the lexical tone and the focus contribute to the formation and alignment of $f_0$ contours, using short Mandarin sentences consisting of five syllables with varying tones on the middle three syllables. The sentences were produced with four different focus patterns: focus on the first word, second word, last word, or with no narrow focus. The results indicate that while the lexical tone is the most important determining factor for the local $f_0$ contour of the syllable, the focus extensively modulates the global shape of the $f_0$ curve, which in turn affects the height and shape of local contours. Moreover, despite extensive variations in shape and height, the $f_0$ contour of a tone remains closely aligned with the associated syllable.


(2)\textbf{Long-term $f_0$ variations.} Many tone recognition algorithms incorporate features that encode the relative pitch heights of the tones \cite{Levow2005, Surendran2007}, in conjunction with the features that encode the contour shapes. In this regard, the pitch height of tones in longer temporal units of spontaneous speech (e.g., a sentence) must be normalized not only to account for individual speaker differences, but also to compensate for the long-term $f_0$ pitch movements due to factors such as down-drift and other pragmatic functions such as focus and topic. 

\cite{Wang2011} reports an experimental investigation of the prosodic encoding of topic and focus in Mandarin by examining disyllabic subject nouns elicited in four discourse contexts. They also looked at how prosodic effects of topic and focus differ from each other and how they interact with sentence length, downstep and newness to determine sentence-initial $f_0$ variations. Sixty short discourses were recorded with variable focus, topic level, newness, downstep, and sentence length conditions by six native speakers. The important conclusions include: 

(a) The difference between topic and focus is that focus raises on-focus $f_0$ and lowers post-focus $f_0$, but topic raises the $f_0$ register at the beginning of the sentence while allowing $f_0$ to drop gradually afterward;

(b) Topic has higher pitch register in isolated and discourse-initial sentences than in non-initial sentences;

(c) Longer sentences have higher sentence-initial $f_0$s than shorter sentences, but the differences are small in magnitude and are independent of topic and focus;

(d) The effect of downstep is independent of topic and focus, but is large in magnitude and accounts for a significant amount of the $f_0$ declination in a sentence;

(e) Newness has no $f_0$ manifestations independent of other factors;

(f) The effects of topic, focus, downstep and sentence length are largely cumulative.

As with other experimental findings reviewed in this chapter, the crucial question is how can we incorporate these fine-grained differences in machine learning algorithms to improve tone recognition accuracy. As will be discussed later, current methods tend to compensate for the global pitch shift patterns in a catch-all framework rather than distinguishing different communicative functions. 

%me: the cumulative nature of the different functions is said to support the PENTA model, which cumulatively encode and add the effects of each communicative function.




\subsection{Prosodic modeling}

Research in prosodic modeling provides evidences and often validations to the results obtained from speech production experiments mentioned above. It is also closely related to tone recognition, but with a different goal. The goal of prosodic modeling is to analyze prosodic patterns and synthesize speech prosody that is as natural as possible, while requiring less resources in storage, computation, and supervision. These models are used to generate $f_0$ contours for general speech synthesis. As such, typically, prosodic models are evaluated by means of its capability to (1) re-synthesize speech melodies that closely approximate the original data (training data) ; (2) predicatively synthesize / generate speech melodies of unseen data given annotated sentence and syllable conditions (i.e., input features). 

%what are we most interested in in prosodic modeling?
%  representation of intonation and tone; modeling of $f_0$ generation process

Meanwhile, on a different level, prosodic modeling is also associated with the representation of speech intonation in suprasegmental phonology, and the underlying mechanism for the production and perception of speech prosody \cite{Xu2011}. While this dissertation is not primarily concerned with either the generation of $f_0$ contours for speech synthesis or the phonological and psycholinguistic theory of tone production and perception, there are aspects of prosodic modeling that can shed light on the computational analysis of tones. Specifically, the representation of intonation is directly relevant to the choice of feature vectors we use to mine tone data. Moreover, the modeling of the $f_0$ generation process can also provide clues as to how tone variability occurs in real-time spontaneous speech. 

In the next two sections, I follow the convention in speech prosodic modeling \cite{Sun2002} and divide the review of relevant works into two parts: phonology-based and phonetic-based models\footnote{There has been theoretical discussions and debates \cite{Xu2011, Ramadoss2009} on which type of models is a more truthful representation of the speech production mechanism, which this dissertation is not concerned with. }. One of the phonetic-based models of particular interest for Mandarin is the quantitative Target Approximation model \cite{Xu1999}, which I will discuss separately. This model was developed specifically with Mandarin tones in mind, although it has been also generalized to be a language independent model.  
  








\subsubsection{Phonology-based models} \label{sec:prosodic}


%overview of phonological models
Phonological models are concerned with the universal organization and underlying representations of intonation, with implications on the theory of speech production and perception. Complex intonation patterns are compressed into a set of highly succinct and abstract vocabulary with wide coverage \cite{Sun2002}. In this framework, with the general notion of tonal targets, production of tones can be thought of as an interpolation between the various targets, and perception of tones is understood as an attempt to identify these targets. 




%AM model




The most influential example of the phonological representation of tone and intonation is the Autosegmental-Metrical (AM) intonational phonology and Pierrehumbert's model for American English \cite{Pierrehumbert1980} . \cite{Ladd1996} states four principles of the AM approach to intonation: (1) Linearity of tonal structure; (2) Distinction between pitch accent and stress; (3) Analysis of pitch accents in terms of level tones; (4) Local sources for global trends. It has also evolved into a standard for transcribing intonation of American English - Tone and Break Indices (ToBI) \cite{Silverman1992}.



The main idea of Pierrehumbert's model and the AM approach is that tone and intonation can be represented compositionally by two types of tones: High(H) and Low(L). In the autosegmental representation of tones, a \textit{Register} feature is proposed \cite{Yip1980} to represent H and L tones in the upper or lower register, allowing representation of up to five levels according to a division in pitch range. The AM representation also entails that associations between tones and TBUs(Tone Bearing Unit) are not necessarily one-to-one. Contours, therefore, can be represented as a sequence of tones associated with a single TBU: HL (Fall) or LH (Rise) \cite{ZsigaZec2013}. 

%The tone inventory include: \textit{Pitch Accents} can be either single tones (H*, L*) or bitonal (H*+L, H+L*, L*+H, L+H*). The * symbol represents the alignment of a tone with the accented syllable. \textit{Boundary tones}, denoted by the Ò\%Ó symbol, are single High or Low tones aligned with the edges of a phrase (H\%, L\%). Thus, they indicate the onset and offset pitch of an intonational phrase, respectively. \textit{Phrase accents}, indicated by the Ò-Ò symbol, are used to represent the pitch movement between a pitch accent and a boundary tone (H-, L-).

In terms of intonation, Pierrehumbert's model has a linear structure in that intonation is solely determined by a local component, which is in contrast to the superpositional approach that treats intonation as resulting from the addition of several components, including a local pitch accent and a global phrase contour. The mapping from phonology onto acoustics and physiology is a dynamic interpretative process \cite{Pierrehumbert1980}, where phonetic realization rules are applied to convert abstract tonal representation into $f_0$ contours by considering the metrical prominence of the syllables and the temporal alignment of the tones with the accented syllables \cite{Pierrehumbert1980}. 


In addition to prosody representation and synthesis, phonological models can also be used to learn and recognize tones. For example, \cite{Ramadoss2009} adopted a phonological view in the probabilistic tone recognition model for Thai (based on the theory from \cite{MorenZsiga2006}). In this study, since each tone category is modeled to have a specific target template associated with its TBU (mora in this case), categorizing tones reduces to matching the identified targets to the templates.

Overall, few works in tone recognition have considered this phonological approach, possibly due to the general lack of familiarity with phonological theory in the machine learning community, as well as the challenge of incorporating the general abstract symbolic representation of tonal targets into a machine learning framework that targets real-valued $f_0$ trajectories.


\subsubsection{Phonetic-based models}

%overview of phonetic models
Phonetic models use a set of continuous parameters to describe intonation patterns observable in $f_0$ contours \cite{Taylor2000}. An important goal is that the model should be capable of reconstructing $f_0$ contours faithfully when appropriate parameters are given. However, as many researchers have pointed out, a phonetic model should also be linguistically meaningful, since it is not mathematically difficult to approximate $f_0$ contours with some polynomial function. The real challenge is to develop a model whose parameters are predictable from available linguistic information \cite{Sun2002}. Here I describe several representative phonetic models.


% Fujisaki model

\textbf{Fujisaki model.} \cite{Fujisaki1983, Fujisaki1988} developed an intonation model for Japanese (later applied to other languages). The model additively superimposes a phrase component and an accent component on a logarithmic scale. The control mechanisms of the two components are realized as critically damped second-order systems responding to impulse/rectangular commands. As can be seen, it is a superpositional approach that assumes different intonation components are superimposed on top of each other, which is different from the linear AM approach described above. \cite{Mixdorff2003} has developed an algorithm to automatically extract model parameters for the Fujisak model from large speech corpora.

%qTA PENTA mention

\textbf{quantitative Target Approximation. }A pitch target approximation model for generating $f_0$ contours in Mandarin Chinese was proposed by \cite{Xu1997, Xu2001} and quantified in \cite{Xu1999} with the quantitative Target Approximation model (qTA). In this model, the surface $f_0$ contour is viewed as the result of asymptotic approximation to an underlying pitch target, which can be a static target (High or Low) or a dynamic target (Rise or Fall). These four pitch targets correspond to the four tones in Mandarin. Here, a pitch target is defined as the smallest unit that is articulatorily operable. The host unit of a pitch target is assumed to be the syllable (for Mandarin, at least). The model is also regarded as a quantitative realization of $f_0$ based on a speech production model (Parallel ENcoding and Target Approximation, or PENTA \cite{Prom-on2009}), which emphasizes the role of articulatory constraints in intonation modeling. Due to the relevance of the qTA model to the current dissertation, we discuss the relevant literature in more detail in Section \ref{sec:qta}.


%non-parametric phonetic models
\textbf{Non-parametric models. }Both phonological and phonetic frameworks seek to model $f_0$ contours effectively with a set of more abstract representations. However, $f_0$ values themselves are no doubt good indicators of high-level linguistic information \cite{Sun2002}. As discussed above, the goal in developing parametric models is to find a better representation of $f_0$ contours. However, if inappropriate forms are used, the predictions can be significantly different from the original $f_0$ contours \cite{Sun2002}. To address this problem, an alternative is to use the original $f_0$ contours directly or $f_0$ with some trivial modifications as the output targets. Such systems are referred to as non-parametric models, and often times they can achieve very competitive results. 

%some comments on model comparison based on Sun?






%PENTA and the annotation scheme plays a crucial role
%the reason here we separate this out is also b/c PENTA is the only model developed with Mandarin tones in mind and generalized to be language independent
\subsubsection{PENTA and quantitative Target Approximation (qTA)} \label{sec:qta}

As discussed above, the qTA and PENTA model have evolved over the years from its earliest theoretical formulation to the development of quantitative and computational modes. \cite{Prom-on2009} reports the full realization of the quantitative Target Approximation (qTA) model for generating $f_0$ contours of speech, including its mathematical modeling of the pitch target approximation process, and its parameter optimization strategy. The model simulates the production of tone and intonation as a process of syllable-synchronized sequential target approximation \cite{Xu2005}. As a speech production model, the qTA and the associated Parallel Encoding and Target Approximation (PENTA) model has generated much debate on its architecture, representation, and predictive powers. In the current context, however, we are only interested in evaluating how qTA's capability to numerically predict tone contours, as well as its representation of tone targets as input features to our data mining framework. In this model, each tone is produced with a pitch target in mind, defined by a linear equation with a slope and a intercept parameters, m and b:

%%%%%%%%%%%%%%%%%%%%%%%% E Q U A T I O N %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%equations
\begin{equation}
x(t)=mx+b
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

However, the realization of this target is often constrained and deviated by the characteristic factors of the human vocal folds, such as the continuity of pitch change (no abrupt changes in the slopes of the trajectories across syllable boundary) and the limitation of the maximum speed of pitch change \cite{Xu2002}. As a result, actual $f_0$ contours of tones are characterized by a third-order critically damped system:

%%%%%%%%%%%% E Q U A T I O N %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%equations
\begin{equation}
f_0(t)=x(t)+(c_1+c_2t+c_3t^2)e^\lambda t
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Intuitively, this can be seen as casting a noise component on top of the linear pitch target. In this equation, we have in total three parameters to represent a tone contour with the qTA model: slope ($m$) and height ($b$) of the pitch target, and $\lambda$, which represents how fast the pitch change is approaching the target slope and height. \figref{fig:qta} shows a number of different combinations of the parameters to demonstrate how the actual $f_0$ trajectory behaves depending on the underlying pitch targets. 





%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.4]{qta.png}}}
 \caption{Examples of $f_0$ contours generated by the qTA model with varying values of $m$, $b$, and $\lambda$. The dashed lines indicate the underlying pitch targets, which are linear functions of m and b. The vertical lines show the syllable boundaries through which the articulatory state propagates (adapted from \cite{Prom-on2009})}
 \label{fig:qta}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The qTA model extracts function-specific model parameters from natural speech audio via supervised learning (analysis by synthesis and error minimization\footnote{This strategy is used in the early version. Later versions adopted a more sophisticated method.}). After the parameter extraction, $f_0$ contours generated with the extracted parameters can be compared to those of natural utterances through numerical evaluation and perceptual testing (for evaluation).



The computational tools for extracting parameters and performing re-synthesis based on qTA model were developed in Praat Scripting Language (PSL). In the early version of this tool (PENTATrainer1\footnote{Downloaded from http://www.homepages.ucl.ac.uk/~uclyyix/PENTAtrainer1/.}), parameter optimization is achieved by an exhaustive search through the parameter space via error minimization algorithms\cite{Prom-on2009}. The local parameter sets learned from this process are then summarized into categorical ones by averaging across individual occurrences of the same functional categories \cite{Prom-on2009}. While the synthesis results did closely approximate the original $f_0$ contours, there are a few disadvantages of this strategy. First, the estimated parameters are optimal for the local syllable but not necessarily for the functional categories. Second, the estimation of $\lambda$ is often not satisfactory because it may be stuck at a local minimum and fails to converge to global minimum\cite{Xu2014}. 


To address this problem and upgrade the qTA model to include more features reflecting function-related variability, \cite{Xu2014} developed PENTAtrainer 2 using stochastic learning from real speech data with annotations of metadata information about the sentences (referred to as layered pseudo-hierarchical functional annotation scheme, which requires the manual labeling of only the temporal information of the functional units). More specifically, each syllable is annotated with its syllable boundaries, tone categories of the current and adjacent tones, focus / stress status, and associated sentential modality (see \figref{fig:PENTA2}). Overall, this version is characterized by its use of a functional annotation scheme, and training from the annotated data to obtain the parameter values, making it more explicitly a standard machine learning approach that encodes various types of input features. In this respect, it is unlike prosodic modeling approaches typically seen in previous literature. It also has the ability to predicatively generate synthesized speech melody on unseen data, given that the test data are also annotated in this set of input feature labels. The authors argue that this set of annotation is much less labor intensive than traditional frameworks. 

%discussion of dataset?


%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.5]{penta2.png}}}
 \caption{PENTATrainer 2 annotation scheme (adapted from \cite{Xu2014})}
 \label{fig:PENTA2}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cite{xu_lee_prom-on_liu_2015} comments on the advantage of such a learning model using the example of how to learn tone sandhi in this framework (below). This is an expected effect of the model if we consider it from a machine learning perspective:

\begin{quote}
...tone sandhi. For example, the Mandarin Tone 3 is changed to T2 when followed by another Tone 3. With PENTAtrainer2 this rule can be operationalized as the result of an interaction between two functions: lexical tonal contrast and boundary-marking. That is, the pitch target to be implemented in articulation is jointly determined by the morphemic tone of the current syllable, the morphemic tone of the next syllable, and by the strength of the boundary between the two syllables. Such functional interaction may allow T3 to develop a pitch target variant that happens to be similar to that of another tone, e.g., T2. But the two do not need to be identical, since the functional combinations are not the same. As found in \cite{Xu2014}, the best modelling result was obtained when the sandhi T3 was allowed to learn its own target, rather than when it was forced to use the T2 target. This result is consistent with the empirical finding of subtle yet consistent differences between the original and sandhi-derived T2 in Mandarin \cite{Xu1997}. Thus the obligatoriness of associating a unique target to each functional combination may have led to the development of tone sandhi in the first place. But further research along this line is needed.
\end{quote}
%This paper is not closely relevant to what I do, but it is a good review of a system that generates prosodic patterns for sentences. it might serve as an inspiration, and of course it has served as a candidate of feature representation of unsupervised learning. Maybe we could elaborate and see what other feature representations can be better based on this article.




\subsection{Evaluation data set} \label{sec:evaldataset}
%discuss pros and cons with Xu's argument
An important aspect of machine learning is the data set used in training and evaluation. In Mandarin tone learning, the nature of the data set varies depending on the mode of the speech: tone contour shapes in a read speech data set are more faithful to the canonical forms, and is therefore easier to learn (although it is by no means perfectly "clean", as co-articulation between adjacent syllables would still introduce variability). Such data sets are usually produced with carefully designed research questions in mind (in the context of a speech production / perception experiment) and is therefore not always appropriate to use in all contexts. The advantage, of course, is that the data set is controlled and may contain more balanced data with regard to the goal of the study, which helps the researcher to better understand a particular problem. In contrast, in a large spontaneous speech data set (such as newscast data sets), the speaking rate is faster, and all parameters of the speech are free to vary. This leads to more distortions to the shapes of the tone contours, and makes them more difficult to recognize when considered in isolation for each syllable. By convention, evaluation of tone recognition systems is usually done with both types of data set, progressing from an easier "clean" data set to a more messy and much bigger "hard" data set \cite{Levow2006, Levow2006a}. 

\cite{Xu2014} paid special attention to justifying the use of experimentally produced, smaller, "clean" data sets in training the prosodic models of PENTATrainer 2 with supervised learning methods: 

\begin{quote}
......Note that all these three corpora, due to their experimental nature, may seem more
limited than most other corpora used in data-driven modeling, which are typically much less controlled. But speech corpora are merely subsets of all speech and as such they can never be full exhaustive. What really matters is whether a corpus includes sufficient samples (preferably by multiple speakers) of the patterns of interest as well as their triggering contexts. Traditional corpora, typically consisting of many more unique sentences than in a controlled corpus, inevitably have very uneven sample sizes for different patterns. As a result, it is hard to determine in the end which proportion of the modeling errors should be attributed to the modeling algorithms and which should be attributed to the uneven sample sizes. A further advantage of controlled corpora is that they allow special designs for focusing on difficult problems such as the neutral tone in Mandarin...... it would be very hard to find more than a few (or any at all) samples of similar neutral tone sequence in a traditional corpus. Furthermore, controlled corpora, like those just described, due to their full transparency, makes it easier for investigators to understand what may be the source of a particular problem and how damaging it is, as we will see in the case of the Mandarin corpus used in the present study...... 

\end{quote}


%lab condition is controlled, but not perhaps always mirror what happens in spontaneous speech as Dinoj dissertation suggested.
%edit this:



This point is well supported by many experimental works. For example, \cite{Liu2006} analyzed sentence global intonation by using a data set where syllabic tone effects are removed. This is achieved through carefully controlled sentences where all words have the same tone (such as the first tone). This type of design is indeed very helpful in understanding the behavior of the global intonation without the effect of tones, and it may indeed by hard to obtain from a large corpus of spontaneous speech. In the meantime, from the perspective of building robust predictive models, the complexity of a larger data set of spontaneous speech is still indispensable. 







 \section{Supervised learning of tones}

Supervised learning is the predominant approach in Mandarin tone machine learning research. In our current project, a successful unsupervised learning framework must learn from the supervised learning literature. Recent years have seen the renewed interest in improving tone recognition using context-dependent models in supervised learning frameworks. These improvements include better understanding of the features used in tone recognition, and the effort to utilize contextual information to recover underlying tone targets. These techniques will be reviewed in the next two sections. In Section \ref{nucleus}, we also review works that attempt to recover underlying tone targets by identifying the most relevant "nucleus" region in the syllable $f_0$ contour.

%look at how some papers summarized this literature organizationally

% mention why supervised learning is useful for unsupervised learning (1) features (2) problems and adjustment - ask Wilson

\subsection{Feature selection}

%[Surendran 2007] dissertation
Intuitively, $f_0$ contour is the most relevant feature of tones. However, the problem of using only the basic form of $f_0$ features, as discussed above, lies in its variability in running speech. To improve tone recognition accuracy beyond the constraints of using basic $f_0$ features, there have been many efforts to identify and select other useful features that can be extracted from the speech signal. 

\cite{Surendran2007} concentrated on solving this problem by incrementally testing and identifying effective features in all dimensions. In this dissertation, the author conducted hundreds of experiments on a variety of datasets of broadcast speech to determine the effectiveness of a set of 68 features from multiple dimensions.  The results suggest that (1) modifying the pitch and intensity of a syllable based on its neighbors was useful (pitch normalization by subtracting the mean pitch of the preceding syllable); (2) Among the twenty voice quality measures used in tone recognition, energy in various frequency bands was the most useful; (3) A set of 60 band energy features greatly aided the recognition of low and neutral tones; (4) Tone context (knowing the tones of surrounding syllables) did not help as much as one would have expected, suggesting the other features are already capturing a lot of contextual information; (5) Stronger syllables (such as focus) were easier to recognize in lab speech, but the effect is diminishing for broadcast speech. 

%Kristen Yu's dissertation
In another doctoral dissertation, \cite{Yu2011} investigated a similar problem by asking how tones are learned (by machines) and acquired (by humans) from the speech signal through the available information in various phonological spaces (such as $f_0$ and voice quality). The author concentrated her investigation on Cantonese but also included a variety of tone language data such as Mandarin. The results demonstrated that voice source parameters beyond $f_0$ must be included for characterizing phonetic spaces for tonal maps in a wide range of languages. 

%Xu and whalen
The correlation between intensity and tones have been demonstrated in early works of speech experiments. In a series of intriguingly designed tone perception judgment experiments, \cite{Whalen1992} tests the information present in the amplitude contours and in brief segments of Mandarin tones. In the first two experiments, the researchers used a signal-correlated noise (by adding samples with flipped signs to the original samples such that the amplitude is unchanged, but the $f_0$ and formant structure information is removed) to obtain the amplitude contours of the tones without retaining information of $f_0$ and formants. The results showed that Mandarin speakers are able to identify tones with high accuracy using only amplitude contour information (although later it was shown that amplitude values correlate highly with absolute $f_0$ values for tone 2, 3, and 4). In experiment 3 and 4, the authors extracted brief tone segments of variable length using a hamming window, and tested the accuracy of tone identification at each position along the tone contour (e.g., onset at 0ms, 20ms, 40ms, etc., from the beginning of the tone contour). The result suggests that tone 2 and tone 4 are identified with better accuracy when movements of the segments are similar to their respective movement trajectories (i.e., rising for tone 2 and falling for tone 4). For tone 1 and tone 3, the listeners identified more accurately when there are little pitch movement, using differences of absolute $f_0$ (lower sounding pitch judged as tone 3). This indicates the pitch register effect of the tone perception, which is largely unexplored in previous research. The information in intensity contours are subsequently used in computational works to identify the nucleus region of tones \cite{Wang2011}, to be discussed in chapter \ref{nucleus}.


\subsection{Context-dependent modeling}
As mentioned above, recent works have largely distinguished local from broad context in the context-dependent investigation of $f_0$ variability. While tone recognition literature conceptually identifies those two types of contexts, in practice, the two are usually combined to work together inside a single machine learning framework. Therefore I discuss the context-dependent modeling in tone recognition without separating these two types into different sections.

%doesn't distinguish local vs broad (or use both)
\cite{Wang2000} improved tone recognition accuracy using contextual information in a Mandarin spoken digit recognition application. The authors focused on two aspects of the contextual intonational effect (one broad and one local context): First, $f_0$ downdrift during the course of an utterance (sentence); Second, the distortion of $f_0$ contour height and slope according to different tonal contexts (i.e., preceding and following tones). To address the first problem, a linear model was built for sentential downdrift and a value is subtracted from the observed $f_0$ values. To take into account the local tone context, the proposed algorithm adjusts the observed $f_0$ contours based on a model trained from the different tonal contexts, in terms of $f_0$ frequency and slope. This system has an overall error reduction rate of 26.1\% compared to the base system.



%Levow use both
Similarly, \cite{Levow2005} incorporates both local context and broader context features in tone recognition with linear kernel SVM, while paying attention to the individual feature sets.  The local context is encoded in two types of features: "difference" and "expanded" features. Both types of features have sub-features that encode left or right contexts.

The first set of features (\textit{difference features}) corresponds to differences between the current syllable and its preceding and following syllables. They include differences between pitch maxima, pitch means, pitch at the midpoint of the syllable, pitch slopes, intensity maxima, and intensity means. The second set of features, known as \textit{extended syllable features}, is simply the ending pitch values from the end of the preceding syllable and the first values from the beginning of the following syllable, as well as the pitch maxima and means of these adjacent syllables.

The context dependent features are found to consistently outperform context independent features. The results of additional contrastive experiments suggest that left tone context is much more important than right context in tone category identification. In fact, the right context is shown to decrease the performance of the classifier. This result is consistent with speech perception/production experimental results from previous works \cite{Xu2001}, showing that the tone co-articulation effect is asymmetric. 

The broader context feature mainly includes the $f_0$ compensation for downdrift (similar to \cite{Wang2000}). The author used the median slope per syllable \textit{across the entire corpus} as phrase-based falling contour compensation. Similar to \cite{Wang2000}, \cite{Levow2005} found the alternative compensation strategy based on \textit{individual phrase} slope (i.e., build a linear model for each phrase, instead of using a global slope across the corpus) overfits to the specific tone configuration and reduced accuracy. In the phrase-based feature representation, each pitch value is thus replaced with an estimate of the pitch value with downdrift removed, by adding back the estimated pitch drop to pitch values later in the phrase. The result showed improvements in classification accuracy. The author commented that since the phrase segmentation employed here was very simple, it is expected that more nuanced approach with finer grained phrase boundary and possibly phrase accent detection would likely yield greater benefits.




\cite{Wang2011}] proposed a tone recognition approach that employs linear chain Conditional Random Fields (CRF\footnote{CRF is a probabilistic graphic model that can be seen as similar to Hidden Markov Model (HMM) for sequence modeling and inference. Crucially, while HMM is a generative model, CRF is a discriminative model.}) to model tone contour variations due to intonation effects. Three linear chain CRFs are built, aimed at modeling intonation effects at phrase, sentence and story-level boundaries. All linear-chain CRFs are found to outperform the baseline unigram model, and the biggest improvement is found in recognizing third tones in overall accuracy. In particular, Phrase Bigram CRFs show a 39\% improvement in recognizing third tones located at initial boundaries. This improvement shows that the position-specific modeling of initial tones in bigram CRF captures the intonation effects better than the baseline unigram model.



Looking at the broad context, \cite{Surendran2005} exploits the focus conditions to improve tone recognition. Pre-focus, post-focus, in-focus, and no-focus conditions are distinguished. The experiment with known focus labels found that pre-focus and no-focus behave similarly in terms of tone recognition error rate, with post-focus having the largest error rates. Meanwhile, on-focus syllables are the easiest to recognize with minimal error rates. Overall, by training and testing SVMs conditioned upon different focus condition groups, the classification error rate reduced 42.9\% comparing to the baseline, where no focus group is identified. However, in this experiment, the focus labels had to be manually annotated and they were available on both training and testing sets. This is an unrealistic scenario in real applications. Next, the researchers conducted experiments to incrementally reduce the requirements on manual labeling. The second experiment assumes focus labels are only known during training, and uses $f_0$ and intensity based features to predict the focus conditions on testing data set. The third experiment assumes that correct focus labels are not available at all. In this experiment, the focus labels for both training and testing data are predicted from the confidence rating on the tone recognition algorithm without using focus information. It is observed and hypothesized that the tones classified with the highest confidence score is the location of the focus. In both of these subsequent experiments using predicted focus label, it is interesting to observe that even though the prediction errors were high on the focus label (more than 30\%), the error reduction of the ultimate tone recognizer is still comparable with the first experiment where the correct focus label is known (error rate below 10\%). The authors attribute this to the similar behavior of the tone classifier on pre-focus and no-focus conditions, where most of the confusion happens in the focus label prediction phase. Table \ref{table:focus} shows the summary of results in this study assuming known focus.

%insert a table of results.
%%results
\begin{table}
 \caption{Tone recognition using focus (adapted from \cite{Surendran2005})}
 \label{table:focus}
 \begin{center}
 \begin{tabular}{|c | c| }
  \hline
\textbf{Condition}  & \textbf{Error Rates} \\
\hline
Combined:not using focus(baseline) & 15.16\%\\
\hline
No-focus syllables & 7.74\%\\
Pre-focus syllables & 7.74\%\\
In-focus syllables & 0.80\%\\
Post-focus syllables & 18.37\%\\
\hline
Combined: Conditional on correct focus & 8.66\%\\

  \hline
 \end{tabular}
\end{center}

\end{table}

\cite{Liu2006} uses the B-Spline coefficients\footnote{B-Spline is a type of piecewise polynomial that functionally approximates the intonation curve.} plus acoustic features to train decision trees for question/statement classification from intonation contours in Mandarin (referred to as the modality of the sentence), using a highly controlled experimental dataset. For ten-syllable utterances, the highest correct classification rate (85\%) is achieved when normalized final $f_0$s of the seventh and the last syllables are included in the tree construction. The results confirm the previous finding that the difference between statement and question intonations in Mandarin is manifested by an increasing departure from a common starting point toward the end of the sentence. Meanwhile, this paper also raises the question regarding the effectiveness of using compact model coefficients to represent $f_0$ contours in supervised and unsupervised learning (as other works such as \cite{Zhang2015} have found that ultra-low-dimension polynomial and qTA coefficients do not perform well in unsupervised learning for Mandarin tones). 
















\subsection{Tone nucleus region modeling} \label{nucleus}
Other researchers have sought to identify the most relevant regions in a syllable for tone recognition. Such regions are hypothesized to better approximate the true underlying tone target. This is in part motivated by tone production models such as the PENTA model, which assume that carryover coarticulation dominates tone realization and thus the true tone is more closely approximated in the latter half of the syllable. \cite{Sun2002} used partial tone segments from the midpoint to the end of the syllables for pitch accent recognition. Subsequently, \cite{Zhang2004} proposed a model that successfully identifies tone nucleus regions for canonical tone production. The tone region is segmented by applying k-means clustering on pitch contour units; the nucleus itself is identified based on features including segmental time and energy. 





\cite{Wang2006} proposes a strategy to identify nucleus regions of tones using the amplitude and pitch plot segmentation with computational geometry techniques. Given syllable boundaries, this approach employs amplitude and pitch information to generate an improved sub-syllable segmentation and feature representation, essentially segmenting the syllable into several regions (one of which is the nucleus region). This sub-syllable segmentation is derived from the convex hull of the amplitude-pitch plot, based on criteria such as the slope (illustrated in \figref{fig:convexhull}). This approach achieves a 15\% improvement using the said segmentation strategy over a simple time-only segmentation. 


%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.45]{convex.png}}}
 \caption{Three-phase segmentation of Second Tone. Pitch contour (top left); Amplitude contour(top right); Convex hull of amplitude-frequency plot (bottom left); Final segmentation (bottom right), adapted from \cite{Wang2006}}
 \label{fig:convexhull}
\end{figure}





 
 



%%%%%%%%%%%%%%%%% U N S U P E R V I S E D         LEARNING
\section{ Unsupervised learning of tones}
There has been limited effort on the unsupervised learning of tones. It is well known that most supervised learning frameworks must rely on a large amount of manual annotation effort that is costly in time and money \cite{Levow2006a}. This annotation bottleneck, along with the theoretical interest in the learning of tones, motivates the use of unsupervised or semi-supervised approaches to tone recognition \cite{Levow2006}. Another motivation to explore unsupervised learning is to model the process of language acquisition, as child learners must identify these linguistic categories without explicit instruction but only by observing natural language interactions\cite{Levow2006a}. As such, the goal of unsupervised learning frameworks is to improve the accuracy of tone learning algorithms with minimum supervision and human labeled data.




%move and add some motivation of the unsupervised framework for this project.

\subsection{Unsupervised and semi-supervised learning of Mandarin tones}

%need to recharacterize this chapter by arguing the main goal of mining a large quantity of prosodic data, which is in contrast to the smaller and more controlled data set being used in the typical speech experiments and prosodic modeling experiments. there should be a discussion chapter on data sets. 

%the time-series representation chapter could use a bit more consideration from representations in speech prosody modeling.

%add chapters on previous work of intonation corpus mining, including the lithuanian work and references.




Some preliminary unsupervised works by \cite{Gauthier2007} employed self-organizing map\footnote{A self-organizing map (SOM) is a type of artificial neural network (ANN) that is trained using unsupervised learning to produce a low-dimensional (typically two-dimensional), discretized representation of the input space of the training samples, called a map.} by use of $f_0$ velocity as input features for tone learning. \cite{Gauthier2007} used a raw 30-point pitch vector and the pointwise first derivatives (D1) of the $f_0$ values as feature vectors on some 2000 observations of tone contours. In particular, they found that the D1 feature vectors yielded an almost perfect result in classifying unseen stimuli, an improvement over using raw 30-point $f_0$ values. This shows the internal structures that can be exploited in the tone space via unsupervised learning. Meanwhile, since this study did not use spontaneous speech data set, it is yet to be seen how it performs on more realistic data sets\footnote{Christo Kirov (Johns Hopkins University) and I have performed an initial trial experiment of using SOM on some small samples of spontaneous speech data and obtained mixed results. This is yet to be more systematically evaluated on a larger dataset of spontaneous speech.}. 

\cite{Levow2006, Levow2006a} concentrated on the problem of unsupervised learning and semi-supervised learning in Mandarin tone recognition. \cite{Levow2006} employed asymmetric k-lines clustering, a spectral clustering algorithm, as the primary unsupervised learning approach. Rather than assuming that all clusters are uniform and spherical, this approach enhances clustering effectiveness when clusters may not be spherical and may vary in size and shape. The author argues that this flexibility yields a good match to the structure of Mandarin tone data where both the shape and the size of clusters vary across tones. A comparison is made between k-means clustering, symmetric k-lines clustering, and Laplacian Eigenmaps with k-lines clustering. 

This algorithm is evaluated on a clean read data set and a spontaneous broadcast news data set. Table \ref{table:unsupsup} summarizes the results using the unsupervised vs. supervised approaches. 

Contrastive experiments showed that the asymmetric k-lines clustering approach consistently outperforms the corresponding symmetric clustering learner, as well as Laplacian Eigenmaps with binary weights for English pitch accent classification (shown in \figref{fig:clust}). To the author's surprise, k-means clustering outperforms all of the other approaches when producing 3 to 14 clusters (i.e., $k=3,4,...,14$).\footnote{In fact, it has been shown in time-series mining literature \cite{Mueen2009} that k-means and Euclidean distance are extremely powerful techniques as the the data gets bigger, despite their simplicity.} Accuracy when using the optimal choice of clusters and parameters is comparable for asymmetric k-lines and k-means, and somewhat better than all other techniques considered. The author attributes this similar performance to the careful feature selection process. Moreover, for the four-tone classification task in Mandarin using two stage clustering, asymmetric k-lines strongly outperforms k-means, at 87\% vs. 74.75\% accuracy.


%features	
	
%%results of unsupervised vs. supervised learning
\begin{table}
 \caption{Tone recognition with unsupervised and supervised learning (adapted and modified from \cite{Levow2006, Levow2006a})}
 \label{table:unsupsup}
 \begin{center}
 \begin{tabular}{|c || c | c | c|}
  \hline
Condition & Unsup. & Supervised & Semi-supervised \\
\hline
Lab,In-focus & 87\% & 99\% & 94\%\\
\hline
Lab, Pre and In-focus & 77\% & 93\% & n/a\\
\hline
Broadcast News & 78\% & 81.3\% & 70\%\\
  \hline
 \end{tabular}
\end{center}

\end{table}

The feature set used in this study is well informed by previous works on tone production and perception, which included multiple types of features beyond the $f_0$ and features that reflect the context-dependent nature of tone contour shapes. The basic features include $f_0$ features (five equidistant points sampled from the $f_0$ contour of the syllable nucleus, and mean $f_0$) and intensity features (both are normalized per speaker and log scaled). The final region of each syllable is identified as the nucleus region. To account for co-articulation effects, nucleus region slope features are computed according to qTA's assumptions \cite{Prom-on2009}.  These are further log-scaled and normalized to compensate for the greater speeds of pitch falls than pitch rises\cite{Xu2002}. \figref{fig:heightslope} shows the well-separatedness of the four tones in the read speech data set in terms of the slope and height of their pitch targets. Overall, while this yields valuable evidence for feature experimentation, it is doubtful that this pattern can be generalized to the spontaneous speech data.



\subsection{Semi-supervised learning of Mandarin tones}
	
	
	
\cite{Levow2006a} further explored semi-supervised learning for the tasks in \cite{Levow2006}, using the Manifold Regularization framework. This framework postulates an underlying intrinsic distribution on a low dimensional manifold for data with an observed, ambient distribution that may be in a higher dimensional space with pairwise distances preserved. More specifically, this paper uses Laplacian Support Vector Machines, a semi-supervised classification algorithm, which allows training and classification based on both labeled and unlabeled training examples. For each class in a Mandarin data set, the model uses a small set (40) of labeled training instances in conjunction with 60 unlabeled instances, and then tests on 40 instances. 
	
	
The semi-supervised classifier achieved comparable results with the unsupervised algorithm (see Table \ref{table:unsupsup}). Surprisingly, the semi-supervised classifier also reliably outperforms an SVM classifier with an RBF kernel trained on the same labeled training instances. 



%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.5]{clust.png}}}
 \caption{Comparison of different clustering algorithms with varying number of clusters and clustering accuracy}
 \label{fig:clust}
\end{figure}
	
	%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.5]{heightslope.png}}}
 \caption{Cluster separation of pitch target slope (x) vs height (y) in Mandarin read speech data set}
 \label{fig:heightslope}
\end{figure}
	
	
 
 
 
\section{Speech prosody mining using time-series mining techniques}
A less explored area related to the computational modeling of tones is the data mining of speech prosody in a large spoken or intonation corpus \cite{Raskinis}. The goal of this endeavor is to improve the understanding of speech intonation and tone contour patterns through data mining and pattern discovery algorithms using a large quantity of real speech data. 

Previous works in corpus-based intonation research \cite{Raskinis, Zhang2015} have shown the challenges of mining a large intonation corpus. At the core of this task is the expensive computation of a large amount of high-dimensional pairwise distance (especially with the Dynamic Time Warping or DTW distance measure for time-series data) to obtain the distance matrix, and to find the most effective low-dimension feature representation for the $f_0$ time-series data that faithfully preserve the true distances among objects, with increased efficiency for storage.



\subsection{Overview of time-series data mining} \label{sec:tsmining-overview}
%ts mining introduction
%time series data mining
Formally, a time series T = $t_1$,...,$t_p$ is an ordered set of p real-valued variables, where $t_i$ is the time index. Time-series data mining focuses on data mining tasks using time-series data. \cite{Lin2007} outlined the main tasks that time-series data mining research is concerned with:

(1) Indexing: Given a query time series Q, and some similarity/dissimilarity measure D(Q,C), find the most similar time series in database DB;

(2) Clustering: Find natural groupings of the time series in database DB under some similarity/dissimilarity measure D(Q,C);

(3) Classification: Given an unlabeled time series Q, assign it to one of two or more predefined classes;

(4) Summarization: Given a time series Q containing $n$ data points where $n$ is an extremely large number, create a (possibly graphic) approximation of Q which retains its essential features but fits on a single page, computer screen, executive summary etc;

(5) Anomaly Detection: Given a time series Q, and some model of normal behavior, find all sections of Q which contain anomalies or surprising/interesting/unexpected/novel behavior.

Due to the typical large size of data mining tasks and the high dimensionality of time-series data, a generic time-series data mining framework is as follows: \cite{Faloutsos} (1)Create an \textit{approximation} of the data, which will fit in main memory, yet retains the essential features of interest; (2) Approximately solve the task at hand in main memory; (3)Make (hopefully very few) accesses to the original data on disk to confirm the solution obtained in Step 2, or to modify the solution so it agrees with the solution we would have obtained on the original data.

However, in practice, the success of this generic framework depends on the efficient time-series representation and distance measure in the approximated space that allows the lower bounding of true distances in the original space \cite{Lin2007}. The distance measure also needs to effectively capture the true (and meaningful) distances among objects, and also allows reasonably efficient computation (tractable) often by using special techniques to prune off impossible candidates. In Part III of this dissertation, I discuss some of the most relevant key issues in these areas and focus on finding the optimal methods for computing similarity for speech prosody time-series data.


\subsection{Data Mining $f_0$ time-series data}

The data mining of $f_0$ (pitch) contour patterns from audio data has recently gained success in the domain of Music Information Retrieval (a.k.a. MIR, see \cite{Gulati2014,Gulati2015,Ganguli15} for examples). In contrast, the data mining of speech prosody $f_0$ data (here on referred to as Speech Prosody Mining (SPM)\footnote{As the previous research in this specific area is sparse, we have coined this term as we conceptualize the time-series data mining based framework for the pattern discovery, similarity computation and content retrieval from speech prosody databases.}) is a less explored research topic \cite{Raskinis}. Fundamentally, SPM in a large prosody corpus aims at discovering meaningful patterns in the $f_0$ data using efficient time-series data mining techniques adapted to the speech prosody domain. Such knowledge has many potential applications in prosody-related tasks, including speech prosody modeling and speech recognition. Moreover, a Speech Prosody Query and Retrieval (SPQR) tool can be also of great utility to researchers in speech science and theoretical phonology/phonetics (tone and intonation). 



Due to the nature of speech prosody data, SPM in a large prosody corpus faces classic time-series data mining challenges such as high dimensionality, high feature correlation, and high time complexity in operations such as pair-wise distance computation. Many of these challenges have been addressed in the time-series data mining literature by proposing heuristics that make use of cheaper and more efficient approximate representations of time-series (e.g., symbolic representations). However, a central question to be addressed in SPM is how to adapt these generic techniques to develop the most efficient methods for computing similarity for the speech prosody time-series data (that also preserves the most meaningful information within this domain). In Part III and Part IV of the dissertation, we will investigate a variety of approaches and toolkits to develop methods targeted at the understanding and analysis of speech prosody time-series data, including time-series representation and distance measure, motif discovery, network analysis, and cross-domain machine learning\footnote{By "cross-domain" we mean using features from a variety of linguistic domains to predict problems from another linguistic domain. See Part IV for details.}.









\newpage

%%%%%%%%%%%%%%%%%%% part 2: data and preprocessing
\part{Data Collection and Speech Processing}
\newpage
\chapter{Data Collection}


Following conventions in machine learning literature for Mandarin tones\cite{Levow2006}, we experiment with two sets of corpora for our preliminary investigation: a class of smaller, cleaner read speech corpus, and another class of large speech-recognition-size corpora containing spontaneous newscast speech typically found in the evaluation for Mandarin speech recognition and tone recognition tasks. See Section \ref{sec:evaldataset} for a discussion on the characteristics of these two types of data.

%Between these two classes, the nature of the data sets varies depending on mode of the speech: tones contour shapes in a read speech data set are more faithful to the canonical forms, and is therefore easier to learn (although it is by no means perfectly "clean", as co-articulation between adjacent syllables will still introduce variability). The advantage of a smaller clean data set is that it is controlled and may contain more balanced data with regard to the goal of the study, which helps the researcher to better understand a particular problem. In contrast, in a large spontaneous speech data set, the speaking rate is faster, and all parameters of the speech are free to vary. This leads to more distortions to the shapes of the tone contours, and makes them more difficult to recognize when considered in isolation for each syllable. Traditionally, evaluation of tone recognition systems is usually done with both types of data set, progressing from an easier "clean" data set to a more messy and much bigger "hard" data set \cite{Levow2005,Levow06a}. 


\section{Read speech dataset} \label{sec:rsd}
We use the read speech data set from Xu's study on the contextual variation of Mandarin tones \cite{Xu1997} (subsequently used in \cite{Gauthier2007}). Many properties of this data set make it a good starting point for time-series similarity experiments.

The design of this data set was originally targeted at revealing only the variability of tone shapes induced by contextual factors (i.e., position of tones) and to reduce the effect of other factors to a minimum. To achieve this, the author designed a word list consisting of two syllables (/ma+ma/), and all 4*4=16 combinations of tones are read by subjects. Most of these two-syllable sequences would be nonsense words. Each two-syllable sequence is read within the context of four different carrier sentences (giving rise to further contextual variation), recorded five times by each speaker, yielding 16*5*4=320 tokens per speaker. Three speakers are recorded in this data set (two male and one female), yielding a total of 320*3=960 words, or 960*2=1920 tokens of single syllable tone instances. We obtained the data set from the first author of \cite{Xu1997} in the format of csv files, including un-normalized and smoothed, downsampled 30-point $f_0$ contour pitch tracks of the 3 speakers. In addition, it contained the corresponding 30-point first derivative (D1) data computed from the original pitch track used in \cite{Gauthier2007}.

At a first glance, this data set seems too clean, as it maintains a very constrained set of combinations of variables. However, simple clustering experiments in previous works demonstrated the challenge of learning this data set\cite{Zhang2015}. In the first study that used this data set, Xu\cite{Xu1997} concluded that in a two-syllable sequence, the influence of the contexts on tone shapes are mutually inequivalent. Specifically, the anticipatory effect of the second syllable on the first syllable is smaller than the carryover effect from the first to the second. Meanwhile, \cite{Zhang2015} observed that clustering with the subset of data from the first syllable achieves significantly better results than using the data set from both syllables. Therefore, one interesting property of this data set is that, it's possible to observe the behavior of features and methods using a cleaner subset of the data (i.e., first syllable only) and contrast it with the performance on the full data set.





\section{Newscast speech datasets} \label{sec:manthaidata}

We describe the Mandarin newscast speech corpus obtained from Linguistic Data Consortium (LDC) in this study. In addition, we also discuss speech corpora for Thai, to be used in extended evaluation.


1) Mandarin Chinese Phonetic Segmentation and Tone (MCPST) corpus\footnote{https://catalog.ldc.upenn.edu/ldc2015s05} was developed by the Linguistic Data Consortium (LDC) and contains 7,849 Mandarin Chinese "utterances" and their phonetic segmentation and tone labels separated into training and test sets. The utterances were derived from 1997 Mandarin Broadcast News Speech and Transcripts (HUB4-NE) (LDC98S73 and LDC98T24, respectively). That collection consists of approximately 30 hours of Chinese broadcast news recordings from Voice of America, China Central TV and KAZN-AM, a commercial radio station based in Los Angeles, CA. 

"Utterances" in this corpus are time-stamped between-pause units in the transcribed news recordings. Those with background noise, music, unidentified speakers and accented speakers were excluded. A test set was developed with 300 utterances randomly selected from six speakers (50 utterances for each speaker). The remaining 7,549 utterances formed a training set. In the current work we combine all data sets, obtaining 7849 utterances, totaling about 100,000 syllables (tones) to work with.

This data set is unique in that it contains annotations on the segmentation and identity of syllabic tones (whereas other newscast data sets contain only audio and transcripts). The utterances in the test set were manually labeled and segmented into initials and finals in romanized pinyin form. Tones were marked on the finals, including Tone1 through Tone4, and Tone0 for the neutral tone. The Sandhi Tone3 was labeled as Tone2. The training set was automatically segmented and transcribed using the LDC forced aligner\footnote{Described in http://www.lrec-conf.org/proceedings/lrec2012/pdf/1065\_Paper.pdf}, which is a Hidden Markov Model (HMM) aligner trained on the same utterances. The aligner achieved 93.1\% agreement (of phone boundaries) within 20 ms on the test set compared to manual segmentation. The quality of the phonetic transcription and tone labels of the training set was evaluated by checking 100 utterances randomly selected from it. The 100 utterances contained 1,252 syllables: 15 syllables had mistaken tone transcriptions; two syllables showed mistaken transcriptions of the final, and there were no syllables with transcription errors on the initial. Each utterance has three associated files: a \texttt{.flac} compressed sound file, a transcript text file, and a phonetic boundaries and labels file (\texttt{.phons}).


This is the primary large spontaneous speech data set we will be working with in this dissertation. Henceforth we denote this data set the CMN (Chinese segMentatioN) data set.


%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}
\caption{Three female speakers in the Thai data set} \label{tab:thai-spk}

\small
 \begin{center}
 \begin{tabular}{|c||c|c|}
\hline


Speaker ID & mean pitch & size (syllable) \\
\hline
SPA & 212.767628995 & 294\\
SPB & 268.64804386 & 208\\
SPC & 263.441188041 & 185\\


  \hline
  
  
 \end{tabular}

\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%

2) Corpora for Thai. In Part V of the dissertation, we extend the supervised and unsupervised tone learning algorithms proposed in Part III and evaluate them on a data set of Thai. For this experiment, we need data that satisfies these conditions:(1) segmented and annotated with tone information; (2) the quality of the audio should be good, with decent signal-to-noise ratio(SNR); (3) the data set should be of a relatively large size that merits data mining tasks.

In reality, we have found that such large-scale corpora (or Thai speech corpora in general) are much harder to acquire comparing to Mandarin. This may be related to the relatively large amount of interest, high activity and commercial markets present in the Mandarin speaking world. There are several speaker recognition corpora on LDC that claims to include multiple languages including Thai, however, we are not able to locate the Thai portions of the corpora (nor their transcripts) in any of these data sets made available on LDC. 

On the other hand, we have tracked down some data sets used in previous Thai tone works such as \cite{Ramadoss2009}. However, these data sets are very small in size (data size $<$ 50 tones) and are therefore not meeting our criteria for performing data mining experiments. 

In the end, we have decided to utilize a subset of the CRSLP-MARCS corpus\footnote{http://childes.talkbank.org/access/EastAsian/Thai/CRSLP.html.} \cite{Luksan2000} made available through CHILDES\footnote{http://childes.talkbank.org.}, the child language acquisition data platform. The CRSLP-MARCS corpus consists of video-linked transcriptions of 18 Thai adult-child interactions from the child age of 6 to 24 months, at three monthly intervals. Sessions were of 20 minutes of duration and for CHILDES these have been split into 10 minute files, a total of 242 files. This corpus has several advantages for our use: (1) it is a large corpus containing more than 40 hours of video recordings (not all of which are speech), from which we only need to extract a fraction to obtain a good size in terms of number syllables for our analysis; (2) all adult speech (which we are using) are transcribed with clear phonetic symbols and each syllable is marked with the tone label; (3) the data is already segmented with utterance-level timestamps (however, additional manual work is needed to segment syllables and mark their tone labels); (4) the entire corpus is publicly available on the CHILDES platform. The major shortcoming of this data is that the audio is not of ideal quality, which often contains a lot of background noise.

An additional consideration when using this data is that being a data set on CHILDES, we observe a lot of child-directed speech which may include prosodic profiles that deviate from regular speech found in a newscast corpus, for instance. 

Due to these considerations and limitations, we have segmented, annotated and extracted about 700 tones from a subset of the corpus following these criteria: (1) we primarily chose speech that are directed at adults (whenever available), and secondly, directed at children; (2) we chose speech with relatively low ambient noise; (3) we chose to annotate tones with a consideration of the balance of the five tone categories in the data set. The resulting data set comes from 3 different female adult speakers. Table \ref{tab:thai-spk} shows the statistics of the three speakers in the data set.

This corpus marks tones in the following convention:  mid level = tone 0; low level = tone 1; falling = tone 2; high level = tone 3; rising = tone 4. 




%% We use the data from Ramadoss's Thai tone modeling paper \cite{Ramadoss2009}. In that work, pitch tracks were extracted from stimuli used in \cite{ZsigaNit2004}. The stimuli were all recorded from a young female speaker of the Bangkok dialect of Thai. The stimuli used in this study are all monosyllabic utterances of different syllable types, instantiating the different tones. There are
%restrictions on the tones each syllable type can take, and these can vary depending on the
%length of the vowel, or whether the final coda is an obstruent or sonorant. Three repetitions of each of the five possible tonal shapes on the selected syllables were recorded in each of four different contexts planted in a carrier sentence (for details see \cite{ZsigaNit2004}).


%As there is limited availability of speech audio corpora for these languages in LDC, we are researching into the tone and speech recognition literatures for these languages and identify the resources they used for evaluation. We observe that the availability and accessibility of large scale audio corpora is limited in those languages comparing to Mandarin. For example, \cite{Sue2005} had to requested their large spontaneous speech corpus (phone conversation in the hotel reservation domain) from a Thai national government institution (NECTEC), which contains 6 hours of speech data.  Otherwise, researchers tend to collect a smaller size data themselves, exemplified by Tan et al.\cite{Tan04}. This data is taken from a continuous Thai speech corpus consisting of 360 utterances. The data was collected from 18 native Thai speakers (9 male and 9 female speakers) with each speaker reading 20 utterances randomly chosen from Thai words, and total 5726 tones. The speech data was manually segmented and transcribed at phoneme level. We plan to obtain this data for Thai, as it is a medium sized corpus with number of syllable between our read and newscast data for Mandarin.

%For Cantonese, there is a large scale corpus called the CUCorpus, built by Chinese University of Hong Kong \cite{Lee2002}. This corpus is oriented towards large vocabulary speech recognition and contains several sub-corpora with data from general purpose and special domains (digit commands, etc). The corpus contains about 200,000 syllables and 70,000 utterances. For details on the development and statistics in this corpus, refer to \cite{Lee2002}. We will consider using a subset of this corpus for evaluation on Cantonese. The availability and accessibility of this corpus is currently unknown. 




 
\newpage

%segmentation strategy will depend on the corpus specs, what is annotated. also see next chapter comments
\chapter{Speech Processing}


%pitch estimation, smoothing, normalization, etc. however, these may be part of the evaluation. #alternative org
\section{Fundamental frequency ($f_0$) estimation}
One challenge of obtaining high-quality time-series $f_0$ data from speech is the presence of voiceless segments as well as pitch estimation errors (e.g., pitch doubling and halving, etc). To this end, previous literature have used standard pitch estimation algorithms such as autocorrelation \cite{Boersma93} found in Praat, paired with pitch smoothing techniques. In the current study we use the autocorrelation pitch detection algorithm in Praat as our pitch estimation algorithm, and we describe post-processing steps to ensure the quality of the tone time-series data. To evaluate the estimated pitch, we randomly sampled pitch tracks and manually checked that they are identical to the ground truth in spectrogram (i.e., \textit{fundamental} frequency), as shown in Figure \ref{fig:interp-spectro}. 


%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{spectro.pdf}}
 \caption{Sample trimmed pitch track and manual check of fundamental frequency $f_0$ ground truth (estimated pitch track, marked in dark thick lines, matches the fundamental frequency in the background spectrogram in red)}
  \label{fig:spectro}

\end{figure}
%%%%%%%%
\section{Speech Processing} \label{sec:speech-proc}

Following \cite{Surendran2007}, we then apply an intuitive trimming algorithm to eliminate large jumps in pitch, and use simple linear interpolation to fill in values of $f_0$ for unvoiced frames. Others have used more complex methods of interpolation, such as splines \cite{Lei2006}. 
		%? Flow chart[ Picture on page "Proprocess"][Picture on page "Flow chart syl-ext"]
\subsection{Pitch Trimming}
Due to the unavoidable pitch detection errors in autocorrelation algorithm, such as octave doubling, we must carefully trim pitch values obtained from the original algorithm before they can be used for any data mining purposes. We discuss several problems and strategies in pitch trimming.


\subsubsection{Naive pitch trimming based on outlier removal}
Intuitively we can apply outlier removal to trim spurious pitch values estimated from a sentence, and we will interpolate pitch values for both removed and unvoiced frames. Outliers can be detected by looking at values above the upper whisker in a boxplot. However, this results in a large amount of remaining spurious pitch values, and the interpolation makes the pitch distribution even more deviated from the true distribution. Figure \ref{fig:naive-lts} shows the results obtained by this method. This plot shows the entire pitch time-series in the CMN corpus (normalized). Values around and above 1.5 should be considered spurious (corresponding to above 600 Hz in original space). We see that after our proposed trimming method is applied (described next), we obtain a much cleaner pitch time-series\footnote{In this plot the periodic chunks of fluctuations reflect the different pitch ranges of different speakers.} (Figure \ref{fig:trim-lts}).

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{original_pitch}}
 \caption{Long pitch time-series of the entire CMN corpus after naive trimming (normalized)}
  \label{fig:naive-lts}

\end{figure}
%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{trimmed_pitch}}
 \caption{Long pitch time-series of the entire CMN corpus after more sophisticated trimming (normalized)}
  \label{fig:trim-lts}

\end{figure}
%%%%%%%%
\subsubsection{Problem with centrality-based approaches}
The problem with the naive approach is that it assumes unimodal central tendency of the pitch data. While this is in general true for well estimated pitch tracks, it has problems with the spurious pitch tracks which can appear to have a bimodal distribution. We show such a sample pitch track in Figure \ref{fig:bimodal-pitch}, where pitch segments are discontinuous and is therefore bimodal between true pitch values and spurious (very high) pitch values. We show a sample bimodal pitch distribution histogram in Figure \ref{fig:bimodal}. Therefore, in order to effectively trim spurious pitch values, we need to consider this kind of data, and carefully design a more sophisticated trimming algorithm.


%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{bimodal_pitch}}
 \caption{A sample pitch track with bimodal distribution (spurious)}
  \label{fig:bimodal-pitch}

\end{figure}
%%%%%%%%

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{bimodal}}
 \caption{Distribution of a sample bimodal pitch track}
  \label{fig:bimodal}

\end{figure}
%%%%%%%%

\subsubsection{A segment-based speaker-dependent triming algorithm}
Our proposed algorithm starts from the observation that in a pitch track like Figure \ref{fig:bimodal-pitch}, we can easily identify spurious pitch segments if we divide the pitch into discrete segments first based on timestamps and we compute the difference $d$ in pitch values between the end of a segment and the beginning of the next (and vice versa). A spurious pitch segment would have a very large positive value of $d$ followed by a very large negative value whereas other true pitch values would have a $d$ that's fairly constant. We implemented this intuition and made some observations in Figure \ref{fig:D1-filter}, where we plotted the difference values of all consecutive pairs of points in the pitch track, overlaid with the original pitch track itself. We can see that large (absolute) values of $d$ (indicated by lone red crosses) are good indicators of spurious segments. Mathematically, this method is equivalent to calculating the first derivative of the pitch track and observing its irregularities. 

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{D1-filter}}
 \caption{Difference values between pairs of consecutive points in identifying spurious pitch segments. Dark green shows the original pitch track, with red cross showing its difference values.}
  \label{fig:D1-filter}

\end{figure}

%%%%%%%%

This algorithm has one hyperparameter, i.e., it depends on setting a threshold $T$ for $d$ difference values so that we can be confident to trim of pitch values beyond that threshold of difference. However, this again depends on our understanding of the pitch movements in speech and the distribution of $d$, which can vary a lot depend on speaker and other functions. Concretely, we have found that the speaker's overall pitch standard deviation (std) is an useful indicator for their pitch movement patterns. Therefore we propose a speaker dependent value for $T$. But before we can compute the std values for each speaker, we must also apply a first round trimming of their outlier pitch values (otherwise the std would be a distorted representation of their most typical pitch movement patterns). Figure \ref{fig:XIY} shows a sample speaker's (XIY) original pitch value distribution and the std value is suspiciously large. However, after we performed an outlier pruning step, the distribution becomes more reasonable (Figure \ref{fig:XIYpost}). We implemented the outlier pruning step by computing a histogram with density estimation and empirically decided to remove any pitch value with a density value less than $10^{-4}$. In the end, we chose the threshold $T=130$ for $std \leq 70$, and $T=200$ for $std>70$ (only applies to one speaker). Besides, we also remove very short pitch segments with a duration less than 60 samples (with a time step of 0.001s using the autocorrelation algorithm).

Lastly, we used a remedy to the centrality problem by first interploating the pitch track so that the central tendency can be regained, before we apply any outlier-based trimming strategy. Figure \ref{fig:spectro} shows the results of trimmed pitch.

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{XIY}}
 \caption{Original pitch value distribution of a speaker (XIY), with mean and standard deviation indicated in vertical lines.}
  \label{fig:XIY}

\end{figure}

%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{XIY-posttrim}}
 \caption{Pitch value distribution of a speaker (XIY) after first applying outlier pruning.}
  \label{fig:XIYpost}

\end{figure}

%%%%%%%%







\subsection{Normalization}
Speaker-dependent pitch normalization is necessary to account for the different range of different speakers. We normalized all pitch values by individual speakers using the subtract mean normalization (see Section \ref{sec:TSN} for detail).

\subsection{Log transformation}
Generally, semitones (a logarithmic function of fundamental frequency) are a more robust measure of pitch than Hertz. Therefore, we used $logF_{0hz}$ instead of $F_{0hz}$ following \cite{Surendran2007}. More specifically, we use Bark scale, a log scale of pitch shown to correlate with perception better than linear scales such as Hertz. Bark scale is defined as below and will be further discussed in Section \ref{sec:pmfr}.

\begin{equation}
F_{CENT}=1200 * log_2 \frac{F_{HZ}}{F_{REF}}
\end{equation}

Bark scale is near linear in lower values and deviates faster from linear in higher values. While this is true for log scale in general, we found that Bark scale is more effective at many tasks comparing to simply using $log_2$ on pitch values (as some previous works did). This also shows the importance of the quality of preprocessing.


\subsection{Pitch reliability percentage}
The outcome of pitch estimation contains many frames without reliable pitch values. For each syllable we collect a simple statistic describing the percentage of the syllable duration being reliably estimated, and we logged this information as an extra column in the \texttt{.phons} file in the corpus, which contains time and segmental information of the utterances. This enables us to estimate the confidence of pitch estimation of a given syllable and easily filter unreliable ones.



\subsection{Interpolation}
Following convention, wee use the \texttt{scipy.interpolate1d} function in Python to perform linear interpolation on missing pitch values. A sample pitch track after applying interpolation is shown in Figure \ref{fig:interp-spectro}.

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{interp-spectro.pdf}}
 \caption{Sample trimmed and interpolated pitch track}
  \label{fig:interp-spectro}

\end{figure}
%%%%%%%%


\subsection{Smoothing}
We experimented with two smoothing strategies: first, a simple moving average window; second, a Gaussian window that assigns more weight to points that are closer and decaying weight for those that are far away\footnote{https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.gaussian.html}. However, in subsequent time-series mining experiments (Part III of this dissertation), we found that this sophisticated smoothing technique consistently decreased the performance of the Query by Content (QBC) task in the unsupervised learning of tones. We speculate that this is due to that fact that often times, this technique may produce too big a deviation from original values. Therefore, in subsequent tasks we use only simple moving average sliding window to smooth the pitch curves. Figure \ref{fig:smo} gives us a peek into how a rising contour profile, coupled with some discontinuities in pitch estimation, can turn into falling when more sophisticated smoothing is applied.
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{tone2.png}}
 \caption{Sample result of how smoothing can change the profile of a tone pitch curve}
  \label{fig:smo}

\end{figure}
%%%%%%%%


\subsection{Downsampling}
We test three strategies for downsampling. First, we test \texttt{scipy.resample} which resamples x to a specified number of samples using Fourier method along the given axis\footnote{https://docs.scipy.org/doc/scipy-0.16.0/reference/generated/scipy.signal.resample.html}. This is a sophisticated method using signal processing techniques. Second, we test a "padding-and-averaging" method, a classic downsampling method by first padding the signal with 0s to the length of $L$ so that it can be divided by the desired downsampled length $l$ with no remainders. Then we average each $L/l$ samples to derive $l$ samples as the downsampled vector. Third, we implement a "(quasi)equidistant" downsampling algorithm where we compute a combination of hop sizes $a$ and $b$ to do (quasi)equidistant sampling, where $a,b$ are very close integers. Concretely, we want to use a linear combination of hop sizes $a$ and $b$ in order to maximize $f=a*x+b*y$, where $x,y$ are integers, $x+y=l$ (where $l$ is again the desired length of the vector after downsampling), with the constraint $f \leq L$. The result is almost equidistant sampling of the original vector. In practice we found $a=5, b=4$ to work well, and we'll be able to programmatically solve for x and y given that $x\leq(L-30*b)/(a-b)$. Intuitively this means that when absolute equidistant sampling is not possible because the remainder of $L/l$ is not zero, we use a combination of hop size steps $a$ and $b$ to achieve quasi-equidistant sampling. 

Empirically the quasi-equidistant method performs the best with the QBC task (Part III of this dissertation). Here we show the results of applying these three methods to a group of sample pitch tracks in Figures \ref{fig:res}, \ref{fig:mix}, \ref{fig:ave}. From comparing these plots we can see that the quasi-equidistant method is the most faithful to the original (by design), while the other two have different amounts of distortion (the averaging method is a natural smoothing mechanism). Based on the empirical evidence, we conjecture that these distortions are harmful to the signal carried in the original pitch tracks for tone recognition purposes.

Figure \ref{fig:sp} shows the pipeline of speech and data preprocessing.

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{CHJ000014_voicedcsv_res.pdf}}
 \caption{Sample downsampled pitch track with resampling method}
  \label{fig:res}

\end{figure}
%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{CHJ000014_voicedcsv_mix.pdf}}
 \caption{Sample downsampled pitch track with quasi-equidistant method}
  \label{fig:mix}

\end{figure}
%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{CHJ000014_voicedcsv_ave.pdf}}
 \caption{Sample downsampled pitch track with averaging method}
  \label{fig:ave}

\end{figure}
%%%%%%%%

\subsection{Extracting ngrams}
We extract tone unigrams from the preprocessed pitch data, producing two versions: voiced-only and whole-syllable unigram data. A downsampled version is produced after the originals. We then extracted tone N-gram data (bigrams and trigrams) from the whole-syllable unigram data set by concatenating tone unigrams and then downsample them to different sampling rate (100, 200, 300, and 400 point vectors). The metadata (which speaker and sound file the N-gram is coming from and its index position in the corresponding \texttt{.phons} file, tone labels, token sentence boundary, etc.) is also appended to the end of each line, enabling us to access the original data points in a later stage. 

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.4]{sp.png}}
 \caption{Speech processing and data preprocessing pipeline}
  \label{fig:sp}

\end{figure}
%%%%%%%%

\subsection{Data sets}
We give a summary of the data sets we produced after preprocessing. We organize this information in Table \ref{tab:datasets} by the value of $N$ (number of syllables in the N-gram) and we show the variety of data sets produced for tone unigrams, bigrams, and trigrams. Subsequence length refers to the number of data points in a tone N-gram. In the rest of the dissertation we refer to these data sets by their ID. With the exception of UW data set, all other data sets are downsampled and therefore suffered from a loss of data points comparing to the original (UW). Concretely, these lost data points have an original subsequence length less than the downsample subsequence length. Therefore the downsampling also serves as a pruning step to ensure better quality of the data set.


%%results of unsupervised vs. supervised learning
\begin{table}
 \label{tab:datasets}
  \caption{Data sets overview. U=unigram, B=bigram, T=trigram, W=whole syllable, V=voiced only, nN=non-neutral tones. UW is the only original data set without downsampling.}
 \begin{center}
 \begin{tabular}{|c|c|c|c|}
  \hline
N & Subsequence length & ID &  Size \\
\hline
\hline
1 & varies & UW & 100161\\
 & 30 & UW30p & 78546\\
  & 30 & UV30p & 74141\\
  & 30 & UVnN30p & 70815\\
  & 100 & UW100p & 90524\\
  \hline
2 & 100 & B100p & 88360\\
 & 100 & B200p & 85573\\
 \hline
3 & 100 & T100p & 77813 \\
 & 200 & T200p & 77562 \\
 & 300 & T300p & 76513 \\
 & 400 & T400p & 67644\\
 


  \hline
 \end{tabular}
\end{center}


\end{table}
















\newpage
\part{Computing similarity for speech prosody time-series}
% alternative title:  time-series mining and unsupervised learning of tones







\newpage

\chapter{Time-series representation and distance measures}
A preliminary task for SPM (Speech Prosody Mining) is the computation of similarity for time-series objects in the speech prosody domain. In order to efficiently and meaningfully capture this similarity, in this chapter, we consider a variety of parameters in the time-series data mining framework: (1) time-series representation; (2) distance measure; (3) normalization. Then, in the next chapter, we evaluate these methods in a series of time-series data mining tasks in the speech prosody domain.



\section {Prosodic modeling feature representation} \label{sec:pmfr}

%(1)numeric representation: qTA, polynomial fitting, raw $f_0$ vector (diff or same length),D1

(1) \textbf{Polynomial Regression.} The most straightforward way to model $f_0$ contour curves is to use polynomial functions to fit the $f_0$ contour of each utterance. A $f_0$ contour can thus be represented by the coefficient vector [$c_1$, $c_2$,..., $c_{n+1}$] of a \textit{n}-th order polynomial. This has been done in a number of studies for tone and intonation  \cite{Liu2006}. Alternatively, one could use a spline function, a piece-wise polynomial to model different sections of a complex contour. This approach greatly reduces the dimensionality of the original $f_0$ contour.  However, \cite{Xu2011} points out that the critical question about polynomial representations is that whether they are linguistically meaningful, and whether they can be used in predictive modeling, i.e., serving as categorical parameters that can be generalized to other instances of the same category. However, this method has not been evaluated in a predictive synthesis context. \cite{Zhang2015} experimented with the third degree polynomial representation (a 4d vector) of $f_0$ contours in a clustering task with a clean read data set of Mandarin tones. The conclusion suggests that the clustering accuracy is low.
 
 


(2) \textbf{quantitative Target Approximation.} Given that qTA model (see chapter \ref{sec:qta}) has been shown to perform well in producing curves that closely resemble real tone contours in connected speech, an important question to be asked is: do qTA parameters perform well to reflect the similarities between tones in perception? In other words, we want to make sure that qTA parameters have the property where perceptually similar tone contour shapes also have similar parameter values. In \cite{Zhang2015}'s experiments the results suggest a negative answer to this question. The poor performance of both polynomial and qTA features suggests that in order to use coefficients for features, the model from which the coefficients are derived must preserve the true distances between objects in the original space, a property that these two models don't seem to possess.


(3) \textbf{Raw Time-series $f_0$ Vector}. \cite{Gauthier2007} showed that unsupervised classification using Self-Organizing Map (Neural Network) yielded a nearly 80\% correct result when time-series are represented with a 30-point raw $f_0$ vector. 

In \cite{Zhang2015}, in order to find the best method of working with $f_0$ vectors, several transformations are made from the raw $f_0$ vectors, including un-normalized and normalized. For each of these, in order to avoid the logarithmic behavior of Hertz unit, three versions are created, using Hertz, Bark, and Cent scale representations, giving rise to a total of 6 types of feature vectors. The conversion from Hertz to Bark and Cent are computed as below:

\begin{equation}
F_{CENT}=1200 * log_2 \frac{F_{HZ}}{F_{REF}}
\end{equation}

where the $F_{REF}$ is the reference frequency, corresponding to the minimum $f_0$ in the computation of the pitch track (set to 55Hz).

\begin{equation}
F_{BK}=7*log [F_{HZ}/650 + ([1+(F_{HZ}650)^{2}]^{1/2})]
\end{equation}



(4) \textbf{First Derivative Vector (D1)}. The discrete first derivative feature (D1) is obtained simply by taking the first derivative of the original signal of the tone contour, and downsampled to 30 point:

\begin{equation}
D1=0.5 * (F_0 (t+1) - F_0(t-1))
\end{equation}

for all timestamps \textit{t}.

Intuitively, the D1 feature captures the movement of the pitch trajectory at each timestamp. It also serves as a normalization strategy where the differences in pitch height among different speakers are removed. Otherwise, the D1 does not reduce the dimensionality of the time series, nor does it create new abstract features as a combination of other features. As a first glance, it is not a fundamentally different transformation over the $f_0$ feature. However, \cite{Gauthier2007} showed a near-perfect performance using the D1 feature in a classification task with Self-Organizing Map. In the same experiment, the $f_0$ feature performs around 20\% lower than the D1 feature. The authors attributed this success to the fact that D1 is able to capture the direction of pitch movement at each timestamp, a property that raw $f_0$ vectors do not possess. 









\section{Time-series symbolic representation}
There have been a great number of time-series representations proposed in the data mining community, including both real-valued and symbolic representations. \figref{fig:ts-rep} illustrates the most commonly used representations \cite{Lin2003}\footnote{Notice in this taxonomy, there is no representation that satisfies the lower bounding requirement under symbolic representation. Later, we will discuss Symbolic Aggregate approXmiation (SAX) \cite{Lin2003}, the first symbolic representation to satisfy this condition. }.





  

%a figure
\begin{figure}[h]
 \centerline{\framebox{
 \includegraphics[scale=0.4]{ts-rep.png}}}
 \caption{Types of Time-series Data Representations (adapted from \cite{Lin2003})}
 \label{fig:ts-rep}
\end{figure}

\cite{Lin2007} points out the limitations of real-valued time-series representations (such as DFT and DWT) in data mining algorithms. For example, in anomaly detection, we cannot meaningfully define the probability of observing any particular set of wavelet coefficients, since the probability of observing any real-valued number is zero. Such limitations have led researchers to consider using a symbolic representation of time series.

There have been many symbolic representations proposed for time-series. However, none of the techniques (that is, before the Symbolic Aggregate approXimation) allows a distance measure that lower bounds a distance measure defined on the original time series. This constitutes a problem for the generic time-series mining framework discussed above in Section \ref{sec:tsmining-overview}, since the approximate solution to problem created in main memory may be arbitrarily dissimilar to the true solution that would have been obtained on the original data. A symbolic approach that allows lower bounding of the true distance would not only satisfy the requirement of the generic framework, but also enable us to use a variety of algorithms and data structures which are only defined for discrete data, including hashing, Markov models, and suffix trees \cite{Lin2007}. Symbolic Aggregation approXmation (abbreviated SAX) \cite{Lin2003} is the first symbolic representation for time series that allows for dimensionality reduction and indexing with a lower-bounding distance measure at the same time. The related MINDIST distance function for SAX is discussed in chapter \ref{sec:dist}.

 

The SAX representation transforms the pitch contour into a symbolic representation using Piecewise Aggregate Approximation technique (PAA, \figref{fig:paa}), with a user-designated length ($\textit{w}$=desired length of the feature vector) and alphabet size ($\textit{a}$), the latter being used to divide the pitch space of the contour into $\textit{a}$ equiprobable parts assuming a Gaussian distribution of $f_0$ values (\figref{fig:sax}). Here, the Gaussian distribution is used to obtain the breakpoints for vertial pitch space so that each region (represented by a symbol) is equiprobable (probability of that symbol is given by the integration of the area under the Gaussian curve, as defined by the break points). This ensures that the probability of a segment being assigned any symbol is the same. \figref{fig:sax} shows an example of SAX transformation of a time-series of length 128. It is discretized by first obtaining a PAA approximation and then using predetermined breakpoints to map the PAA coefficients into SAX symbols. 



%SAX as used in MIR and by me
SAX has been evaluated in various classic time-series mining tasks and shown to work well in numerous applications to mine data from a variety of fields such as bioinfomatics, finance, telemedicine, audio and image signal processing, and network traffic analysis\cite{Lin2007}. In particular, it has been shown to preserve meaningful information from the original data and produce competitive results for classifying and clustering time-series data. 




%[Velaro ]
SAX has been less explored in the domain of audio signal $f_0$ pattern mining. In the context of Music Information Retrieval (MIR), \cite{Valero-Mas2015} experimented with SAX representation for the computation of $f_0$ contour similarity from music audio signals in a Query-By-Humming (QBH) task\footnote{In a query by humming task, a user hums a section of the melody of a desired song to search for the song from a database of music recordings.}. However, results suggest that SAX does not perform well for musical time-series data in the context of QBH. The authors attribute this to the fact that SAX does not align well with the particularities that the origin domain of the time series may have - in this case, the discrete musical notes. Thus, in the case of QBH, SAX may be abstracting away key musically-relevant information from the melodic contours required for properly performing the alignment of $f_0$ contour pairs. 


%[Zhang et al 2014,2015a,2015b]
\cite{Zhang2015, ZhangCaro2014} showed the effectiveness of SAX in mining speech or speech-like $f_0$ contours - tones, where finer details of the $f_0$ contours do not carry crucial information comparing to its global shape. In \cite{ZhangCaro2014}, musical $f_0$ contours from Beijing opera singing are converted to SAX representations in order to compare its similarity to linguistic tones of its lyrics. In a manually constructed data set consisted of balanced $f_0$ contour shapes from all four tones, four types of evaluation measures showed that SAX representation faithfully preserves the original clusters. Similarly, \cite{Zhang2015} experimented with the SAX parameters by iterating through different combinations of \textit{w} and \textit{a} to find the best correlation with the perceived pitch relationships in pairwise contour analysis.


%[gaustuv]
One strength of SAX is its ability to reduce the dimensionality of the original $f_0$ contour (this is also termed "pitch quantization" in signal processing). This type of simplification is very useful in both addressing the "curse of dimensionality" problem, and to reduce cost and speed up computation. However, there are also many other variants of symbolic representation that can perform pitch quantization. One must choose the most appropriate variant according to the specific needs of the task at hand. For example, a property of SAX is that each segment used to represent the original time-series must be of the same length. This might not be an ideal situation in many applications (exemplified in \cite{Zhang2015, Ganguli15}) where variable lengths segments are desired. The complexity of converting to such an variable-length representation may be greater than SAX, as one must design some criteria that decides whether the next frame of audio samples belong to the current segment or it should be the start of a new segment. 


% distance measure, mindist, 


%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.5]{paa.png}}}
 \caption{Piecewise Aggregate Approximation. The PAA representation can be visualized as an attempt to model a time series with a linear combination of box basis functions. In this case, a sequence of length 128 is reduced to 8 dimensions (adpated from \cite{Lin2007})}
 \label{fig:paa}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.4]{sax.png}}}
 \caption{Symbolic Aggregate Approximation, with original length n = 128, number of segments w = 8 and alphabet size a = 3, output word \textbf{baabccbc} (adpated from \cite{Lin2007})}
 \label{fig:sax}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%












\section{Time-series normalization} \label{sec:TSN}


%time-series normalization
Many literature reviews \cite{Lin2007} in time-series mining assert that time series must be normalized using the z-score transformation normalization strategy so that each contour has a standard deviation of 1 and mean of 0 (in fact this is a general strategy that is also used in mining non-time-series data):

%z-score transformation formula
\begin{equation}
z=(x_i-\mu)/\sigma
\end{equation}

where $\mu$ is the mean of the contour and $\sigma$ is the standard deviation.

However, \cite{Zhang2015} observed that speech tone time-series data has a special property so that the z-score transformation would seriously distort the shapes of the tones in the normalized corpus. Essentially this is caused by the presence of many flat or near flat contours (such as in level tones). Since z-score transformation expresses each data point in a time series by its relative value to the mean in terms of standard deviation, it would magnify the differences in the values of the flat or near flat contours (since each point in this contour is identical and also identical to the mean), and turn such contours into a significantly non-flat contour. 

Since normalization is required for a meaningful comparison of time-series patterns, we need to design an alternative strategy for time-series normalization in this task. There are many strategies that fulfill this purpose. After trial and error experimentation, one of the best working measure is the Subtract-Mean normalization strategy (Equation \ref{form-norm}). It effectively retains the original shapes in a normalized corpus of tones. 

%add equation

%z-score transformation formula
\begin{equation}
\label{form-norm}
z=(x_i-\mu)
\end{equation}


This issue also exists in the SAX representation since normalized time-series SAX significantly outperforms un-normalized ones \cite{Zhang2015}. Therefore it is a built-in requirement of SAX to first normalize the time-series using z-score transformation. Fortunately, our SAX implementation\footnote{https://github.com/zangsir/saxpy/blob/master/saxpyFast.py} also has a built-in remedy for this problem: when the standard deviation of a time-series subsequence is less than a pre-set threshold (a very small number), all of its segments will be assigned the same symbol. 



%Distance measure
\section{Distance measure} \label{sec:dist}
(1) \textbf{Euclidean distance}. The Euclidean distance is one the most widely used and computationally economic distance measures \cite{Lin2007}, defined as follows on the \textit{n}-dimensional Euclidean space for a time-series of length \textit{n}:

\begin{equation}
d(p,q) = d(q,p) = \sqrt{\sum_{i=1}^{n} (q_i - p_i)^2} 
\end{equation}


(2) \textbf{DTW distance}. In time-series analysis, dynamic time warping (DTW) is an algorithm for measuring similarity between two temporal sequences which may vary in time or speed (\figref{fig:dtw}). The DTW distance between two time series is computed with dynamic programming, by recursively solving the optimal alignment between two sequences in subproblems, and return the shortest distance between the two (i.e., best alignment) time series. In particular, the optimal path is the path that minimizes the warping cost:

\begin{equation}
DTW(Q,C)=min\bigg\{\sqrt{\sum_{k=1}^{K} (w_k)}
\end{equation}

where $w_k$ is the matrix element $(i,j)_k$ that also belongs to k-th element of a warping path W, a contiguous set of matrix elements that represent a mapping between two time-series objects Q and C.

This warping path can be found using standard dynamic programming to evaluate the following recurrence.


\begin{equation}
\gamma (i, j) = d(q_i, c_j) + min\bigg\{\gamma(i-1,j-1), \gamma(i-1, j), \gamma(i,j-1)\bigg\}
\end{equation}

where d(i,j) is the distance found in the current cell, and $\gamma$(i,j) is the cumulative distance of d(i,j) and the minimum cumulative distances from the three adjacent cells.


To make the computation tractable and to prevent pathological warping, many constraints have been proposed to impose upon the possible warping window. One such window is shown in green in \figref{fig:dtw}. 


%%%%%%%%%%%%%%a figure
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.7]{dtw.png}}}
 \caption{Euclidean distance vs. Dynamic Time Warping: example (adapted from \cite{Rakthanmanon2012})}
 \label{fig:dtw}
\end{figure}
%%%%%%%%%%%%

In practice, since DTW has a time complexity of \textit{O($n^2$)}, where \textit{n} is the length of the time-series, various lower-bounding techniques are proposed to speed up DTW distance computation in a large database. The LB\_Keogh lower bounding technique \cite{Keogh2002}, for example, speeds up the computation by first taking an approximated distance between the time-series objects that is both fast to compute and lower bounds the true distance. It would go on to compute the real DTW distance only if this distance turns out to be smaller than the best-so-far, since otherwise there is no way that the true distance is smaller than the best-so-far. This makes DTW essentially an \textit{O($n$)} algorithm as we rarely have to do a full DTW calculation. The general approach is illustrated in \figref{fig:lbk}. This approach can be used in many applications that require DTW, such as exact motif search (see discussions below) and k-means clustering with DTW, where for each data point one needs to find its closest centroid. 


%a figure
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.5]{lbk.png}}}
 \caption{An algorithm that uses a lower bounding distance measure to speed up the sequential scan search for the query Q (adapted from \cite{Ratanamahatana2004})}
 \label{fig:lbk}
\end{figure}

In the meantime, it is worth noting that the DTW distance, similar to Euclidean distance, is not immune to the biases existing in time-series data. For example, \cite{Batista2011} has shown that there exists a tendency for a high complexity time-series TS1 (higher degree of micro level variations) to obtain a high similarity score with a low complexity time-series TS3, when in actuality, TS1 is obviously more similar to another high-complexity time-series TS2 (i.e., dist(TS1,TS2) \textless dist(TS1,TS3), where dist() is the distance function between the two time series). An illustration of this phenomenon is seen in \figref{fig:invar} \cite{Gulati2015a}. \figref{fig:invar} shows three time series P1, P2, and P3, pitch contours of three melodic phrases. Acoustically, P1 and P2 are the occurrences of the same characteristic base phrase and both are musically dissimilar to P3. However, using the best performing variant of the similarity measure in \cite{Gulati2015a}, the algorithm obtains a higher similarity score between the pairs (P1, P3 ) and (P2, P3 ) compared to the score between the pair (P1, P2 ). The same bias is found to apply to DTW distance. Therefore, if such problem is present, we must resort to using a complexity-invariant distance (CID) measure as exemplified by \cite{Batista2011}.




(3) \textbf{MINDIST distance function. }The MINDIST function is a distance measure defined for the SAX representation of the time series, which, crucially, have been proved to lower bound the true distances of original data \cite{Lin2003}. It returns the minimum distance computed between two strings by building on the PAA representation distance function and substituting the distance computation with a subroutine of \texttt{dist()} function:




\begin{equation}
MINDIST(Q,C)= \sqrt{\frac{n}{w}} \sqrt{\sum_{i=1}^{w} dist(q_i , c_i)^2} 
\end{equation}



%a figure
\begin{figure}
 \centerline{\framebox{
 \includegraphics[scale=0.4]{invar.png}}}
 \caption{Pitch contours of three melodic phrases (p1, p2, p3). p1 and p2 are the occurrences of the same characteristic phrase and both are musically dissimilar to p3 (top pink). (adpated from \cite{Gulati2015a})}
 \label{fig:invar}
\end{figure}

The \texttt{dist()} function can be implemented by searching over a lookup table (for details see \cite{Lin2003}). The lower bounding property is an important heuristic for pruning sub-optimal candidate when finding the minimum distance: to avoid expensive computational cost of computing the true distances over a large number of time series, we can first use a SAX approximation to the original time series and compute the MINDIST distance matrix. Since the MINDIST is proved to lower bound the true distance, then we can prune off those whose MINDIST distance is greater than the best-so-far, since there is no way their true distances would be less than the best minimum distance so far. 















\newpage

\chapter{Data mining Mandarin tones using time-series mining techniques}
\section{Overview}
There are many techniques proposed for the data mining of time-series data. These include the choices on time-series representation, distance computation, normalization techniques (temporal and pitch), and time-series data mining and pattern discovery algorithms. However, before we make any particular choices, we need to consider the many features that distinguish one type of time-series data in domain $A$ from another type in domain $B$, in terms of the local and global characteristics of the time-series data in question, and the meanings they map to\footnote{For example, the structure, noise level, periodicity, and complexity of financial, weather, musical, and speech time-series may vary greatly, and the time-series similarity measures meaningful for one domain may not apply to another.}. In an important meta paper, Keogh et al \cite{Keoghbench2002} pointed out:

\begin{quotation}
...the unique structure of time series means that most classic machine learning algorithms do not work well for time series. In particular the high dimensionality, very high feature correlation, and the (typically) large amount of noise that characterize time-series data have been viewed as an interesting research challenge. Most of the contributions focus on providing a new similarity measure as a subroutine to an existing classification or clustering algorithm...
\end{quotation}

Therefore, the key to successful SPM lies in optimizing the methodological choices for computing similarity in the speech prosody time-series domain\footnote{In this dissertation we will refer to speech prosody and tone as our target research objects for two reasons. First, despite our focus on tone data, our methods should be generalizable for other speech prosody analysis tasks. Second, we also deal with tone n-grams, which contain data from both local and global speech prosody phenomena. }
. The optimization is achieved by maximizing efficiency (which is crucial in mining massive data sets in terms of the tractability of the algorithm) while preserving the most meaningful information for the prosody domain. In short, the goal of the similarity computation is: how can we efficiently compute meaningful similarity scores and extract similar patterns between pairs of speech prosody (tone) time-series found in a large database?

%For example, in the domain of MIR, \cite{Gulati2015} performed a comparative evaluation of methodologies for computing similarity between short-time melodic fragments of audio recordings of Indian art music. In this paper, Gulati et al. experimented with 560 different combinations of procedures and parameter values, including the sampling rate of the melody representation, pitch quantization levels, normalization techniques and distance measures. The results indicate that melodic fragment similarity is particularly sensitive to distance measures and normalization techniques, while the sampling rate plays a less important role. 

In this chapter we propose several dimensions of experimentation that enables us to develop the best combination of core methodologies to efficiently extract meaningful patterns from speech prosody data. First we discuss relevant previous works on mining $f_0$ data in the domain of Music Information Retrieval. Then we carry out time-series data mining experiments to evaluate the set of representations and distance measures considered in the last chapter.

The result of this chapter is a set of fundamental methodologies for computing speech prosody time-series similarity. They are important in their own right, as well as in various time-series mining tasks carried out in the rest of this dissertation.

\section{Related work}
There has been limited amount of previous works on $f_0$ pattern data mining, including MIR $f_0$ melodic pattern mining, and corpus based speech intonation research. 

\cite{Gulati2014} mined a database of melodic contour patterns in Indian Art Music. Due to its astronomical size (over 14 trillion pairs of distance computation), various techniques are used to speed up the computation, including lower bounding in DTW distance computation \cite{Keogh2002} and early abandoning techniques for distance computation \cite{Rakthanmanon2012}. The goal is to discover highly similar melodic time-series patterns that frequently occur in the collection (motifs) in an unsupervised manner, and the result is evaluated using the query-by-content paradigm (in which a seed query pattern is provided and top-K similar patterns are returned). The meaningfulness of the discovered pattern is then assessed by experts of Indian music.  


\cite{Gulati2015} experimented with 560 different combinations of procedures and parameter values (including the sampling rate of the melody representation, pitch quantization levels, normalization techniques and distance measures) in a large-scale evaluation for the similarity computation in MIR domain. The results showed that melodic fragment similarity is particularly sensitive to distance measures and normalization techniques, while sampling rate plays a less important role. 

\cite{Valero-Mas2015} experimented with the SAX representation for the computation of $f_0$ contour similarity from music audio signals in a Query-By-Humming (QBH) task\footnote{In a query by humming task, a user hums a section of the melody of a desired song to search for the song from a database of music recordings.} in MIR. Results suggest that SAX does not perform well for music time-series data in the context of QBH. The authors attribute this to the fact that the SAX representation loses information important in music melodic retrieval through its dimensionality reduction process. 


To the best of our knowledge, the only work that attempted at data mining of speech prosody is \cite{Raskinis}'s work on clustering intonation patterns in Lithuanian (although it did not explicitly employ any time-series data mining techniques). While this work examined the use of a number of distance measures (mainly Euclidean vs. DTW), it is an early-stage research and without clear conclusions regarding either the effectiveness of the discussed methods or the significance of the patterns discovered.






\section{Data sets}
In this chapter, we perform time-series data mining experiments using two data sets discussed previously: (1) Xu 1999 \cite{Xu1999} Read Speech Data set described in Section \ref{sec:rsd}; (2) CMN (Mandarin Chinese Phonetic Segmentation and Tone (MCPST)) data set by LDC, described in Section \ref{sec:manthaidata}. We use the CMN-UVnN30p data set, as listed in Table \ref{tab:datasets}.

%we should include a table with statistics of these data sets.







\section{Classification of Mandarin tone time-series}
\subsection{Experimental setup}


\subsubsection{Classification experiments}

For classification, we use $k$-nearest neighbor (KNN) and Decision Tree, both of which are widely used in time-series classification\footnote{In practice, KNN is an expensive algorithm that scale more poorly than decision trees.}\cite{Lin2007}. We report only accuracy on the classification experiments considering the balanced nature of the data set. All classification experiments are done with 10-fold cross validation with randomized split of data.

In the KNN classification of the Read speech data set, due to the high time complexity of KNN, we need to consider the optimal split of training and testing data size that reduces the time complexity of the algorithm. In addition, following the convention of using a smaller training size in time-series data mining literature, we carry out the classification experiments using 1600 samples for testing and 320 samples for training (the total size of the data set being 1920 samples of tone contour time-series). 

To optimize SAX parameters, for $w$, we search from 6 up to $2n/3$ (n is the length of the time series); for $a$, we search each value between 6 and 20. It is observed that a lower value for $a$ results in poor classification results (since the MINDIST distance measure is defined as a sum of pairwise letter distance between two strings). Figure \ref{fig:3dsax} shows how classification accuracy varies depending on $w$ and $a$.
%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\small
 \centerline{
 \includegraphics[scale=0.55]{waac.pdf}}
 \caption{KNN classification accuracy depending on $w,a$} 
 \label{fig:3dsax}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In the Decision Tree classification, we use the standard 90-10 split of the training-testing data.

Because of the poor scalability of KNN algorithm, it is impractical to use it on larger data sets. Therefore, we perform only Decision Tree classification experiments on our large data set (CMN data set). The size of the CMN data set is on the scale of 100,000 syllables. We randomly sample 10,000 for each classification experiment. 


\subsubsection{A note on SAX implementation}
While the original SAX was implemented in Matlab\footnote{https://cs.gmu.edu/~jessica/sax.htm}, we have adopted the SAX Python implementation in the Library \texttt{saxpy}\footnote{https://github.com/nphoff/saxpy}. Consistent with the definition of symbolic representation, \texttt{saxpy} internally uses strings to represent alphabet letters and outputs literal SAX strings. While this is an intuitive choice that doesn't affect the correctness of the implementation, we observe that MINDIST distance computation implemented with Python string type is very slow when used with high time-complexity algorithms such as KNN\footnote{With a small data set of 2000 time series, it would take more than one hour to run KNN on a Intel core-i5 laptop with 16GB RAM.}. Therefore, inspired by the original Matlab implementation, we have re-implemented \texttt{saxpy} using internal float representation in Python \texttt{numpy} module while taking advantage of \texttt{numpy}'s fast, Matlab-fashion matrix operations to greatly improve the speed of the code. The result is \texttt{saxpyFast} \footnote{https://github.com/zangsir/saxpy/blob/master/saxpyFast.py} and is estimated to be 4-5 times faster than the original \texttt{saxpy}. This improvement makes running many time-series mining tasks efficient (especially those that depend on MINDIST distance computation), including KNN, clustering, and QBC.




\subsection{Results}




\begin{table*}[t]

\small
\caption{K-Nearest Neighbor tone classification results, with 10-fold cross validation (CR=compression rate, EU=Euclidean Distance, SAX parameters (w,a)=(20,17), test\_size=1600, training\_size=320)} \label{tab:res}
 \begin{center}
 \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}

\hline
%Data & Feature & \multicolumn{3}{|c|}{NB} & \multicolumn{3}{|c|}{KNN} & \multicolumn{3}{|c|}{SVM}\\  
config & \multicolumn{4}{|c|}{SAX-MINDIST}	&	\multicolumn{1}{|c|}{BK}  &	\multicolumn{1}{|c|}{EU}	& \multicolumn{1}{|c|}{DTW}	&	\multicolumn{1}{|c|}{D1} & \multicolumn{1}{|c|}{qTA}		& \multicolumn{1}{|c|}{polyN}	\\
\hline
 %&  & Precision & Recall & F1 & Precision & Recall & F1 & Precision & Recall & F1\\

\hline
K	& 1 &	3 & 5 & 7 & 	1  & 	1 & 	 1	 & 	1  & 		1 & 	 	1  \\
\hline
dimension & 20 & 20 & 20 & 20 & 30 & 30 & 30 & 30 & 3 & 4\\
\hline
accuracy	& 0.81	& 	0.87	& 	0.87	& 	0.89	& 	0.92	& 	0.92		& 	0.93		& 	0.93			& 	0.73			& 0.70	 \\
\hline
%precision		& 0.81	& 	0.87	& 	0.87	& 	0.89	& 	0.92	& 	0.92			& 	0.92		& 	0.93					& 0.72			& 0.71	\\

%\hline
%recall	& 	0.80		& 0.87	& 	0.87		& 0.89	& 	0.93				& 0.92		& 	0.93		& 	0.93				& 0.72			& 0.71		\\

%\hline
%F1	& 0.80 & 0.87		& 0.87	& 	0.89	& 	0.93		& 0.92			& 	0.93		& 	0.93		& 	0.72			& 0.71	\\



\hline
CR	& 	0.66	& 	0.66	& 	0.66	& 	0.66	& 	 	1	& 	1	& 	1	& 	1	& 	 0.1	& 0.13	\\ 





 \hline
 \end{tabular}



\end{center}
\end{table*}

%classification
\subsubsection{Read Speech Dataset}
First we report time-series classification results on the Read dataset using K-Nearest Neighbor (KNN) and Decision Trees (J48 as implemented in Weka). These classification results are presented in Table \ref{tab:res} and Table \ref{tab:j48}, respectively. First, we observe that the original $f_0$ (Hertz) representation performs comparably with normalized-Bark and First Derivative (D1) vectors, using Euclidean distance and DTW distance\footnote{The difference between Bark and Cent features is small, so we only report results for Bark.}. All of these achieved above 90\% accuracy and F1 score using $K=1$.  The DTW distance showed slight advantage over Euclidean distance. All of the numeric representations performed comparably when $K$ varies, so only results for $K=1$ are shown. Second, we note that the SAX representation achieved reasonable but lower score (with lower dimensionality, compression rate being 0.66). In particular, it performs worse on $K=1$, and the performance improves significantly when we increase $K$ to 3, 5, and 7. Third, the qTA and polynomial representations achieved significantly lower classification accuracy, at the advantage of having very low dimensionality (compression rate around 0.1). These trends also showed up in the Decision Tree classification, which has comparable classification accuracy with KNN (with lower cost). Overall, we note that SAX shows slight disadvantage in the time-series classification accuracy, while being able to achieve a 0.66 compression rate for time and space complexity. Taking into consideration the results obtained from the CMN data set of spontaneous speech, we attribute the lower performance of SAX in this experiment to the nature of the data set: the clean read speech in this data set is easy for a regular classifier to learn so that they already saturated their performance at greater than 90\% accuracy. Meanwhile, the advantage of SAX in noise reduction did not show in this clean data.

\begin{table}
\caption{Decision tree classification results in Read speech data set (with 10-fold cross validation), CR=compression rate} 
\small

 \begin{center}
 \begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 TSR & SAX	 & BK	 & Hertz	 & D1 & 	qTA	 & poly \\
  \hline
  accuracy & 	0.88 & 	0.93 & 	0.92	 & 0.93 & 	0.83 & 	0.79\\
  \hline
  dimension & 12 & 30 & 30 & 29 & 3 & 4\\
  %precision & 	0.88 & 	0.91 & 	0.92 & 	0.93 & 	0.84 & 	0.80\\
  %\hline
  %recall & 	0.88 & 	0.93 & 	0.92 & 	0.93 & 	0.83 & 	0.81\\
  \hline
  %f1 & 	0.88 & 		0.93 & 		0.92 & 		0.93 & 		0.83 & 		0.80\\
  CR & 0.66 & 1 & 1 & 1 & 0.1 & 0.13 \\
  \hline
  
  
  
 \end{tabular}

\label{tab:j48}
\end{center}
\end{table}


\subsubsection{CMN data set}

In this section, our primary goal is to see if SAX can show its advantage in time-series classification tasks using a much larger spontaneous speech data set comparing to the previous small-scale experiments on the Read data set. We have several considerations before we proceed to this experiment. First, we have seen (in both supervised setting above and unsupervised setting below) that qTA and polynomial representations of tones are ineffective for distinguishing tone categories. They are very low dimensional and thus lose too much information. Therefore we don't include them in this round of evaluation. Second, as discussed above, we are only conducting experiments using the Decision Tree algorithm due to the poor scalability of KNN for large data sets.

We report the classification accuracy on the CMN data set in Table \ref{tab:j48cmn}. Here we are showing results using SAX with parameters $w=12, a=7$. First, in this much harder data set, even though absolute classification accuracy is low comparing to the Read data set, we observe that they are still much higher than chance. These results are in line with the previous works using large data sets of spontaneous speech\cite{Surendran2007}. Second, we note that the SAX shows its advantage in this classification task, outperforming both original Hertz based time-series and D1 based representation (both normalized across speakers) with much lower dimensions. We conclude that SAX is an effective representation that performs dimensionality reduction and improves classification accuracy comparing to raw time-series. This is also in line with previous works showing the advantage of SAX acting as a noise-reduction algorithm \cite{Lin2003}. Finally, comparing to other classification algorithms such as SVM and Random Forest (which are highly effective algorithms for other types of non-time-series data), we observe that Decision Tree always yields the best classification accuracy in this task. This is consistent with the time-series data mining literature's assertion of the special properties of time-series data in selecting machine learning algorithms, and that KNN and Decision Tree are among the most competitive classification algorithms for time-series data\cite{Lin2003}.

\begin{table}[h]
\caption{Decision tree classification results in CMN data set (with 10-fold cross validation), CR=compression rate} \label{tab:j48cmn}
\small

 \begin{center}
 \begin{tabular}{|c|c|c|c|c|}
\hline
 TSR & SAX	 & Hertz	 & BK	 & D1 \\
  \hline
  accuracy(\%) & 59.97 &	57.51 & 58.83 & 53.95\\
\hline
dimension & 12 & 30 & 30 & 29 \\
  \hline

  CR & 0.4 & 1 & 1 & 1 \\
  \hline
  
  
  
 \end{tabular}


\end{center}
\end{table}





\section{Clustering of Mandarin tone time-series}
\subsection{Experimental setup}

\subsubsection{Clustering experiments}
For clustering experiments we use the k-means clustering algorithm, where accuracy is computed against true tone labels for each instance. The clustering accuracy is measured by comparing the assigned cluster labels to the true tone labels of each time series. We then construct a confusion matrix showing the true labels against the predicted labels of the cluster assignments, where the predicted label is the most predominant label (i.e., the tone category with the most number of
instances among all tones assigned that label) within that cluster. If the the predominant label is not unique across clusters, then we assign a low accuracy value of 0.1 to represent the accuracy is undecidable. 

\subsubsection{Alternative evaluation on the CMN data}
This approach of evaluating accuracy based on majority class label is similar to the purity evaluation metric of clustering, as seen in contexts such as information retrieval \footnote{https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html}. However, one shortcoming of this approach is that when multiple clusters have the same majority label, it is impossible for each cluster to have a unique class label. Such scenario is highly likely to occur in larger and more noisy data sets such as the CMN data set. In such cases, we are nevertheless still interested in evaluating whether one method is doing better than others. For this reason, we propose to use a more robust evaluation metric called Mean Average Precision (MAP) within an alternative time-series mining task called Query by Content (QBC). Also related to information retrieval, we formulate the QBC task as retrieving time-series data points of relevant tones given a specific query of a tone object, and we evaluate the result on how much of the top $k$ retrieved tones are truly relevant to the query tone time-series object. We will describe the QBC task in Section \ref{sec:qbc} and use it to evaluate the time-series representations and distance measures in the CMN corpus. The current clustering task is only applied to the Read speech data set. 


% first, let's formalize this evaluation measure (purity?) based on IR book; intrisic
% second, note that this evaluation is not applicable to CMN corpus.


\subsection{Results}
%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\small
 \centerline{
 \includegraphics[scale=0.55]{clustac.pdf}}
 \caption{Average clustering accuracy for 1920 Mandarin tones (\%) from 5 iterations. For numeric representations, Euclidean distance is used by default unless otherwise noted}
 \label{fig:clustac}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%clustering
%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\small
 \centerline{
 \includegraphics[scale=0.6]{imagetot.pdf}}
 \caption{Kmeans clustering objective function by number of iteration. Intra-cluster distance (y axis) is normalized, distance measure noted except for Euclidean. Only polynomial and qTA (overlapped) showed periodic oscillation without a trend to converge.  }
 \label{fig:kmof}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The true utility of the SPM framework lies in detecting patterns in an unsupervised setting. Comparing to classification, SAX shows more distinct advantage in the clustering experiments. In the following discussion, we note that we are able to use a bigger compression rate (comparing to the classification experiments on the same data set) for SAX in the clustering experiments (i.e., smaller word size), at $w=13$, which gives a compression rate of approximately 0.43.  

The clustering accuracy is summarized in Figure \ref{fig:clustac}. We establish a baseline accuracy of 56\% with normalized $f_0$ representation, indicating the difficulty of this task (although this is still well above chance level of 25\% for four tones). Clustering results suggest that (1) The D1 feature significantly outperforms the $f_0$-based features with Euclidean distance; (2) The DTW distance computed with LB\_Keogh heuristic shows its clear advantage with $f_0$ features, although its utility is quite limited in this dataset compared to previous works; (3) it is noteworthy that SAX is in a much lower dimension yet performs comparably with D1; (4) polynomial and qTA model coefficient based features perform below chance in this task, indicating distances in the original space are not preserved in the ultra-low dimensional parameter space. To probe into these behaviors, we plot the k-means objective function against the number of iteration in \figref{fig:kmof}. In particular, the polynomial and qTA parameters show periodic oscillation of intra-cluster distances, lacking a trend to converge. SAX shows quick convergence, ranking among the most effective. 

Overall, in this unsupervised setting, it is noteworthy that DTW is not showing its advantage in computing time-series similarity for the current tone dataset as seen in literature in other domains (see previous discussion in Section \ref{sec:dist}). We are yet to further investigate DTW's utility in the speech prosody domain. 

Finally, we plot distance matrixes of tones in this data set (shown in \figref{fig:saxhc}), which may give us a hint as to why SAX is a more effective representation than the $f_0$ (Hertz) vectors in clustering: In \figref{fig:saxhc} we can clearly see that the lower dimension SAX-MINDIST distance reflects the intrinsic structure of the clusters with lower distances along the diagonal, whereas the distances are all somewhat equalized in the $f_0$ distance matrix. Overall, SAX and its low dimensionality property may act as a noise-reduction mechanism for revealing the internal structure of the data, making it more suitable for speech tasks comparing to MIR tasks.















%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\small
 \centerline{
 \includegraphics[scale=0.4]{matrix-nocl.png}}
 \caption{SAX-MINDIST(left) and $f_0$-Euclidean (right) Distance matrix of 1920 Mandarin tones sorted by tone category. Tones are ordered by tone categories along the x- and y-axis. Origin at top left corner (i.e., on both axis data points are ordered by 480 instances of tone 1, tone 2, tone 3, and tone 4 when moving away from origin). }
 \label{fig:saxhc}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Query by Content} \label{sec:qbc}
%introducing qbc and evaluation with an IR framework. a list of evaluation methods, including MAP score is desired.

\subsection{Experimental setup}
\subsubsection{Query by Content}
Query by Content (QBC) is a commonly used content retrieval task in many domains and data types, such as text\cite{Manning:2008:IIR:1394399}, audio\cite{Gulati2014}, and image retrieval. In our use case, the advantage of using QBC to evaluate our time-series mining techniques is that it always delivers quantified results regardless of its absolute quality, therefore allowing us to compare different methods even when their accuracy values are on the lower side (as discussed above, clustering will not allow us to do that). 

QBC works similarly to classic information retrieval (IR) - where the user supplies some query string and the system attempts to find the most relevant documents given the query. It then presents the results in a ranked list. Top ranked results should be the most relevant, and vice versa. In our case, the users information need is expressed by a specific query tone curve (or more generally, a time-series subsequence), and the goal is to find similar time-series objects in the data base that are in the same category of the query tone curve. This also has the advantage of allowing us to adopt evaluation techniques typically used in IR, which is a well-researched area where the behaviors of evaluation methods are well understood. 



\subsubsection{Evaluation}
In IR research, the basic challenge of evaluation stems from the fact that the system produces ranked results. Precision, recall, and the F measure are set-based measures. They are computed using unordered sets of documents. We need to extend or revise these measures if we are to evaluate the ranked retrieval results that are now standard with search engines. In a ranked retrieval context, appropriate sets of retrieved documents are naturally given by the top $k$ retrieved documents. For each such set, precision and recall values can be plotted to give a precision-recall curve, such as the one shown in Figure \ref{fig:prec-recall}. Precision-recall curves have a distinctive saw-tooth shape: if the $(k+1)^{th}$ document retrieved is nonrelevant then recall is the same as for the top $k$ documents, but precision has dropped. If it is relevant, then both precision and recall increase, and the curve jags up and to the right\cite{Manning:2008:IIR:1394399}. 

%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
 \centerline{
 \includegraphics[scale=0.56]{prec-recall}}
 \caption{Precision recall curve (from \cite{Manning:2008:IIR:1394399}) }
 \label{fig:prec-recall}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		
Based on this understanding, in recent years, one of the most common IR evaluation measures is the Mean Average Precision (MAP), which provides a single-figure measure of quality across recall levels. Among evaluation measures, MAP has been shown to have especially good discrimination and stability. For a single information need, Average Precision is the average of the precision value obtained for the set of top  $k$ documents existing after each relevant document is retrieved, and this value is then averaged over information needs. That is, if the set of relevant documents for an information need $q_j \in Q$ is $\{d_1,
\ldots d_{m_j}\}$ and  $R_{jk}$ is the set of ranked retrieval results from the top result until you get to document $d_k$, then 
\begin{displaymath}
\mbox{MAP}(Q) = \frac{1}{\vert Q\vert} \sum_{j=1}^{\vert Q\vert} \frac{1}{m_j}
\sum_{k=1}^{m_j} \mbox{Precision}(R_{jk})
\end{displaymath}	

When a relevant document is not retrieved at all, the precision value in the above equation is taken to be 0. For a single information need, the average precision approximates the area under the uninterpolated precision-recall curve, and so the MAP is roughly the average area under the precision-recall curve for a set of queries\cite{Manning:2008:IIR:1394399}. 

For our use case, in the above equation, $|Q|$ is the cardinality of the set of tone queries $q_j$; $m_j$ is the total number of relevant tones, i.e., in the same tone category as the query; $R_{jk}$ is basically the set of top ranked $k$ tones, for which we compute their precision. Effectively, this equation is saying we should compute for all values of $k$ from 1 to $m_j$, the precision of the top ranked $k$ results and then average them. Finally, we repeat this for all queries $q_j$ in a set of queries $Q$, and we yet again average the results.

In our evaluation setup, each time we randomly sample $m$ tones to serve as the set of query tones, and we retrieve top $d$ tones to compute the MAP score.

\subsection{Results} \label{sec:qbc-results}
We present the evaluation results of QBC using MAP scores in the CMN corpus in Table \ref{tab:qbc}. The $q$ and $d$ values indicates query and retrieved data sizes (for instance we use a set of 20 queries and for each query we retrieved 100 tones in the first configurations). We can see that across the board (and on average), SAX-MIDNIST does better than Euclidean distance in retrieving relevant tones in a ranked retrieval task. (The ranking is a measure of the quality of time-series representation and their distance measures with regard to the tone category space). This result obtained from the CMN corpus, which is a large spontaneous speech (newscast) data set, is consistent with the results we observed from the Read speech data set in the last chapter in a unsupervised experiment using K-means clustering.

%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}
\small
 \begin{center}
 \begin{tabular}{|c||c|c|}
\hline
evaluation/iteration & SAX-MINDIST & EUCLIDEAN\\
\hline
MAP(q=20,d=100) & 0.414 & 0.348\\

& 0.404 & 0.429\\

& 0.438 & 0.390\\

& 0.458 & 0.362\\
\hline
MAP(q=50,d=200)
 & 0.412 & 0.404\\

 & 0.439 & 0.415\\

 & 0.452 & 0.466\\
 & 0.396 & 0.401\\

 & 0.438 & 0.418\\

 & 0.499 & 0.400\\

  \hline
  
  
 \end{tabular}

\caption{QBC results MAP scores, data: CMN corpus, q=query size, d=retrieved size} \label{tab:qbc}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Discussion}

In the above experiments we showed the potential of how the tone learning task (and Speech Prosody Mining, SPM) could benefit from time-series mining techniques, such as low-dimension symbolic representation of time-series that can exploit computational gains from the data compression as well as the availability of efficient string matching algorithms\cite{Ganguli15} (whose utility in SPM is our future research task). 

We observed one paradox in our evaluation of SAX in the Read speech data set, between supervised and unsupervised learning: the latter is able to achieve better performance (comparing to other time-series representations within the same experiments) with a greater compression rate (0.4) of SAX, whereas the former performs relatively worse with a higher compression rate (0.7) while requiring a larger value of $k$ ($k$=7 is with SAX performs comparably with $k$=1 for other representations). We attribute this difference to the nature of the two algorithms, KNN classification and k-means clustering. It is possible that in SAX-MINDIST space, data points have lower distances to cluster centers, but higher distances to its nearest $k$ neighbors within the same tone category (that is, comparing to Euclidean distance). However, this paradox no long exists in the large spontaneous speech data set using the decision tree classifier, where SAX achieved superior performance in both supervised and unsupervised tone learning tasks.


Meanwhile, a property of SAX is that each segment used to represent the original time-series must be of the same length. This might not be an ideal situation in many applications (exemplified in \cite{Ganguli15}) where variable lengths segments are desired. The complexity of converting to such an variable-length representation may be greater than the original SAX, as one must design some criteria to decide whether the next frame of audio samples belong to the current segment or it should be the start of a new segment. One intuitive strategy is inactivity detection (i.e., flat period can be represented with a single symbol). Moreover, the utility and implications of symbolic representations (equal- or variable-length) for tones and intonation is also of great theoretical interest to phonology \footnote{Personally communication with scholars in phonology.}. These research directions are outside the scope of the current work and we will leave then for future research.
























\newpage

\part{Analyzing tone n-grams}
\newpage
%this should be an overview of both tasks to replace this content.
\chapter{Overview}
One of the fundamental problems in tone research is the variability of tone contour shapes in spontaneous speech production. Given a particular tone category and a template contour, we usually observe many different realizations of that template in real speech data. In the mean time, the specific mechanisms that give rise to these variabilities are not completely well understood. 

In Chapter 2 we have seen that the tonal context is a strong factor in explaining the variability of tones. Motivated by this phenomenon, in this part of the dissertation we focus on the analysis of tone N-grams - a sequence of N tones (where $N=1,2,3$) that occur consecutively in natural speech\footnote{The N-gram modeling is a well known technique in language modeling (LM) in text-domain natural language processing (NLP) with a wide varieties of applications. Here we borrow the concept to capture the contextual factor of tones. }. 

In order to efficiently mine tone N-gram data in a large corpus, we need to first develop computational methods targeted at analyzing speech prosody domain time-series patterns. In Chapter \ref{motif-disc}, we investigate the problem of finding previously unknown patterns (motif discovery) in this domain: how can we modify existing motif discovery algorithm to prune spurious motifs and retrieve real meaningful tone N-gram motifs? In Chapter \ref{network} we look at the predicability of the tone contour shapes: how well can we predict the (highly variable) tone N-gram contour shape types of real spontaneous speech, using features from a variety of domains with linguistic knowledge? In both chapters we will develop creative solutions to investigate these problems involving motif discovery, network (graph) analysis, machine learning, and information retrieval.
 







\newpage

%%% chap: ngrams MK_DB
\chapter{From contours to categories: Motif discovery of tone n-grams patterns} \label{motif-disc}
Motif discovery is a well-researched task in time-series data mining\cite{Mueen2009, Chiu2003a}. It aims to find previously unknown patterns that repeat across different parts of the time-series subsequences in a long time-series. These patterns are highly similar to each other (within a range $R$ of each other according to a specified distance measure) and therefore are candidates of patterns that are significant and meaningful and worth further investigation. 

In the context of speech prosody data mining, we perform motif and pattern discovery as a main step in the analysis and understanding of the speech prosody time-series subsequences in a corpus. Here we state the most fundamental hypothesis of of the motif discovery in SPM: Meaningful events in speech prosody tend to occur in a repeated pattern more than expected by chance. Therefore, by discovering previously unknown patterns that are highly similar to each other across the speech prosody time-series corpus, within and between speakers, the motif discovery allows us to zoom in on interesting patterns within the data that merits further assessment using linguistic knowledge.

There are two types of motif discovery tasks in the context of SPM, and in particular, for the study of the property of tones. The first is motif discovery on a database of pre-extracted time-series subsequences as input. The time-series subsequences correspond to tone N-grams, where $N = 1, 2, 3$.This allows us to discover only the time-series subsequence motifs that are N-syllable long and whose boundaries align with the syllable boundaries. We denote this tone \textit{N-grams motif discovery}. Second, we can perform motif discovery taking a long time-series as input. In this mode, the long time-series may be an entire recording of newscast speech from our corpus. It can contain a single speaker or multiple speakers (in which case the pitch values are normalized by speaker). In this case, the motif discovery algorithm extracts time-series subsequences on the fly with a user-specified window length $m$ and a hop size $h$ of 1 sample (i.e., each time the sliding window moves forward one sample, generating adjacent subsequences overlapping $m-1$ samples. Therefore, in this mode, we can only discovery motifs of length $m$ samples, instead of the integer multiple of syllables (i.e., $N$ syllables, or N-grams). If we use downsampled equal-length representation of syllables, we can still get motifs with window length equal to N syllables, however, there is no guarantee that their boundaries align with syllable boundaries. Therefore we denote this mode as \textit{any-length motif discovery}. 


Any-length motif discovery is more exhaustive but due to its massive scale and time complexity, it is hard to experiment with and control the outcome. Therefore, in this dissertation we focus on the tone N-grams time-series motif discovery using the MK algorithm for exact discovery of time-series motifs (\cite{Mueen2009}). In contrast to the Long Time-Series (LTS) version of motif discovery, the N-grams motif discovery is concerned with discovering motifs from only time-series subsequences that correspond to tone N-grams, i.e., a unit of N syllables extracted from spontaneous speech, where N=1,2,3 (whereas in the LTS mode, the motif length is only defined in terms of number of time-series data points or samples, but not necessarily correspond to N syllables, where N is a positive integer).  
 
%what is the different purpose of this chapter vs. the next? probably at the core this chapter focuses on the ngram motifs. If we want to do n-gram motifs in the subsequence mode, it will be essentially the same as mk_db and it is not worth doing it. so this chapter is about N-gram motifs, the next is about any-length motifs. (length in terms of units of syllable).




\section{Motif discovery: problem definition and algorithms}
%overview: exact; probablistic; DTW
Motif discovery is the discovery of previously unknown but repeated, highly similar patterns in a time-series database. There are two basic types of motif discovery algorithms: exact algorithms\cite{Mueen2009} vs. probabilistic algorithms \cite{Chiu2003a}. Exact algorithms are guaranteed to find all motifs as specified by the user with no uncertainty. In contrast, probabilistic algorithms are guaranteed to find motifs with a probability of, for example, 95\%. While exact algorithms is often more desirable, probabilistic algorithms remain useful for very large data sets of time-series databases. 


\subsection{Problem definition} \label{probdef}

Here we give a formal definition of the concepts used in motif discovery for clarity\cite{Lin2003}, and we comment on the necessity and utility of each definition in plain English.

\textbf{Definition 1}. Time Series: A time series $T = t_0,...,t_m$ is an ordered set of m real-valued variables.


\textbf{Definition 2}. Subsequence: Given a time series $T$ of length $m$, a subsequence $C$ of $T$ is a sampling of length n\textless m of contiguous position from $T$, that is, $C = t_p,...,t_{p+n-1}$ for $1\leq p \leq m - n + 1$. This definition is equivalent with the way we have described subsequences above.

\textbf{Definition 3}. Match: Given a positive real number $R$ (called range) and a time series $T$ containing a subsequence $C$ beginning at position $p$ and a subsequence $M$ beginning at $q$, if $D(C, M)\leq R$, then $M$ is called a matching subsequence of $C$. This states that given a parameter of distance $R$, a match is defined as all subsequences within distance of $R$ from a seed pattern (motif). In other words, $R$ is a similarity threshold for the grouping of motifs.


\textbf{Definition 4}. Trivial Match: Given a time series $T$, containing a subsequence $C$ beginning at position $p$ and a matching subsequence $M$ beginning at $q$, we say that $M$ is a trivial match to $C$ if either $p = q$ or there does not exist a subsequence $M'$ beginning at $q'$ such that $D(C, M') \textgreater R$, and either $q< q'< p$ or $p< q'< q$. This definition is necessary because if subsequences of length $n$ is extracted with a hop size of $k$ samples (the distance between the two consecutive sliding windows), and if $k$ is small enough, then the most similar match to a subsequence $A$ is the subsequences starting $i*k$ samples following $A[0]$ ($i$ is a small integer), with a significant overlap with $A$ itself. We therefore need to rule out these trivial matches as it essentially is a match between $A$ and $A$ itself. 

\textbf{Definition 5}. K-Motifs: Given a time series $T$, a subsequence length $n$ and a range $R$, the most significant motif in $T$ (called thereafter 1-Motif) is the subsequence C1 that has the highest count of non-trivial matches (ties are broken by choosing the motif whose matches have the lower variance). The $K^{th}$ most significant motif in $T$ (called thereafter K-Motif) is the subsequence $C_K$ that has the highest count of non-trivial matches, and satisfies $D(C_K, C_i)>2R$, for all $1\leq i < K $. This is used to rank the significance of the motifs based on the frequency of the occurrence of a motif in the data. Note that this definition (the last part) forces the set of subsequences in each motif to be mutually exclusive. This is important because otherwise the two motifs might share the majority of their elements, and thus be essentially the same. Figure \ref{fig:kmotif} illustrates the need for this condition on a simple set of time series projected onto 2-D space\cite{Lin2002}.


%a figure
\begin{figure}
 \centerline{
 \includegraphics[scale=0.5]{def.png}}
 \caption{2-D space projection of illustration of K-motifs (adapted from \cite{Lin2002})}
 \label{fig:kmotif}
\end{figure}



\subsection{General algorithm} \label{genalgo}

The general obvious algorithm of finding the 1-Motif is to use brute force distance computation and constantly updating the 1-Motif candidate, i.e., the motif with the largest count of time-series data points. Figure \ref{fig:obvalgo} shows the high level code for this algorithm. A generalization to the K-Motif discovery is obvious and omitted here. Note that the motif discovery algorithm takes three inputs: the time-series data (stored as one long sequence or subsequences); $n$, the length of the desired motif; and $R$, the similarity/distance threshold for motifs. This algorithm is an $O(m^2)$ algorithm where $m$ is the length of the entire time-series sequence (i.e., when stored as one long sequence).


%a figure
\begin{figure}
 \centerline{
 \includegraphics[scale=0.4]{obvalgo.png}}
 \caption{Obvious brute force algorithm for motif discovery of 1-Motif (adapted from \cite{Lin2003})}
 \label{fig:obvalgo}
\end{figure}
%%%%%%%%%%%%%%%



\subsection{MK exact discovery of time-series motifs}
%db vs subsequence version: also ngrams vs. others
The MK exact motif discovery \cite{Mueen2009} is the first tractable algorithm for the exact discovery of time-series motifs. Fundamentally it leverages the power of pruning the search space by projecting higher dimension time-series data points onto the one dimensional space. By iteratively selecting reference points and compute a ranking of all other time-series objects to the reference points in 1-dimensional space, the algorithm is a vast improvement over brute force algorithm in terms of time complexity, and it is an exact algorithm, guaranteed to find the motifs with a probability of 1. Figure \ref{fig:MK} shows the MK algorithm.
%a figure
\begin{figure}
 \centerline{
 \includegraphics[scale=0.4]{MK.png}}
 \caption{MK algorithm for motif discovery of 1-Motif (adapted from \cite{Mueen2009})}
 \label{fig:MK}
\end{figure}
%%%%%%%%%%%%%%


\subsection{Probabilistic discovery of time-series motifs}
The probabilistic motif discovery algorithm \cite{Chiu2003a} is guaranteed to find motifs with a probability close to 1. Inspired by algorithms for DNA motif mining from the bioinformatics community, this algorithm leverages symbolic representation of time-series to randomly hash partially masked time-series symbols into buckets in order to speed up processing time. The results of the hashing are logged into a collision table marking the indexes of time-series subsequences. This process is called random projection. After a large number of times of running random projection, the cell in the collision table with a higher value indicates the two masked subsequences have been hashed to the same bucket many times and therefore are likely to be a match (motif). This heuristic greatly speeds up the high time complexity required by the brute force algorithm. In practice, probabilistic discovery is not exact since its probability of finding true motif is less than 1. However, it is still useful in mining truly massive data sets where the exact algorithm is too slow.

Considering the size of our data set is not astronomical, we choose MK to be our base algorithm for motif discovery.


\subsection{DTW motif discovery}
Both MK and Chiu algorithms described in previous chapters depend on Euclidean distance computation at its base. Despite its efficiency, in some domains Euclidean distance is not sufficient to capturing the meaningful similarity between time-series objects, where Dynamic Time Warping (DTW) distances is necessary. One example is \cite{Gulati2014}. However, in Part III we have shown that this is not the case in speech prosody domain.



\section{Research questions}
MK is an algorithm for efficient discovery of time-series motifs. Running MK database version off-the-shelf, however, only gives us top motif pairs that looks suspicious (Figure \ref{fig:motif_pairs_sus}) and uninteresting. This indicates the challenges we face for the discovery of meaningful patterns from speech prosody data.

%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{motif_pairs_sus.pdf}}
 \caption{Top 5 motif pairs (spurious) from the CMN corpus (tone bigrams 100-point dataset), with their ranking, distance and tone categories noted}
  \label{fig:motif_pairs_sus}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

One of the primary goals of this thesis is to identify the unique challenges of time-series data mining in the speech prosody domain and develop appropriate methods to address those challenges. In the n-grams motif discovery task, we define our research questions as follows:

\begin{enumerate}
\item What are the unique properties of speech prosody time-series data that poses challenge for motif discovery in this domain?
\item How can we propose methods (or modify existing algorithms) to solve these problems in order to find meaningful motifs?
\item How can we analyze the tone N-gram patterns to extract meaningful insights and knowledge? 
\end{enumerate}

In this chapter we will address the first two questions in developing effective methods for speech prosody motif discovery of tone n-grams. The final question requires more domain expertise and its solution can vary significantly depending on the specific type of research being carried out. Therefore, we defer the analysis and extraction of meaningful knowledge from tone N-gram patterns to the next chapter and we will develop new methods well suited to this problem.



\section{Properties of speech prosody time-series motifs}
Time-series data exists in many domains. This encompasses a variety of data sources where time-series data can come from. For instance, time-series data from a sensor that records the behavior of insects or from EKG machine recording signals from the heart can have very different properties than data from the domain of music information retrieval (MIR) or speech prosody mining (SPM). In the time-series mining community, the last decade has seen the introduction of hundreds of techniques designed to efficiently measure the similarity between time series with invariance to properties such as (or the various combinations of) the distortions of warping \cite{Keogh2009}, uniform scaling\cite{Yankov2007}, offset\cite{Faloutsos:1994:FSM:191843.191925}, amplitude scaling,phase  \cite{Keogh2009}, occlusions, uncertainty and wandering baseline.

In this chapter, we discuss two particular types of properties of the speech prosody time-series data: rarity of events, and complexity. These two properties are key contributing factors that distinguish the mining of speech prosody time-series data from the type of time-series data that the majority of time-series data mining researchers are concerned with (such as weather, sensor, etc. data). Investigating the unique properties of the speech prosody TS is an important step in both understanding the characteristics of speech data TS, and in effective TS data mining and motif discovery by both adapting existing algorithms and developing new methods.


\subsection{Rarity of events}
In time-series data mining community, motif discovery is most commonly defined as finding the most similar pair of time-series subsequences across the database. In fact, the default version of the MK motif discovery algorithm only returns a top pair of motifs that has the lowest distance between them under some distance measure while ignoring all other possibly interesting but lower ranked motifs. Another motif discovery tool, the Matrix Profile\footnote{http://www.cs.ucr.edu/~eamonn/MatrixProfile.html} algorithm, considers the top three motif pairs and the top discord (discord is the subsequences that have the largest distance to its nearest neighbor in the database, therefore can be used for anomaly detection). \footnote{To be fair, Matrix Profile also gives the user the option to discard uninteresting motifs among the top three, however, once you found three interesting enough motifs, there is no straightforward way to search for more.} In sum, these algorithms are typically developed in conjunction with data sets from domains where meaningful and significant events in the entire time-series data base is rare. 

Does this property apply to speech prosody time-series data? Intuitively it does not, but it is also an empirical question. On the one hand, we note that in the particular case of tone n-grams, the most typical task considered is a classification task: each tone n-gram can be classified into some combination of tone categories. In that sense, each instance of the subsequence can be partitioned into a divided space of classes, and therefore is a meaningful and significant event (as opposed to a dataset like EKG signal of heart beats, where we are most interested in discovering the motifs symptomatic of rare cardiac events). On the other hand, nonetheless, motif discovery - the discovery of previously unknown patterns - can still be of utility in uncovering interesting patterns, based on our basic assumption that significant and interesting speech prosodic events tend to repeat more than once. However, what we are interested is not to discover a few pairs of motifs; we want to uncover all motif clusters in a database of tone n-grams given a distance threshold (range) for the intra-cluster distances.  
%intuitively, it doesn't, but we also would like to show more formally.



\subsection{Time-series Complexity}  
If we contrast the top ranked spurious motifs from Figure \ref{fig:motif_pairs_sus} to a number of lower ranked real motifs (Figure \ref{fig:real_motif_sus}) from the same dataset, we observe an important fact about the top ranked motifs: they tend to be extremely simple motifs that are almost straight lines.

%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{real_motif.pdf}}
 \caption{5 motif pairs (spurious) from the CMN corpus (tone bigrams 100-point dataset), with their ranking, distance and tone categories noted}
  \label{fig:real_motif_sus}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In fact, the impact of the complexity of time-series data on the outcomes of data mining algorithms was a topic largely omitted until recently \cite{Batista2011,Gulati2015a}. In the research of the current thesis, we independently discovered that this is an important issue to be considered in the discovery of meaningful time-series motifs in the speech prosody data.

The complexity of time-series data refers to the intuitive definition that some time-series objects have more complex shapes (more peaks and valleys) than others with simpler shapes. In Figure \ref{fig:complexity} we show several shapes in the artificial geometric figures data set from \cite{Batista2011} and their corresponding 'time' series objects with different levels of complexity. Here we illustrate the impact of complexity on the distances between objects: the distance between pairs of complex time series is frequently greater than the distance between pairs of simple time series. In fact, complex time series are commonly deemed by distance measures (e.g., Euclidean distance) as more similar to simple time series than to other complex time series they look like. This phenomenon is shown when considering the distance matrix of the same data set in Table \ref{table:geoms}. As we can clearly see, whereas shapes 24 is clearly more similar to 32 than to 4, however, the pair 24 and 4 has a lower distance than the pair 24 and 32. 



%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{complexity.png}}
 \caption{Shapes and their corresponding 'time' series with different levels of complexity (from  \cite{Batista2011})}
 \label{fig:complexity}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% t a b l e %%%%%%%%%%%%
\begin{table}
 \caption{Euclidean distance matrix for the geometric figures data set (from  \cite{Batista2011})}
 \label{table:geoms}
 \begin{center}
 \begin{tabular}{| c || c | c | c | c | c | c | c | c | }
  \hline
      & 4 & 5 & 6 & 7 & 10 & 12 & 24 & 32\\
  \hline
   4 &   & 1.000 & 1.122 & 1.231 & 1.181 & 1.048 & 1.155 & 1.170\\
    5   &    &    & 1.318 & 1.068 & 1.103 & 1.153 & 1.165 & 1.180\\
  6  &  &  & &  1.088 & 1.097 & 1.103 & 1.186 & 1.200\\
  7 & & & & & 1.217 & 1.199 & 1.198 & 1.191\\
  10 & & & & & & 1.263 & 1.195 & 1.124\\
  12 & & & & & & & 1.135 & 1.199 \\
  24 & & & & & & & & 1.191 \\
  32 & & & & & & & & \\
  \hline
 \end{tabular}
\end{center}

\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



Different levels of complexities of speech prosody n-gram subsequences can cause problems in many time-series mining tasks. To foreshadow the discussion in the next chapters, motif discovery algorithms tend to find very simple motif pairs or clusters as top ranked motifs (as they have the lowest intra-motif distance). However, the problem is that these very simple motifs tend to be not real pitch estimations of the speech from audio but are artifacts of the linear interpolation of the unvoiced segments as a result of preprocessing. These (quasi-) linear motifs are therefore artificial and uninteresting, but they dominate all the top ranked motifs returned by the algorithm. Figure \ref{fig:linear} and \ref{fig:real_motif} show the contrast of a simple (artificial) vs. a complex (real) motif cluster (in addition to the motif pairs previously shown) in the tone bi-grams subsequence (database) data set from the CMN corpus.  In the rest of this chapter, I will consider the problem of finding real motifs from a database of time-series subsequences through the use of complexity measures and other features in machine learning methods. 



%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{linear.png}}
 \caption{A top-ranked simple (linear) spurious and artificial motif cluster from the CMN corpus(tone bigrams 100-point dataset) }
  \label{fig:linear}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{real_motif.png}}
 \caption{A real motif cluster from the CMN corpus (tone bigrams 100-point dataset) }
  \label{fig:real_motif}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%











\section{MK motif discovery algorithm setup and hyperparameter tuning}

We take the original implementation of the MK algorithm and modify/recompile the program as necessary. The original MK algorithm is implemented in C++ and takes only long time-series as the input as it is hardwired to extract time-series subsequences with a hop size of 1 sample throughout the entire long time-series. We therefore modified the code in order to perform N-grams motif discovery taking a pre-extracted database of subsequences as input. 

%hyper parameters
In our modified version of MK algorithm (database version), there are three parameters to be set: $X$, the range of the motif cluster (i.e., all subsequences within distance $X$ of the motif pair would be included in the motif cluster);  $k$, the number of motif clusters the user would like to find; and $R$, the number of reference points in the MK motif discovery algorithm. 

The MK documentation has provided a guideline for parameter setting: for $X$, they suggest to start with 2 and increase to 3; for $k$, it should be up to the user's needs; for $R$, they showed that \cite{Mueen2009} the exact value of $R$ doesn't affect the time performance of the algorithm as long as it is greater than 5, and they strongly suggest $R=10$. In the experiments, we follow their suggestions in general but also experiment with different sets of parameter settings.

% in the beginning we have used k=30, and we'll only find spurious motifs. but in real use cases we may assume that users may want to use arbitrary values for k. that is also why we use MAP score to evaluate. Maybe we should say something about that here - otherwise if readers assume we also use k=200 then the pruning is kind of trivial.


\subsection {Experiments on the value of $X$}
Running the MK with $X=2$ is in general a good starting point, as the authors' of MK algorithm have suggested. Nonetheless, we have several observations regarding running MK with different values of $X$: First, we observe that the value of $X$ is negatively correlated with the number of motif clusters found. A lower value of $X$ will in most cases yield more numerous motif clusters from the same data set. Second, the value of $X$ also positively correlate with the size of the motif clusters found. Taken these two points together, we see that using smaller $X$ will cause MK to discover more numerous but small motif clusters, whereas a bigger $X$ will lead to fewer but bigger clusters. If we go back to the original definition of $X$ as a range parameter, this behavior is predictable because a smaller range will produce many highly similar (low intra-cluster distance) and compact motif clusters, and vice versa. Therefore, we can think of the fewer yet bigger sized clusters found with a large $X$ as lumping together many smaller clusters from the smaller $X$, as many small clusters may merge into one big cluster as the range $X$ increases. 

The implication of this observation is twofold. First, it shows the tradeoff between finding more motifs and the size of each motif cluster. Second, it is also a tradeoff between intra-cluster distances and inter-cluster distances. The question is, is it more sensible to find more numerous tight clusters or fewer but more tolerant clusters? Considering the stochastic and analog nature of the speech production, we tend to prefer the latter type. That is, considering $f_0$ patterns produced by the human vocal fold will always contain some stochastic noise, it makes more sense to loosen the distance threshold of range $X$, rather than requiring motifs to be the near-exact copies of each other. Moderate variance should allowed in a meaningful motif cluster of $f_0$ patterns. On the other hand, as $X$ increases we can have a big cluster that contains many motifs that are too dissimilar to each other. Therefore, we still need to find a balance point given the tradeoff.


The third observation is that when X is fixed, the number of motifs ($num\_motif$) found also correlates negatively with the length of time-series subsequences ($len\_ts$). This effect is demonstrated in Table \ref{tab:numX} (note the contrast in the number of motifs discovered when X=2 or 3 but $len\_TS$ varies from 100 to 200). Intuitively, this is because the distances from a data set tend to increase when $len\_TS$ becomes larger, therefore under the threshold of the same range $X$, less number of subsequences make the cut into the motif cluster (and note that MK algorithm did not normalize for the different values of $len\_TS$).To confirm this suspision, we have computed the pairwise distances (Euclidean) of 50,000 randomly sampled subsequence pairs from each data set of bigram 100p, 200p, and 300p. Figure \ref{fig:distb300p},\ref{fig:distb200p},\ref{fig:distb100p} show the distance distribution of these three data sets (x axis is Euclidean distance). From these plots we confirm that the distances increase when $len\_TS$ increases. Therefore, we conjecture that when we increase $X$, we are able to find more motifs. To leverage this effect, we compute that $X=2$ translates into excluding 99.9\% of the subsequence pairs when $len\_TS$ equals 100 (as they have a distance greater than this threshold), and we similarly experiment with a 0.1\% in the cummulative distance distribution for $len\_TS$ equals 200 and 300, using $X=3$ and 4 respectively. Our hope is that this will yield more motifs from these datasets.



%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{distb300p.png}}
 \caption{Distance distribution of 50,000 randomly sampled pairwise distances in bigrams 300-point dataset) }
  \label{fig:distb300p}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{distb200p.png}}
 \caption{Distance distribution of 50,000 randomly sampled pairwise distances in bigrams 200-point dataset) }
  \label{fig:distb200p}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{distb100p.png}}
 \caption{Distance distribution of 50,000 randomly sampled pairwise distances in bigrams 100-point dataset) }
  \label{fig:distb100p}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%% table
\begin{table}
\small
\begin{center}
\begin{tabular}{ |c|c|c| } 
 \hline

X & No.motif clusters & Len(TS) \\
\hline
\hline
1.6 & 90 & 200 \\
2 & 48 & 200 \\
2.2 & 44 & 200\\ 
2.5 & 33 & 200 \\
3 & 22 & 200 \\
2 & 90 & 100 \\
3 & 33 & 100  \\

 \hline
\end{tabular}
 \caption{Number of motif clusters discovered varies with $len\_TS$ and $X$}
  \label{tab:numX}
\end{center}
\end{table}

%%%%%%%%%%%%%%% table


However, it turns out that this factor tends to be quite irrelevant in the presence of the effect of $X$'s negative correlation with $num\_motif$. This effect is again showing in Table  \ref{tab:numX}: as X increases, we see that the $num\_motif$ decreases, despite the distance effect discussed in the last paragraph. We conclude that the distance effect with $len\_TS$ is quite diminishing in the presence of the tradeoff associated with $X$ and inter- / intra- cluster distances and in turn with the $num\_motif$.

Given these observations, we now move on to propose methods for finding the appropriate value of X that satisfis several conditions. First, our objective is to find maximally distinct motif clusters (inter-cluster distance is big). Second, given the same level of distinctiveness, we want to find more motifs. Alternatively, as a balance point given the tradeoff, we want to find motif clusters with high ratio of inter- to intra- cluster distances. 

We first propose a Motif Cluster Quality Measure (MCQM) based on the first two conditions above:

\begin{equation}
%TLC(C)=\frac{TLC_{raw}} {\binom{m}{2} * N}
%ave_dist*np.log10(len(distinct_motifs_list)
MCQM = ICD \times log_{10}^{num\_motifs}
\end{equation}

where the ICD is the mean Inter-Cluster Distances given all motif clusters found at a fixed value of $X$. 

Next, having computed the MCQM and the inter- to intra- cluster mean distance ratio, we combine the two measures:

\begin{equation}
%TLC(C)=\frac{TLC_{raw}} {\binom{m}{2} * N}
%ave_dist*np.log10(len(distinct_motifs_list)
MCQM\_ratio = MCQM\times(1/100+IIC\_ratio/10)
\end{equation}

where IIC\_ratio is the Inter- to Intra- Cluster mean distance ratio given a fixed value of $X$. The MCQM\_ratio meaure is intended to combine the three conditions outlined above when evaluating the optimal value of X, while giving different weights to these considerations. Figure \ref{fig:mcqmb100p}, \ref{fig:mcqmb200p}, \ref{fig:mcqmb300p} show the evolution of inter-cluster distance(mean), number of clusters, inter-to-intra cluster distance ratio, MCQM, and MCQM\_ratio measure given the different values of $X$ in the bigram100p,200p,and 300p data sets (values are normalized to be plotted in the similar range). We can clearly see the tradeoff between these different parameters, and how the MCQM\_ratio measure combines them into a single decision. We therefore pick $X=2.2, 2, 2$ for $len\_TS$ of 100, 200, and 300. In addition, the decision can be automatically made given any other values of $len\_TS$ of unseen data sets.


%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}



 \centerline{
 \includegraphics[scale=0.5]{bigram_100p.pdf}}
 \caption{Experiments on the value of X and motif cluster quality measures, len\_TS=100 }
  \label{fig:mcqmb100p}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}



 \centerline{
 \includegraphics[scale=0.5]{bigram_200p.pdf}}
 \caption{Experiments on the value of X and motif cluster quality measures, len\_TS=200 }
  \label{fig:mcqmb200p}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}



 \centerline{
 \includegraphics[scale=0.5]{bigram_300p.pdf}}
 \caption{Experiments on the value of X and motif cluster quality measures, len\_TS=300 }
  \label{fig:mcqmb300p}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\subsection {Varying the value of $k$}
When we follow MK's suggestion and fix the value of $X$ at 2, we first set $k$ to 200 in order to exhaustively retrieve the maximum possible number of motifs. The result depends on the specifics of the data set (as well as the length of time-series subsequences in the data set and X, as well as the size of the data set), but in general in a data set that has about 100,000 subsequences (or the same order of magnitude), the number of distinctive motifs that the MK algorithm discovers has an upper limit of about 100. If running MK only once, then at least 30\% of those are linear motifs (spurious), which should be pruned off. In the following chapters we will focus on the details of pruning these spurious motifs in conjunction with running MK iteratively while varying $k$ from 30 to 100.





%one strategy is to find a complexity measure and a cutoff. if you're using MK complexity measure that won't work - but using CP_POLY it kind of work that way - but still, it's hard to say how SVM works better than DT. 

\section{Distinguishing spurious and real motifs}
In this chapter, we analyze the properties and characteristics of motif clusters from the output of the MK algorithm on databases of tone N-gram subsequences. We then propose several measures to both quantitatively describe these characteristics, and utilize them to reach our end goal of filtering out spurious motifs and finding real motifs.

\subsection{Annotating motif classes}
%we need to include a data set name table or something
Our first task in distinguishing spurious from real motifs is to define what constitutes a spurious motif versus a real motif. In order to have a better understanding of the attributes of the output of MK motif discovery algorithm, we run the algorithm with different configurations and having a human annotator annotating the motif classes. Using the bigram\_100 data set, we observe that when k=30, all motif clusters are strictly linear, looking similar to the one in Figure \ref{fig:linear}. We therefore use k=200 and X=2, in order to exhaustively find all motif clusters. The result shows that in this data set, given the subsequence length (200) and size (~80,000) of the data set, the algorithm would exhaust and stop returning distinctive motif clusters at around 110, i.e., it only finds 110 distinctive motif clusters given the constraints of a range X=2. This configuration therefore gives us an overview of the range of motif clusters in terms of its goodness and naturalness. 

We have shown the two classes of motifs previously: a spurious motif (also known as a linear motif, Figure \ref{fig:linear}), and a real motif (also known as a non-linear motif, Figure \ref{fig:real_motif}). However, through annotating the 110 motif clusters found in the bigram\_100 dataset, we have found another class of motif: the ambiguous motifs. We also refer to them as q-linear (quasi-linear) motifs. Figure \ref{fig:qlinear} shows an example of q-linear motif cluster. As the name suggests, q-linear motifs are mostly linear (i.e., considers a linear segment that occupies at least more than half of the motif length), and it is ambiguous to annotate them as whether a real motif or an artificial (bad) motif. Therefore, in a real-world application scenario, we would hesitate to prune them out completely and we also don't want to say they are real motifs of interest. Our strategy is to first annotate the motif cluster results using the three-class distinction. This distinction can be maintained in real applications as well: when presenting to the user, we rank them as potentially of interest in descending order: non-linear, q-linear, linear. In the following chapters we also present further analysis as evidence to justify this ranking. 

In Figure \ref{fig:rank-class-t200} we show the distribution and correlation between motif cluster ranking and classes trigram\_100 corpus, where the bars correspond to the first, second, third, and fourth quarter of the data according to motif ranking. Interestingly, the annotated linearity classes are distributed according to the rank of the motif clusters: top ranked motif clusters tend to be linear; mid-ranked clusters tend to be q-linear; low-ranked clusters tend to be linear. There are some transitional regions where classes maybe mixed; however, the trend is consistent across different data sets (Figure \ref{fig:rank-class-t300},\ref{fig:rank-class-b200},\ref{fig:rank-class-b100}). 

In the following chapters our primary goal is to develop quantitative measures in order to automatically learn to classify these classes. For this task, we have annotated four data sets and pool them together as the pooled data set. Table \ref{tab:datasets} shows the details of these data sets.


%%%%%%%%%%%%%%%%%%%%% table
\begin{table}
\small
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c|c| } 
 \hline
Dataset & Size & TS length & \#motif clusters & L & QL & NL & bad  \\ 
\hline
\hline
Bigram100p & 88440 & 100 & 107 & 43 & 19 & 40 & 5\\
Bigram200p & 85819 & 200 & 74 & 34 & 10 & 24 & 6\\
Trigram200p & 77588 & 200 & 48 & 10 & 5 & 31 & 2\\
Trigram300p & 76586 & 300 & 39 & 10 & 6 & 22 & 1\\
Pooled & n/a & n/a & 268 & 97 & 40 & 117 & 14\\  

 \hline
\end{tabular}
 \caption{Datasets annotated, L=linear, QL=q-linear, NL=nonlinear, X=2, k=200 for number of motif clusters found by MK algorithm. A bad cluster is a cluster where members have dissimilar shapes visually so that they should not be a motif - this is a motif range problem and usually with X=2 there are less than 5 bad motif clusters ranked lowest in discovered motifs. This can be resolved by experimenting with smaller value of X.}
  \label{tab:datasets}
\end{center}
\end{table}

%%%%%%%%%%%%%%% table

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\small


 \centerline{
 \includegraphics[scale=0.5]{qlinear.png}}
 \caption{A q(uasi)-linear motif cluster from the bigram\_100 corpus  }
  \label{fig:qlinear}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{rank_class_plot_t200.pdf}}
 \caption{Stacked bar chart showing the distribution and correlation between motif cluster ranking and classes trigram\_200 corpus  }
  \label{fig:rank-class-t200}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{rank_class_plot_t300.pdf}}
 \caption{Stacked bar chart showing the distribution and correlation between motif cluster ranking and classes trigram\_300 corpus  }
  \label{fig:rank-class-t300}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{rank_class_plot_b200.pdf}}
 \caption{Stacked bar chart showing the distribution and correlation between motif cluster ranking and classes bigram\_200 corpus  }
  \label{fig:rank-class-b200}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{rank_class_plot_b100.pdf}}
 \caption{Stacked bar chart showing the distribution and correlation between motif cluster ranking and classes bigram\_100 corpus  }
  \label{fig:rank-class-b100}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%just say these motif classes are Motif classes based on linearity



\subsection{BWK complexity measure}
There are many complexity measures for time-series, such as Kolmogorov complexity [], many variants of entropy [], the number of zero crossings, etc.  \cite{Batista2011} considers the desirable properties any such complexity measure should have: (1) It should have low time and space complexity; (2) It should have few parameters, ideally none; (3) It should be intuitive and interpretable. Given these above desideratum, we adopt an intuitive measure of the complexity of time-series proposed by \cite{Batista2011} (here on referred as BWK complexity measure). It has O(1) space and O(n) time complexity, is completely parameter-free, and has a natural interpretation. It is empirically tested to be the best, even though it has not been claimed to be `optimal'. 

The complexity measure is simply defined as the squared sum of the differences between adjacent points in the entire time-series:

\begin{equation}
CE(Q)=\sqrt[2]{\displaystyle\sum_{i=1}^{N-1} q_i^2+q_{i+1}^2}
\end{equation}


where Q is a time series $q_1,q_2,...,q_N$. Intutively, this approach is based on the physical intuition that if we could stretch a time series until it becomes a straight line, a complex time series would result in a longer line than a simple time series\cite{Batista2011}. 

Despite being evaluated on many time-series data sets as an effective measure of complexity \cite{Batista2011, Gulati2015a}, the BWK complexity measure has shortcomings to be used in the current tone N-gram motif mining task. First, we note that the z-score normalization (which centers the time-series subsequence at mean of 0 and standard deviation of 1) must be applied in order for the measure to work properly. This is due to the fact that the BWK method only measures the squared distance between a sample and its neighbors while ignoring the direction of the difference. Therefore we could easily make up a counter-example where the pair of time-series objects obviously have different complexity but are assigned the same scores. Figure \ref{fig:ab} shows such an example - and this problem is fixed when z-score normalization is applied (Figure \ref{fig:anbn}). However, as discussed in earlier chapters, in tone $f_0$ data, it is beneficial to avoid z-score normalization but preferrable to simply apply a subtract-mean normalization due to the existence of quasi-flat contours with low values of standard deviation. Moreover, we could imagine a scenario where the two subsequences in Figure \ref{fig:ab} are in fact post-normalization. In that case, we have no way of correctly detect their complexity ranks.

There is a second problem of BWK cannot be easily fixed. Intuitively, we want a complexity measure that is invariant to the length of the time-series subsequence, or \textit{invariance to sampling rate}. For example, if we have two versions of the same subsequence with length 100 and 200, we want a measure that can assign the same complexity score to both\footnote{In the same database usually the subsequences are all of the same length, which is why this hasn't caused a problem when evaluated within a data set. However, our goal is to train a classifier that can work across different data sets of arbitrary length of subsequences, thus the invariance to sampling rate becomes important.}. That can be easily achieved by normalizing the complexity score by a scaler/factor in proportion to the length - if the scores behave in a linear way in the first place. However, the BWK doesn't behave linearly in such a fashion. Concretely, if we take a subsequence and compute the BWK score of it as well as the BWK score of the first half of the subsequence, we expect the latter to have half the BWK score of the former. However, that doesn't hold for BWK if the two subsequences have different slopes. Figure \ref{fig:sec-prob1} shows such an example from the CMN corpus where a "stretched" version (blue) of the same subsequence (red) having a much lower BWK score due to its smaller slope. Figure \ref{fig:sec-prob2} shows a generalized example of two linear time-series subsequences of the same compexity (visually) but are assigned drastically different BWK scores due to their slope difference.

Due to these shortcomings, we propose a novel complexity score in the next chapter that has the desired property of invariance to sampling rate.

%example of un-normalized time series sequences that are very different in complexity but have similar scores. 
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{ab.png}}
 \caption{Example of BWK complexity on z-normalized time-series pair (inconsistent with intuition) }
  \label{fig:ab}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{anbn.png}}
 \caption{Example of BWK complexity on z-normalized time-series pair (consistent with intuition) }
  \label{fig:anbn}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{sec_prob1.png}}
 \caption{Time-series subsequences with different slopes: blue has a smaller slope than red, therefore it has a smaller BWK score (0.250) desipite it being twice as long than the red (0.359) }
  \label{fig:sec-prob1}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{sec_prob2.png}}
 \caption{Time-series subsequences with different slopes: generalization, BWK(blue)=0.6, BWK(red)=0.12 }
  \label{fig:sec-prob2}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Polynomial regression based complexity measure:LSSE}
In this chapter we propose a novel complexity measure for time-series subsequences in order to achieve the invariance to sampling rate. This algorithm is based on the intuition that a less complexity score will have lower sum of squared error value when we fit a linear regression line to the data points. We call this algorithm the Lowest Sum of Squared Error (LSSE) algorithm. 

The LSSE algorithm works as follows:

(1) We fit a linear regression line to the time-series subsequence data, where $y_i$ is the $i$th data point and $X_i$ is the index $i$ of the data point. Therefore, we can approximate y (written as hypothesis $h(x)$) as a linear function of x, where $\theta$ is a matrix of weights:
\begin{equation}
%CE(Q)=\sqrt[2]{\displaystyle\sum_{i=1}^{N-1} q_i^2+q_{i+1}^2}
h(x)=\sum_{i=0}^{n}\theta_i x_i = \theta^T x
\end{equation}

And we define the cost function as :
\begin{equation}
%CE(Q)=\sqrt[2]{\displaystyle\sum_{i=1}^{N-1} q_i^2+q_{i+1}^2}
%h(x)=\sum_{i=0}^{n}\theta_i x_i = \theta^T x
J(\theta)=1/2 \sum_{i=0}^{m} (h_{\theta}(x^{(i)}) - y^{(i)}) ^2
\end{equation}

We then use stochastic gradient descent to minimize the cost function. In the current experiments we use implementation available in \texttt{numpy.polyfit}.

(2) We compute the sum of squared errors (SSE) for all data points $y_i$, for $i = 1$ to $N$, where N is the length of a time-series subsequence:
\begin{equation}
%CE(Q)=\sqrt[2]{\displaystyle\sum_{i=1}^{N-1} q_i^2+q_{i+1}^2}
%h(x)=\sum_{i=0}^{n}\theta_i x_i = \theta^T x
%J(\theta)=1/2 \sum_{i=0}^{m} (h_{\theta}(x^{(i)}) - y^{(i)}) ^2
SSE=\sqrt{\displaystyle\sum_{i=0}^{N} (y_{pred}^{(i)}-y^{(i)})^2}
\end{equation}

(3) We find the factor $k$ to normalize the time-series by its length $N$. The factor is computed as the maximum value that is smaller than 10 when $N$ is iteratively divided by 10 (the iteration stops when the value is less than 10). The LSSE complexity measure is then given by:
\begin{equation}
LSSE=SSE/k
\end{equation}

Initial experimentation shows this method is invariant to sampling rate, and it performs favorably in motif classification tasks comparing to BWK. We will present a systematic evaluation against BWK in the evaluation chapter.

\subsection{Tone Label Consistency (TLC) score} \label{sec:tlc}
In previous chapters we have indicated that linear motifs are in general spurious and less reliable / interesting than non-linear motifs because they are not true representations of pitch estimation but the result of interpolation. In the mean time, we also distinguished these two classes from a third 'ambiguous' class, which has a substantial linear segment at least 50\% of the length of the time-series. How can we decide the goodness or interestingness of such motifs? Should they be presented to the user as motif cluster candiates for further investigation? Obviously the answer to this question will depend on the specific research task and data set, but in the current stage, the first thing we can do is to utilize the ground truth tone labels of the tone N-grams within a motif cluster and evaluate whether they have high consistency within the cluster\footnote{In this chapter we're in general only concerned with finding real motif clusters instead of asking the question of what is a meaningful or interesting motif cluster. Therefore, in this case, we're not saying that a motif cluster of tone N-grams with highly consistent tone labels are necessarily more interesting to look into than those without. Rather, we're using this intuitive metric of tone label consistency to provide justifications (or falsifications) for our division of classes and their reliability as a good potential motif cluster to look into. }. 


The Tone Label Consistency (TLC) score takes an array of tone N-gram labels from a motif cluster and measures how consistent the labels are. Concretely it computes the  pairwise similarity of tone N-gram labels and aggregate them. Given a motif cluster C with $m$ time-series subsequences, the label of the $i$th member of the cluster has a label in its $k$th position of the N-gram label as: 

\begin{equation}
L_{ki},  i \in \{1,2,...,m\}; k \in \{1,2,...,N\}
\end{equation}

And the $TLC_{raw}$ score is defined as:
\begin{equation}
%CE(Q)=\sqrt[2]{\displaystyle\sum_{i=1}^{N-1} q_i^2+q_{i+1}^2}
%h(x)=\sum_{i=0}^{n}\theta_i x_i = \theta^T x
%J(\theta)=1/2 \sum_{i=0}^{m} (h_{\theta}(x^{(i)}) - y^{(i)}) ^2
%SSE=\sqrt{\displaystyle\sum_{i=0}^{N} (y_{pred}^{(i)}-y^{(i)})^2}
TLC_{raw}(C)=\sum_{k=1}^{N} \sum_{all\ i,j \in \{1,2,...,m\}}  I\bullet_{L_{ki}=L_{kj}}
\end{equation}

where $I\bullet$ is an indicator function as follows:


\[ \begin{cases} 
      0 & if\ L_{ki} \neq L_{kj} \\
      1 & if\ L_{ki} = L_{kj}
   \end{cases}
\]

Finally we further normalize the $TLC_{raw}$ score so that its values range between 0 and 1. In order to achieve that we divide the $TLC_{raw}$ score by the maximum possible score value considering all pairs of matching labels in all $N$ positions:

\begin{equation}
TLC(C)=\frac{TLC_{raw}} {\binom{m}{2} * N}
\end{equation}



\subsection{Correlation between TLC and Complexity score}
Having proposed two features to quantify the characteristics of the motif classes, in this chapter we report some initial analysis in order to better understand the distribution of complexity (using LSSE\footnote{The results obtained from using BWK complexity measure is in general consistent with those obtained from LSSE if we analyze a single data set. However, in the current analysis we analyze a pooled data set of different time-series subsequence length, therefore using LSSE gives us more consistent results due to its invariance to sampling rate. }) and TLC scores among the three classes. All analyses are done using a ground-truth annotated, pooled data set of tone N-grams, including bigram\_100, bigram\_200, trigram\_200, and trigram\_300 motif cluster data sets.
%make a table of the details of these annotated data sets, how many in each class, etc.


%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{3_gram_300p_ave_rank.pdf}}
 \caption{Correlation between rank and complexity in trigram 300p data set }
  \label{fig:tri-300-ave-rank}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{3_gram_200p_ave_rank.pdf}}
 \caption{Correlation between rank and complexity in trigram 200p data set }
  \label{fig:tri-200-ave-rank}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{2_gram_200p_ave_rank.pdf}}
 \caption{Correlation between rank and complexity in bigram 200p data set }
  \label{fig:bi-200-ave-rank}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{2_gram_100p_ave_rank.pdf}}
 \caption{Correlation between rank and complexity in bigram 100p data set }
  \label{fig:bi-100-ave-rank}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%complexity: we should do both measures.
First, we show that the complexity score is negatively correlated with motif cluster ranks: higher ranked motif clusters have low complexity scores. We can see this is indeed the case across different data sets (Figure \ref{fig:bi-100-ave-rank},\ref{fig:bi-200-ave-rank},\ref{fig:tri-200-ave-rank},\ref{fig:tri-300-ave-rank}).  

Second, we plot the complexity score distribution among the three classes. As seen in Figure \ref{fig:pooled-ave-comp}, the three classes are relatively well separated with the LSSE complexity score. Figure \ref{fig:pooled-ave-box} shows the boxplot of the complexity scores.



%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{pooled_ave_comp.pdf}}
 \caption{Distribution of LSSE complexity scores among the three motif cluster classes }
  \label{fig:pooled-ave-comp}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{pooled_ave_box.pdf}}
 \caption{Boxplot of LSSE complexity scores among the three motif cluster classes }
  \label{fig:pooled-ave-box}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%distribution of TLC
As discussed previously, TLC is an intuitive and simple indicator of the quality of the motif clusters: we hypothesize that a random, spurious cluster is of lower quality than a real motif cluster, and the TLC score should be able to capture that. Here we take our annotated three classes, linear, q-linear, non-linear, and we conjecture that the quality of motif clusters from these three clusters should increase linearly. Our plot of the distribution of TLC scores among the three classes in Figure \ref{fig:tlc} supports this conjecture, even though the classes are much less well separated by TLC than the LSSE complexity score. This result also provides support to our division of the three classes and their rank of reliability as a good and real motif cluster. However, we also note that the correlation between motif cluster rank and the TLC score is weaker than those with complexity scores. We show this correlation in Figures \ref{fig:bi-100-tlc-rank},  \ref{fig:bi-200-tlc-rank},  \ref{fig:tri-200-tlc-rank},  \ref{fig:tri-200-tlc-rank}.
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{pooled_TLC.pdf}}
 \caption{Distribution of TLC scores among the three motif cluster classes }
  \label{fig:tlc}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{2_gram_200p_TLC_Rank.pdf}}
 \caption{Correlation between rank and TLC in bigram 200p data set }
  \label{fig:bi-200-tlc-rank}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{2_gram_100p_TLC_Rank.pdf}}
 \caption{Correlation between rank and TLC in bigram 100p data set }
  \label{fig:bi-100-tlc-rank}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{3_gram_200p_TLC_Rank.pdf}}
 \caption{Correlation between rank and TLC in trigram 200p data set }
  \label{fig:tri-200-tlc-rank}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{3_gram_300p_TLC_Rank.pdf}}
 \caption{Correlation between rank and TLC in trigram 300p data set }
  \label{fig:tri-300-tlc-rank}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Finally, we note that complexity score is correlated with TLC score (Figure \ref{fig:corr}). This correlation again provides justification to the division of the three classes and the use of complexity and TLC scores in quantifying the characteristics of motif clusters.
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{pooled_corr.pdf}}
 \caption{Correlation between LSSE complexity and TLC in pooled data set }
  \label{fig:corr}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\section{Learning to classify motifs }
%3-class, 2-class-1, 2-class-2, etc.; BWK vs. LSSE - LSSE is not only superior to BWK in invariance to sampling rate but also in other tasks in general. that might be shown through per data set classification, instead of pooled. 
%if using BWK then it is a good feature for 2-class-1, but 2-class-2 is classified better with two features; otherwise, using LSSE is adequate.

In this chapter we describe a machine learning module we use to perform classification on motif clusters. In the last few chapters we have proposed several features to characterize the motif clusters obtained from running the MK motif discovery algorithm on a database of tone N-grams time-series subsequences. In this chapter we design a series of classification tasks in order to learn the motif classes. In the next chapter, we plug these classifiers into a framework for refining motif cluster ranks in order to find top ranked true motifs, our final goal for the tone N-gram motif discovery task. 

The features we use include complexity features (computed for each member of a motif cluster, then averaged to derive the average complexity of the cluster) and the TLC feature (computed per motif cluster), which measures how consistent a motif clusters' tone labels are. For complexity features we have two varieties, BWK and LSSE. To foreshadow the experimental results reported in evaluation chapters, these two features capture different aspects of the complexities of time-series and can be used in conjunction or individually along with TLC. For TLC we follow our proposed measure as described in chapter \ref{sec:tlc}. These features and their acronyms to be used later in the reports are summarized in Table \ref{tab:features}. We will defer the discussion of how to combine these features under different machine learning algorithm frameworks to the evaluation chapter.

We propose two frameworks to perform the classification tasks. In the first framework we simply perform a three-class classification to distinguish the linear, q-linear, and non-linear classes. We call this a 3-class task in the Classification Framework (CF). 

In the second framework (a Iterative Pruning Framework or IPF), we first perform a 2-class classification task (named 2-class-1) to classify the motif clusters into either \textit{linear} (spurious) or \textit{others} class. Then in a second step, we perform another 2-class classification (2-class-2) to classify the remaining data into either \textit{qlinear} or \textit{nonlinear} class. The rationale for this framework is two fold. First, we observe that in certain data sets (ex: Figure \ref{fig:ave_comp_BWK}), when using BWK complexity measure, the linear class can be best separated from the other classes whereas there is not a good separation between the q-linear and non-linear classes. We therefore would like to explore if adding a second feature (TLC) would help improve the classification of q-linear and non-linear classes. Second, and more importantly, we found that an iterative approach to prune spurious motifs first and re-run MK algorithm on the pruned data set would result in more real motifs being discovered from running the MK algorithm. In that case, we first perform an iterative pruning step until the MK algorithm stops outputting spurious (linear) motif clusters, according to the 2-class-1 classifier. Then we perform the 2-class-2 classification in order to distinguish q-linear (ambiguous) from non-linear (real) motifs. We will further discuss CF and IPF in the next chapter. 



%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{2_gram_100p_ave_compBWK.pdf}}
 \caption{Average complexity (BWK) distribution between three motif classes in bigram\_100p data set}
  \label{fig:ave_comp_BWK}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%% table
\begin{table}
\begin{center}
\begin{tabular}{ |c||c| } 
 \hline
 Features & Acronym  \\ 
\hline
 Average Complexity BWK & AC\_B \\ 
 Average Complexity LSSE & AC\_L  \\
 Tone Label Consistency & TLC\\
 \hline
\end{tabular}
 \caption{Features used in classification}
  \label{tab:features}
\end{center}
\end{table}

%%%%%%%%%%%%%%% table
\begin{table}
\begin{center}
\begin{tabular}{ |c|c|c| } 
 
\hline
 Framework & Task & Acronym  \\ 
\hline
\hline
 CF & 3-class classification & 3C \\ 
IPF & 2-class (linear,others) classification-1 & 2C1  \\
 IPF & 2-class (qlinear,nonlinear) classification-2  & 2C2\\
 \hline
\end{tabular}
 \caption{Classification tasks overview}
  \label{tab:clas-tasks}
\end{center}
\end{table}



\section{Developing algorithms for refining motif cluster ranks}
%benefit of iteratively pruning
%the rank of clusters within a class should be maintained. 
%in pruning, you can keep pruning off the spurious clusters, then in the end you can perform a 2-clas2. 
%the 2c1, 2c2 task is justified mainly by the pruning step benefit - recovering more true motifs. it's true that 3cl has lowest accuracy but if you compound the two tasks it is worse. 

%we need a table that outlines each task with features. 
%then we outline in text the algorithms we will evaluate on.
%we also need a block diagram showing the classifier and the entire chain up to returned motifs with new ranks.


%algorithm description is still different from describing evaluation. The former doesn't need to include MAP score, eval metrics, etc., or even experimental setup. It needs to have the algorithm for returning the real motifs ranked at top for the user - basically a series of ranked motif clusters presented to the user.

We have seen that despite being an efficient algorithm for motif discovery, the MK algorithm cannot be used as an off-the-shelf algorithm for the motif discovery of tone N-grams due to its tendency to retrieve extremely simple motif as top ranked motif clusters. Our goal for this chapter is therefore to develop methods for refining the motif cluster ranks to automatically identify real motif clusters to be returned as top ranked motifs.

Having annotated training data sets with a three-class division, developed complexity measures (BWK, LSSE) and cluster-quality metric (TLC), as well as using these as features in classification tasks in two different frameworks, we now proceed to put them together and outline the variation of algorithms for refining the ranks for motif clusters. 

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{RR-algo.pdf}}
 \caption{Iterative Pruning Framework(IPF)}
  \label{fig:rr-algo}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The input to the following algorithms will be the output ranked motif clusters of running MK algorithm once on a data set of tone N-grams (initial setting X=2, k=200), and the output will be a ranked array of motif clusters. We propose five variations of our rank refinement algorithms in chapter \ref{sec:algo}  (assuming we've already trained the classifiers listed in Table \ref{tab:clas-tasks}).



\section{Rank refinement algorithms} \label{sec:algo}
These algorithms assume constant hyperparameter values over different iterations given a data set.
\begin{enumerate}
  \item Classification Framework: 3-class classification
  \begin{enumerate}
         \item Perform 3-class classification on the input motif clusters and return the re-ranked clusters, where classes are ranked in order of non-linear, q-linear, linear. Two clusters with the same class label are ranked by their original rank in the input. 
         \item We denote this method as '3cl'. 
  \end{enumerate}
  
 %\item Classification Framework: Two step classification
  %begin{enumerate}
     %    \item Perform 2C1 on the input motif clusters and prune linear motif clusters.
       % \item Perform 2C2 on the remaining data and return re-ranked clusters, where classes are ranked in order of non-linear, q-linear, linear. Two clusters with the same class label are ranked by their original rank in the input.  
  %\end{enumerate}
  

\item Iterative Pruning Framework: Exhaustive pruning. This algorithm is a generative IPF algorithm outlined in block diagram in Figure \ref{fig:rr-algo}. This algorithm is also outlined in Algorithm\footnote{The psudocode for this algorithm is written as taking the original tone N-gram database as input, whereas all verbose descriptions of algorithms in this chapter assumes the output of one iteration of MK algorithm as the input.} \ref{euclid}.
  \begin{enumerate}
         \item Perform 2C1 on the input motif clusters and prune linear motif clusters.
        \item Update the tone N-gram database.
        \item Run MK algorithm again on the updated input data.
        \item Repeat the last three steps until there is no motif clusters classified as linear from the output of the MK algorithm. 
        \item Perform 2C2 on the remaining data and return re-ranked clusters, where classes are ranked in order of non-linear, q-linear, linear. Two clusters with the same class label are ranked by their original rank in the input. 
        \item We denote this method is 'ipf'.  
  \end{enumerate}
  

 \item  Iterative Pruning Framework: One-step pruning. 
  \begin{enumerate}
         \item Perform 2C1 on the input motif clusters and prune linear motif clusters.
        \item Update the tone N-gram database.
       \item Run MK algorithm again on the updated input data.
        \item Perform 3C on the remaining data and return re-ranked clusters, where classes are ranked in order of non-linear, q-linear, linear. Two clusters with the same class label are ranked by their original rank in the input.  
        \item We denote this method as 'ipf-1'.
  \end{enumerate}

% \item  Iterative Pruning Framework: Exhaustive pruning with variable hyperparameter. This algorithm is identical to 3 except that it decrease $X$ and increase $k$ through the iterations. We will outline specific experiments configurations in the evaluation chapter.

\end{enumerate}

\begin{algorithm}
\caption{Iterative Pruning General Algorithm (Exhaustive)}\label{euclid}
\begin{algorithmic}[1]
\Procedure{IterPrune}{subseq\_database}
%\State $\textit{stringlen} \gets \text{length of }\textit{string}$
%spurious = True
%all_inds_rm = []
%while spurious == True:
\State $spurious \gets True$ 
\State $all\_inds\_rm \gets \text{initialize dynamic array}$
%\BState \emph{top}:
%\If {$i > \textit{stringlen}$} \Return false
%\EndIf
\Repeat
\State $motif\_clusters \gets \text{run MK\_DB algorithm on subseq\_database}$
%\BState \emph{loop}:
\For{ \textbf{each}  $motif\_cluster$\ \textbf{in}\ $motif\_clusters$}
\State $motif\_class \gets \text{predict/classify class of the motif cluster}$ 
\If {$motif\_class$ == $linear$}
\State $indexes \gets \text{get the indexes of the motif cluster}$
\State $all\_inds\_rm+=indexes$
%\If {$\textit{string}(i) = \textit{path}(j)$}
%\State $j \gets j-1$.
%\State $i \gets i-1$.
%\State \textbf{goto} \emph{loop}.
%\State \textbf{close};
\EndIf
\EndFor
\If {sizeof($all\_inds\_rm$)!=0}
\State $\text{update subseq\_database}$
\Else
\State $spurious \gets False$
\EndIf


\Until {$spurious == False$}
%\State $i \gets i+\max(\textit{delta}_1(\textit{string}(i)),\textit{delta}_2(j))$.
%\State \textbf{goto} \emph{top}.
\State $newRank \gets \text{2C2\_classify (motif\_clusters)}$

\Return {$newRank$}
\EndProcedure
\end{algorithmic}
\end{algorithm}




\section{Evaluation of motif discovery rank refinement}

\subsection{Data sets}
%many versions of equal-length downsampled ngrams varying N and comp_len. Maybe present a table of data set and other relevant info.
The data sets used in n-grams motif discovery vary in several aspects. First, they vary in the value of $N$: $N=1$ for unigram, $N=2,3$ for bigram and trigrams, respectively. Second, they vary in the length of the downsampled time-series subsequences. We denote this length as $dl$ (downsample length). The value of $dl$  represents the sampling rate of the downsampled pitch time-series, and its choice is constrained on the one hand by the faithfulness to the original sampling rate of pitch estimation (high dimension), and on the other hand, by the efficiency of an economic representation (low dimension). The choice of $dl$ also depends on the value of $N$. In previous chapters we have used $dl=30$ for experiments time-series mining. In the current experiments we also explore more values of $dl$: 100, 200, 300, 400, 500, 600 for bi-grams and tri-grams. Finally, it is noted that the number of time-series subsequences after applying downsampling will depend on the value of $dl$ as well: since we're not performing upsampling, any time-series subsequences with a length less than $dl$ will be eliminated from the data set. 
% we need a table of value of N, dl, size of data sets, etc.

\subsection{Experiment setup}
We propose a Motif Retrieval Task as the evaluation for the N-grams motif discovery. The task is analygous to the query by content task in the Part II of the dissertation, conceptualized from a information retrieval perspective. In the Motif Retrieval Task (MRT), our input it the database of time-series subsequences (in the current context, a database of tone N-grams). The goal of the task is to retrieve the real motifs from the database as the top ranked motifs. This is analogous to retrieving most relevant documents as top ranked documents in Information Retrieval. Since the user may be interested to find a variable number of top $K$ interesting motifs, we cannot specify a value for $K$ a priori. Therefore we use the Mean Average Precision (MAP) score as our eveluation metric again. 

We first run classification experiments on the three classification tasks proposed in Table \ref{tab:clas-tasks}. In these experiments our first goal is to evaluate the effectiveness of using complexity and TLC features. Second, we evaluate the competing complexity measures BWK and LSSE. Third, we experiment with several different classification algorithms, Support Vector Machine (SVM)[] , Decision Trees[] and Random Forest. Fourth, we observe that the 2C2 data sets have imbalances in number of training examples, with q-linear class being the minority class. This can lead to false impression of high accuracy scores while introducing more false negatives for the q-linear class. We therefore run additional experiments on a corrected data set (pooled) in order to train a more effective classifier evaluated on F1 score. The corrected data set is obtained through upsampling the minority class (sample twice for each training example). This turns out to be an effective strategy for obtaining higher F1 scores for the 2C2 task. Finally, to select the best classifier in practice, we test classifiers extensively on an unseen test set with 90 motif clusters with different combinations of classification strategies including probability threshold, feature scaling, and SMV kernel. 

We perform classification experiments individually on our four training sets using 10-cross validation, as well as the pooled data set. Finally we pick the best performing classifier for the pooled dataset to use as our classifier module for the rank refinement algorithms.

We run experiments using the three variants of the rank refinement algorithms outlined in chapter \ref{sec:algo}.
%perhaps we can still perform some systematic testing on values of X.- just think about using x=2, we have a few bad motif clusters in the end.
%we can simply do that with k=200 and see what happens.

%we need a diagram for this procedure.
%although this diagram maybe shown earlier at the last subsection of last section when we described the block diagram of the approach. but wouldn't we describe the task there too? let's see. what we do want to say is that this is like a rank refinement algorithm and pruning algorithm for the output of MK. 

\subsection{Results: Training classifiers}

First we present the results of classification experiments in both CF and IPF. All results reported are from experiments conducted using 10-fold cross validation. 

We report the first round experiments using accuracy scores as evaluation metric. The results for the four annotated data sets as well as the pooled data set are reported in Tables \ref{tab:ClassificationRes1}, \ref{tab:ClassificationRes2}, \ref{tab:ClassificationRes3}, \ref{tab:ClassificationRes4}, and \ref{tab:ClassificationRes5}. We use the pooled data set to select our classifiers.

First, we note that the LSSE consistently outperforms BWK in all classification tasks by a large margin. We therefore will adpot LSSE as our complexity measure for subsequence experiments. Second, we observe that the addition of TLC feature often results in a boost in classification accuracy while accompanying BWK feature. However, it did not help improve accuracy significantly in most cases when using LSSE as the complexity feature. In the mean time, we do observe that by incorporating TLC feature, we narrow the confidence interval of the accuracy (i.e., standard deviation of accuracy scores) visibly. In our final task of rank refinement, we evaluate both of the best performing one-feature and two-feature classfiers obtained here in order to make a selection based on its performance in the downstream task. Third, regarding classifiers, we note that SVM outperforms Decision Trees in most cases in this experiment.




%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%% bi 200(1)
\begin{table}
\small
\begin{center}
\begin{tabular}{ |c||c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Features/task & 2C1 & 2C2 & 3C  \\
\hline
BWK & 0.61/0.65 & 0.7/0.75 & 0.56/0.62  \\
BWK+TLC & 0.69/\textbf{0.74} & 0.7/\textbf{0.82} & 0.62/\textbf{0.65} \\
\hline
LSSE & \textbf{0.82}/0.82 & 0.93/\textbf{1.0} & 0.81/\textbf{0.83}\\
LSSE+TLC & 0.82/0.81 & 0.93/1.0 & 0.8/0.78\\
\hline
\end{tabular}
 \caption{Classification accuracy bigram200p (SVM/Decision Tree)}
  \label{tab:ClassificationRes1}
\end{center}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%% table %%%%%%%%%%% bi 100(2)
\begin{table}
\small
\begin{center}
\begin{tabular}{ |c||c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Features/task & 2C1 & 2C2 & 3C \\
\hline
BWK & 0.71/0.72 & \textbf{0.68}/0.55 & \textbf{0.65}/0.53  \\
BWK+TLC &  \textbf{0.78}/0.69 & 0.68/0.58 & 0.64/0.58 \\
\hline
LSSE & 0.92/0.88 & \textbf{0.83}/0.78 & \textbf{0.82}/0.75\\
LSSE+TLC & \textbf{0.93}/0.89 & 0.83/0.78 & 0.81/0.73\\
\hline
\end{tabular}
 \caption{Classification accuracy bigram100p (SVM/Decision Tree)}
  \label{tab:ClassificationRes2}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% table %%%%%%%%%%% tri 300 (3)
\begin{table}
\small
\begin{center}
\begin{tabular}{ |c||c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Features/task & 2C1 & 2C2 & 3C \\
\hline
BWK &  0.73/0.82 & 0.82/0.82 & 0.59/0.66 \\
BWK+TLC &  0.73/\textbf{0.84} & \textbf{0.82}/0.78 & 0.59/\textbf{0.72} \\
\hline
LSSE &\textbf{ 0.88}/0.87 & \textbf{1.0}/1.0 & \textbf{0.89}/0.85\\
LSSE+TLC & 0.8/0.82 & 0.97/1.0 & 0.84/0.79\\
\hline
\end{tabular}
 \caption{Classification accuracy trigram300p (SVM/Decision Tree)}
  \label{tab:ClassificationRes3}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% table %%%%%%%%%%% tri 200 (4)
\begin{table}
\small
\begin{center}
\begin{tabular}{ |c||c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Features/task & 2C1 & 2C2 & 3C \\
\hline
BWK &  0.78/\textbf{0.8} &\textbf{ 0.88}/0.79 & 0.68/\textbf{0.7}  \\
BWK+TLC & 0.78/0.77 & 0.88/0.88 & 0.68/0.7\\
\hline
LSSE & \textbf{0.96}/0.94 & 0.82/\textbf{0.93} & 0.86/\textbf{0.9}\\
LSSE+TLC & 0.96/0.92 & 0.85/0.93 & 0.88/0.9\\
\hline
\end{tabular}
 \caption{Classification accuracy trigram200p (SVM/Decision Tree)}
  \label{tab:ClassificationRes4}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%% table %%%%%%%%%%% pooled
\begin{table}
\small
\begin{center}
\begin{tabular}{ |c||c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Features/task & 2C1 & 2C2 & 3C \\
\hline
BWK &  \textbf{0.76}/0.72 &  \textbf{0.74}/0.59 & 0.69/0.54 \\
BWK+TLC &  0.76/0.72 & 0.74/0.66 & \textbf{0.7}/0.57\\
\hline
LSSE & 0.87/0.84 & \textbf{0.91}/0.87 & \textbf{0.82}/0.76\\
LSSE+TLC & \textbf{0.88}/0.86 & 0.91/0.86 & 0.82/0.8\\
\hline
\end{tabular}
 \caption{Classification accuracy pooled data set (SVM/Decision Tree)}
  \label{tab:ClassificationRes5}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%

%next discuss the 2cl2 experiments with upsampling data.
Next, we report classification results using the upsampled pooled 2C2 data set in Table \ref{tab:ClassificationRes6}. Upsampling turns out to be an effective strategy in this case, as the best performing F1 score is improved from 0.8 (original data set using SVM) to 0.95 (upsampled data set using Decission Trees). It is noteworthy that Decision Tree based classifiers (Decicion Trees and Random Forest) are the most effective when dealing with this data set, boosting both F1 score and accuracy in training and validation sets.

However, we observe that this strategy alone is still not able to perform well in practice as the performance of our best classifier degrades considerably when evaluated on an unseen test set consisting of 90 motif clusters discovery from the bigram 100p data set using MK algorithm. We therefore performed additional experiments using classifier optimization techniques such as probability threshold (altering decision boundary for probabilistic classifiers such as SVM and Random Forest), feature scaling (min-max scaling and z-score scaling), and the kernel trick in the case of SVM (RBF vs linear kernel with \texttt{class\_weights} argument, which has built-in weight adjustment for imbalanced classes). This result is summarized in Tabel \ref{tab:ClassificationRes7}. Note that the results reported in this table are obtained from using SVM classifier. Even though Decision Tree classifier achieved best results on training and validation set (as noted above), it is not a probabilistic classifier and is difficult to caliberate further when found to be ineffective in testing set evaluation. SVM (and Random Forest to a certain extent), in contrast, allows multiple optimization techniques in order to achieve higher F1 score in testing time.

From Table  \ref{tab:ClassificationRes7} we select the best F1 classifier to be the SVM with RBF kernel using 2 features and thresholding at probability of 0.3 for the positive (QL) class. Meanwhile, in general we have found three sets of optimization techniques that are able to achive more or less equivalent improvement over the baseline of default setting of SVM (RBF kernel with 0.5 threshold). These are: (1) RBF kernel with threshold of 0.3; (2) Linear kernel with class weights adjustments for imbalanced classes (otherwise default); (3) RBF kernel with min-max feature scaling (otherwise default). The fourth variation of using z-score scaling of features resulted in the highest recall score but lower F1 score. This would lead to the best looking results when evaluated at top $k$ motif (similar to the precision@10 evaluation metric for information retrieval) since there will be a large number of motifs classified as QL and ranked lower, which also tend to be simple motifs (if not q-linear). However, given the use case of this application and our final objective of MAP score, we select the best F1 classifier, which is the most sensable thing to optimze at the data set level. 



%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
\begin{table}
\small

\begin{center}
\begin{tabular}{ |c|c|c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Dataset & Precision & Recall & F1 & Accuracy\\
 \hline
\hline
Orig-1f & 0.82/0.77/0.78  & 0.8/0.75/0.75 & \textbf{0.80}/0.75/0.75 & \textbf{0.91}/0.87/0.89\\
 
Orig-2f & 0.87/0.72/0.81 & 0.76/0.78/0.73 & 0.79/0.72/0.76 & 0.91/0.86/0.92\\
 \hline
UpS-1f & 0.86/0.90/0.88 & 0.81/1.0/0.95 & 0.83/\textbf{0.95}/0.89 & 0.87/\textbf{0.95}/0.91\\
 
UpS-2f & 0.86/0.94/0.89 & 0.84/1.0/0.98 & 0.85/0.94/0.89 & 0.88/0.95/0.95\\

\hline
\end{tabular}
 \caption{Classification accuracy pooled 2C2 data set. Results reported using SVM/Decision Tree/Random Forest in each cell, Orig=original data, UpS=Upsampled data, 1f=one feature (LSSE), 2f=two features(LSSE,TLC)}
  \label{tab:ClassificationRes6}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
\begin{table}
\small

\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c|} 

 \hline

T & Feature scaling & SVM kernel & \#f & p/r/F1(validation) & p/r/f1(test)\\
\hline
\hline
0.5 & No scaling & RBF & 1 & 0.88/0.84/0.86 & 1/0.65/0.79 \\
0.5 & No scaling & RBF &   2 & 0.87/0.88/0.87 & 1/0.65/0.7 \\
\hline
0.5 & minmax & RBF &  1 & 0.83/0.91/0.86 & 0.96/0.74/0.84\\
0.5 & minmax & RBF &  2 & 0.85/0.98/\textbf{0.91} & 0.93/0.71/0.81\\
\hline
0.5 & zscore & RBF & 1 & 0.89/0.87/0.87 & 0.67/0.85/0.75\\
0.5 & zscore & RBF &   2 & 0.87/0.88/0.87 & 0.68/\textbf{0.86}/0.76\\
\hline
0.3 & No scaling & RBF   & 1 & 0.88/0.85/0.86 & 0.96/0.74/0.84\\
0.3 & No scaling & RBF   & 2 & 0.87/0.88/0.87 & 0.96/0.77/\textbf{0.86}\\
\hline
0.5 & No scaling  & Linear(CW) & 1 & 0.77/0.97/0.86 & 0.96/0.74/0.84\\
0.5 & No Scaling  & Linear(CW) & 2 & 0.8/0.98/0.87 & 0.93/0.74/0.83 \\

\hline
\end{tabular}
 \caption{Classification results using different parameter settings with the pooled 2C2 data set as training/validation set, and testing on bigram 100p MK motif discovery data set using the exhaustive IPF as test set. Results obtained using SVM classifier and upsampled training set (except when using linear kernel with \texttt{class weights} (CW) option in the \texttt{scikit learn} library for Python, which has built-in weight adjustments to account for class imbalance in training set. Complexity computed using the z-score normalized version of motif clusters. T=classification threshold for probabilistic classifier (SVM) for the positive (QL) class, \#f=number of features in classifier. First two rows indicate baseline results.}
  \label{tab:ClassificationRes7}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%



\subsection{Results: Rank refinement}
We report the evaluation results for the MK motif discovery rank refinement algorithms proposed in chapter \ref{sec:algo} along with a baseline MK algorithm where we simple run MK algorithm and take the result as is.

The results are presented in Figure \ref{fig:map-score}. First of all we immediately see the benefit of rank refinement in improving the ranking - even the simplest scheme of three-way classification (linear, qlinear, non-linear) increases the MAP score considerably over the baseline of MK algorithm and often close to the best score achieved by all methods. Second, we expected the iterative methods (IPF, IPF-1) would have benefits to find extra real (non-linear) motifs, however, to our surprise, this benefit only shows when the algorithm exhaustively removes all linear motifs it finds (IPF), whereas the results are worse than non-iterative methods in general if we only run MK one additional time(IPF-1), even though it is still significantly above baseline. Third, we do note that the (often) small gain by running IPF exhaustively is also weighed down by the excessive time it takes to run many iterations of MK algorithm (typically less than 7 iterations before it prunes all linear motifs from the database). Therefore, there is a tradeoff between efficiency (time complexity) and MAP score.

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.45]{MAP-scores.pdf}}
 \caption{Motif discovery MAP scores using different methods proposed, data set indicates N(-gram) and sampling rate, for instance 'b100' indicates bigram downsampled to 100 point per subsequence}
  \label{fig:map-score}

\end{figure}
%%%%%%%%


\subsection{Conclusion}
In this chapter we have developed novel time-series complexity measures and methods for pruning and classifying tone N-gram time-series motifs produced by the MK algorithm in order to refine the ranked retrieval results to achieve the best MAP score, in an attempt to retrieve relevant and meaningful true motif clusters. Our results greatly improves the baseline generated by MK algorithm and is well suited for motif discovery in the speech prosody domain. We observe a time-accuracy tradeoff between the non-iterative and iterative pruning frameworks. 

Overall, the motif discovery enables us to efficiently retrieve highly similar patterns (motif clusters) within a speech prosody database. Meanwhile, in order to extract linguistic meaning and improve our understanding of tone N-grams patterns, we need a linguistically informed conceptual and methodological framework. In the next chapter, we target the very heart of the variability problem in lexical tone production and analyze tone N-gram patterns in conjunction with cross domain linguistic features.















%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  N E T W O R K    A N A L Y S I S%%%%%%%%%%%%%%%%%%


\newpage

%we maybe interested in writing some of this if we have time.
%\chapter{Analysis of n-gram motifs}
%\section{Methodology}
%\section{Unigram motifs}
%\section{N-gram motifs}

\chapter{From categories to contours: Network analysis and machine learning of tone N-gram contour patterns} \label{network}

\section{Research questions}
In the last chapter we looked at how we can use motif discovery to discovery similar contour pattern shapes from tone N-gram data, and go from shape to explore patterns of tone N-gram categories. In this chapter, we look at the reverse of motif discovery problem: Given a tone N-gram category, can we predict what shape the tone N-gram will take on in spontaneous speech, given a set of linguistic knowledge features such as discourse, syntax, and phonology? 

%motivation
The motivation of this problem directly comes from the central question in tone and prosody research: how can we better understand the surface variability problem of tone production? Given a certain tone or tone N-gram category, to what degree can we predict the contour shape profile it will take, given a variety of linguistic knowledge features from both sound and text domain? 

%also, motivations for using features from these domains, discuss previous works on focus, topic, information newness (there is a paper I discussed in my problem statement). this could potentially be expanded in the feature chapter.

%N-gram

%deriving tone shape classes and ML shape classes
In order to formalize this task, we need to first have a method to derive tone contour shape classes so that we can perform subsequent machine learning experiments targeting these classes. In the next chapters, we first describe a method for automatically deriving such contour shape classes using network pattern analysis and we discuss its advantage over traditional unsupervised methods such as k-means clustering. Then, we proceed to investigate the problem of predicting contour shape classes using machine learning.


\section{Deriving tone N-gram contour shape classes through network analysis}
\subsection{Methodology}
We adapt a method proposed by \cite{Gulati16} to automatically derive tone contour shape classes given a particular tone N-gram using network analysis. A network, similar to a graph, is a mathematically data structure consists of nodes that are connected by edges. Each edge can be either directed/undirected or weighted/unweighted depending application. On a high level, this method filters a fully connected network representing a pair-wise distance matrix of all time-series objects of a tone N-gram category and after the filtering only those that have similarity beyond a threshold will remain connected. It then leverages network community detection algorithms to optimize the community structure, effectively deriving clusters where each pair of node inside each cluster are highly similar. Therefore we can use the clusters as our contour shape classes. An advantage of this method over the traditional clustering algorithm like k-means clustering is that, it automatically identifies and excludes outliers from entering main clusters because an object needs not only to have low distance to a cluster centroid, but must have low distances to all objects in the cluster. Under this algorithm, the outlier objects will form its own cluster naturally and we can filter them out by the cardinality of the cluster. Another advantage over K-means is that unlike K-means, we do not need to determine the number of cluster parameter before hand since the algorithm naturally picks clustering structures by network filtering and community detection. Finally, given our goal of deriving only contour shape classes (not any hard categories), this is a completely unsupervised process.  Since this problem is purely a distance-based problem (all the data points already belong to the same tone N-gram category, we only need to derive contour shape classes that are close-knit by their distance) and it has built-in optimization for distance-based filtering and community structure/modularity, there is no need to evaluate the classes in order to optimize any ground truth (extrinsic evaluation). \footnote{This point can be made more clear by comparing this task with a tone recognition clustering task. In a tone recognition task, our objective is to cluster according to tone categories, not contour shapes. If two tones are similar in shape but actually belong to different categories, we still want them to be clustered into different clusters. But in this case, they already belong to the same tone N-gram category, so as long as their contour shapes are similar enough beyond an optimized threshold, they should be in the same cluster, and we don't need to optimize the clustering any further according to additional ground truths. }


\subsection{Network construction}
We use the Python package \texttt{networkx} to implement networks and graphs and their operations. We first construct a fully connected tone N-gram pattern network where each node is a tone N-gram pattern time-series object and the edge between any two nodes is weighted by the distance between the two nodes. For simplicity we used Euclidean distance in this step. We then derive an undirected, weighted and fully connected network of tone N-gram patterns for each N-gram category (e.g., all data from tone trigram 1-3-4 is used to constructed a network, another network for trigram 2-3-1, etc). Due to the sparseness of some tone N-gram categories (especially those involving neutral tones), we have excluded those tone N-grams. %some statistics of tone ngram network sizes.



\subsection{Network filtering}
In this step, we take a fully connected network $G$ of a given tone N-gram category and use a principled method to remove edges from the network. Our goal is to find an appropriate threshold so that all edges whose weights (distance between two time-series objects) are greater than the threshold will be cut. Specifically, we decide the threshold value by a six-step process: (1) after observing the weight distribution of the network edges and trial and error, we search for the appropriate threshold in the set of values $T=\{1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5\}$ for bigrams and trigrams, $T=\{0.2,0.4,0.6,0.8\}$ for unigrams; (2) we iterate over this set of values and each time apply a threshold to the network; (3) after we applied the threshold we convert the network to a unweighted network $G'$ that is no longer fully connected (only those nodes that have a distance below the threshold will remain connected); (4) we produce a randomized network $G_r$ by randomly swapping edges from $G'$ $k$ times while keeping the degree of the nodes constant, where $k$ is equal to the number of edges in $G'$. This can be seen as producing a maximally random network given the degree distribution of the current network; (5) we compute the difference in Clustering Coefficient (CC) of both $G'$ and $G_r$; (6) after repeating this for all values in $T$, we pick the threshold which has the largest difference of CCs. 
%definition of CC

The clustering coefficient of an undirected graph is a measure of the number of triangles in a graph. Intuitively it is measuring how well connected a network is on average (one often cited example is in a social network), ranging from not connected to fully connected (how much of the possible connections are being saturated). It is based on a local clustering coefficient for each node:

\[
    C_i = \frac{number\ of\ triangles\ connected\ to\ node\ i}{number\ of\ triples\ centered\ around\ node\ i}
\]

where a triple centered around node i is a set of two edges connected to node i. The clustering coefficient for the whole graph is the average of the local values $C_i$:

\[
    C = \frac{1}{n}\sum_{i=1}^{n}C_i
\]

where n is the number of nodes in the network. By definition, the value of C is in the range of [0,1].
The clustering coefficient of a graph is closely related to the transitivity of a graph, as both measure the relative frequency of triangles.

In this method, we are comparing the CC of thresholded vs. randomized network. Here we provide some intuitions as to why this method works. What we're really getting at is how much the communities cluster together. Consider that if we have a fully connected network, then there is no communities, and the CC of this network and a randomized one (which is basically the same as this one) is identical. Then we start to threshold and cutting edges, and for a thresholded network we also create a randomized version. We then compare the CC of these two networks. What happens when they are maximally different? First, the CC of thresholded network is not the same as a randomized version of that network. What does that mean? Intuitively, what we really want is a network where the CC is high enough (calling for a higher threshold, because when threshold is too low it leaves only a few edges and will not have much community), but at the same time we don't want it to approach the fully connected network (i.e., to be far away from a fully connected network, we need a low threshold). In the latter case, the fully connected will have the same CC as randomized, so there is the tradeoff between the two forces. Ultimately we are after a balance point between these two extreme scenarios, and the maximal difference between the two CCs is that point.


\subsection{Community detection}
We use Python package \texttt{community} to perform community detection. Specifically we use the Louvain algorithm proposed in \cite{Blondel2008}, a widely popular algorithm due to its effectiveness and efficiency. This method is based on the optimization of modularity of the network as the algorithm progresses. Modularity is a scale value between -1 and 1 that measures the density of edges inside communities to edges outside communities. Optimizing this value theoretically results in the best possible grouping of the nodes of a given network. In the Louvain Method of community detection, first small communities are formed by optimizing modularity locally on all nodes, then each small community is recursively grouped into higher level communities.
%explain louvin method

Figure \ref{fig:cc314} shows a sample evolution of the clustering coefficients of a filtered network and a corresponding randomized network, where red vertical line is superimposed to indicate the maximum difference between the CCs. In this case we choose the value of $T=3.0$. Figures \ref{fig:networkComFull} shows an example community structure of the derived community partitions. The plot shows a small numbers of tightly connected bigger communities and some outlier small communities. Figure \ref{fig:networkComZoom} shows a zoomed in version of the bigger communities. Figure \ref{fig:01community} shows a sample well-behaved community structure (with no outlier communities) in bigram 0-1 data set.


%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{downsample_syl_3_meta_200_314_pkl_CC.pdf}}
 \caption{Evolution of clustering coefficients in trigram 3-1-4}
  \label{fig:cc314}

\end{figure}
%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{downsample_syl_3_meta_200_314_pkl_community.pdf}}
 \caption{Sample network community structure (Full), showing a small numbers of tightly connected bigger communities and some outlier small communities. Number shows index of individual time-series object.}
  \label{fig:networkComFull}

\end{figure}
%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.2]{comm1}}
 \caption{Sample network community structure (zoomed in).Number shows index of individual time-series object.}
  \label{fig:networkComZoom}

\end{figure}
%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{01community.pdf}}
 \caption{Sample network community structure with no outliers.Number shows index of individual time-series object.}
  \label{fig:01community}

\end{figure}
%%%%%%%%

\subsection{Outlier community filtering}
We propose an extra step of outlier community filtering before deriving our final contour shape classes. In this step, we use a heuristic threshold of $t=10$ to filter out any communities (clusters) with a size less than $t$. After we have derived the remaining classes for each tone N-gram category, we map the nodes in the network to the actual time-series data points (tone N-grams) and their metadata attributes and serialize a contour shape class \texttt{.csv} file for each tone N-gram category.

%some statistics of how many clusters and how many outliers and their sizes

\subsection{Evaluation of tone contour shape classes}
%discuss somewhere that using curves we can classify 90%, but that should be shown in network analysis stage.
Previously we have shown why it is unnecessary to perform extrinsic evaluation on the contour shape classes derived from this method. To make sure the result makes sense intrinsically, we perform two types of evaluations. First, we vary the value of threshold $T$ outside of the range we tested from the network filtering stage and observe the outcome community structure. This is to test the possibility that a smaller distance threshold might yield tighter clusters. However, we observe that when using smaller threshold, the community structure of the output classes becomes unstable - often producing a plethora of small communities. This shows our method produces sensible and centralized community structures. Second, we tested the upper bound of a potential classification task we are proposing next: how well can we classify the tone N-grams into different contour shape classes using syntactic, morphological, phonological and other features? Here we test the classes using the compliment feature of that task: how well can tone N-grams be classified into these shape classes using their time-series $f_0$ values? This is similar to a tone classification task except that the classes are contour shape classes. Since the contour shape classes are supposed to capture the different types of shapes in the tone data, we expect this intrinsic task to obtain high accuracy. Expectedly we are able to classify tone N-gram time-series points into these classes with around 90\% accuracy. This indicates an upper bound on how well these data can be predicted to belong to one of the shape classes.



\section{Machine learning of tone N-gram contour shapes}

Our goal in this chapter is to understand how features from various linguistic domains play a role in predicting the contour shape type (class) of a particular tone N-gram category in its realization in spontaneous speech, a key issue at the center of intonation and tone research. There has been a long line of research documenting the interaction between syntax/semantics and prosody, discourse and prosody, etc. in linguistic literature \cite{KLi09,buring2013}. In tone research, \cite{Wang2011DifferentialPE} showed how discourse domain features (and 'communicative functions') such as focus, topic, information structure affect the realization of tone contours. However, to the best of our knowledge, there is no previous work that uses machine learning to systematically investigate the interaction between linguistic features and prosodic realizations of tone N-grams from a large data set of spontaneous speech. 

We can also view this problem from an alternative angle - namely, an information theory perspective on prosody. Speakers produce a large amount of variability in their tone production. Similarly, they also face numerous choices in their use of linguistic forms in their speech, including morphological, referential, syntactic, and phonetic, to name a few. The information theory view of speech production postulates that these choices are not random. Rather, speakers choose to use specific linguistic forms in order to maximize the rate of information transmission \cite{Shannon:1963:MTC:1102016}. In the prosody domain, the evidence of this optimization process can be observed from the statistical correlations between the other attributes (prosodic or non-prosodic) and the tone/intonation contour shape profiles. In this experiment, we therefore take machine learning approaches to find these correlations.



\subsection{Feature engineering}
We aim at investigating a number of linguistic features from the domain of syntax, phonology, morphology, discourse, semantics, etc. In selecting specific features for this task, we are also constrained by the availability and reliability of the annotated corpora and natural language processing (NLP) technologies. The main CMN corpus we use has ground truth segmentations and annotations of tones and words (in both pinyin and Chinese character form). Given the maturity of open source Chinese language NLP tools to extract features in syntactic and discourse domain, we therefore are able to extract relatively reliable features in these domains. There are some features, such as topic and focus, that currently do not have reliable automatic methods for detection, and we therefore have to exclude them from this study (previous works have shown the effect of these features in controlled experiments of read speech, but not large scale spontaneous speech, which would also require significant resources to annotate). 

%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
\begin{table}
\small

\begin{center}
\begin{tabular}{ |c|c|c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Syntactic & Morphological & Discourse & Phonological & Others\\
 \hline
\hline
$POS\_Tag_{1...N}$ & $Tok\_Bound_{1...N}$ & is\_entity & $is\_nasal_{1...N}$ & sent\_position \\ 
$Dep\_Func_{1...N}$ & & is\_singleton & $is\_dipthong_{1...N}$ & start\_pitch \\
 & & & $is\_round_{1...N}$ & end\_pitch\\
 & & & $is\_front_{1...N}$ & prev\_tone\\
  & & & $is\_back_{1...N}$ & next\_tone\\
   & & & $is\_high_{1...N}$ & \\
    & & & $is\_low_{1...N}$ & \\

\hline
\end{tabular}
 \caption{Feature set overview. 1...N indicates this feature is computed for all syllables in the N-gram. Total number is N*10+7 features, 37 for trigrams and 27 for bigrams, etc.}
  \label{tab:trigramFeatures}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%


\subsubsection{Syntactic features}
We extract the POS (part-of-speech) tags for all syllables in a tone N-gram. In addition, we also extract the dependency function \cite{DBLP:conf/emnlp/ChenM14} of all syllables in the tone N-gram. Therefore there are $2*N$ syntactic features where N is the number of syllables included in the tone N-gram data under consideration. The original tag sets used in CoreNLP\footnote{As will be described next, coreNLP is the tool we use to extract features from text.} comes from Penn Chinese Treebank\footnote{See \url{http://repository.upenn.edu/cgi/viewcontent.cgi?article=1039&context=ircs_reports} .} and is too fine grained. To avoid data sparseness, we collapsed several categories. For both POS tags and dependency edge function categories, we compute its distribution using the original tagset and we aim to collapse any categories that appear less than 5 times (often into a 'others' category, but see below). For part of speech tags we mapped the original 33 tags onto 5 categories. For dependency functions, we collapsed all tags with a subcategory separated by a colon (e.g., 'advmod:loc', 'advmod:rcomp', mapped to 'advmod' etc.). Then, during classification we further preprocess the data by removing any values (factor levels) that appear less than 5 times, in order to avoid the 'zero variance' problem warned by the \texttt{caret} package of R.


\subsubsection{Discourse/semantic features}
We extract two discourse features for a tone N-gram data point: (1) whether the tone N-gram includes a Named Entity; (2) whether the tone N-gram includes a singleton (as opposed to being part of a coreference chain in the discourse).The discourse features such as information structure are postulated with associating with prosody domain\cite{buring2013}, in particular, given information may encode prosodic features different from new information. This could also apply to named entities vs. un-named entities. Named entities points to definite, specific objects in the real world; whether the token is a singleton or part of coreference chain can be correlated with information structure (i.e., a singleton may signify new information in discourse, while a non-singleton is part of a coreference chain with potential antecedent or anaphor, pointing to potentially a different information structure). Both can have distinguishing effects on the mental representations and production of speech prosody.


\subsubsection{Morphological features}
In Mandarin Chinese, each word usually consists of one or $m$ syllables (where each syllable is one Chinese character, the smallest semantic unit). The value of $m$ is usually two to four. Building on the intuition that the first syllable is usually spoken with higher prominence (e.g., neutral tone, which doesn't carry stress, only occurs on word-final positions), we extract morphological features for each syllable in the given tone N-gram: whether they cross word boundary or not. There are total of $N$ features in this category.


\subsubsection{Phonological features}
A basic representation of phonological features is the identity of phonemes in each syllable of the N-gram. However, due to the sparseness of this feature representation, we have designed 7 binary features to encode the phonological properties of the syllables in the tone N-gram: (1) whether the syllable includes a nasal; (2)  whether the syllable includes a dipthong; (3) whether the syllable includes a high vowel; (4)  whether the syllable includes a low vowel; (5)  whether the syllable includes a front vowel; (6)  whether the syllable includes a back vowel; (7)  whether the syllable includes a round vowel. In addition, we add two contextual tone features: the tone identity of the previous and following syllable to the tone N-gram in question.


\subsubsection{Other features}
We add two pitch features to the feature set: the beginning and ending pitch of the tone N-gram. This is based on the notion in previous works of Mandarin tone modeling (Parallel ENcoding and Target Approximation model, or PENTA) \cite{xu_lee_prom-on_liu_2015} that in speech production, the actual realized tone shape of a given tone category highly depends on the starting point of the pitch contour and its distance to the actual pitch target of the current tone, which affects its course of trajectory when it approximates the target \cite{Prom-on2009}. An additional feature to be included is the position of the current tone N-gram within the context of the current sentence as a percentage. It is a known effect that pitch tends to downdrift in speech production as sentence progresses\cite{Wang2011} and we also want to explore the effect of sentence position.


\subsection{Feature Extraction Methodology}

\subsubsection{Bag of features}
In this task, we note that the unit of feature extraction is not as straightforward as it would be in classic NLP tasks. That is, instead of a typical syntactic constituent (word, phrase, sentences) as the feature extraction unit, here our target is tone N-gram, a sequence of $N$ syllables that may or may not be a syntactic constituent. As described above, in many features we have adopted a "Bag of features" (similar to speech coreference resolution work in \cite{Roesiger2015}) approach where each feature describes whether the N-gram contains a certain target value in any position. In other features, we simply use a set of $N$ features applied to each syllable in the N-gram in question. 

\subsubsection{Feature extraction}
%stanford coreNLP
We use Stanford CoreNLP\cite{manning-EtAl:2014:P14-5} to extract syntactic, morphological and discourse domain features, a state-of-the-art open source NLP software for Chinese NLP. The CoreNLP suite provides several 'annotators' to be used in the current feature extraction, including the POS tagging, dependency parsing, named entity recognition (NER), and coreference resolution for Chinese\footnote{https://nlp.stanford.edu/projects/chinese-nlp.shtml}. Since coreference is only available in XML format, we configured coreNLP to output both CONLL\footnote{http://conll.cemantix.org/2011/} and XML formats and merge the coreference information as an additional column in the final CONLL output format. The complete text transcripts of the CMN corpus audio is processed in batch through the CoreNLP.

In previous steps we have described serializing the tone N-gram network object to contour shape class \texttt{csv} files, where each row is the downsampled time-series subsequence of a tone N-gram and its metadata attributes followed by its class assigned by the network community detection process. Each csv file contains data points corresponding to a particular tone N-gram, such as 1-3-4. In order to extract features from text domain, we implement a mapping from the csv files to .phons files and text file. Both these files are included in the CMN corpus. The .phons file contains a segmentation and phonetic transcription (using specifically defined symbols) of the audio at the segment level (onset and nuclear/coda) along with tone information marked. The text file is a tokenized version of the transcription of the audio newscast speech. We use .phons file to extract phonological features and text file to extract text domain features using CoreNLP.  Since .phons file is tokenized by phonetic segments and text file is tokenized based on an automatic Chinese text segmentation process, we also created a mapping between these two, as well as the mapping to sentence ID in the CONLL file. In the end, feature extraction takes place by leverage these mappings among several resources and the result is a training set for each tone N-gram with their class label appended.




\subsection{Predicting tone N-gram contour shape classes}
\subsubsection{Feature selection}

Our goal is to see how well we can predict the contour shape type that a tone N-gram will take on in spontaneous speech production, given linguistic features in syntax, morphology, phonology and other domains. On the other hand, we can also say that we aim to better understand how factors and information content from these other domains affect speech production of tones. From an information theoretical point of view: even though all languages use what Martinet called 'the double articulation' (sounds are classified into discrete phonemes, which are combined in arbitrary lexemes), information content is much more fine grained.

From a machine learning perspective, feature selection helps us see which features are the most effective in producing a better classification accuracy, and which features are redundant and contain noise that might hurt the performance of a classifier. From the other perspective, it enables us to better understand the importance of these linguistic features in contributing to the contour shape of tone N-grams. Feature selection is an active area of research in machine learning and data mining, with many dedicated packages across tools and programming languages such as \texttt{Caret\footnote{caret.r-forge.r-project.org}, randomForest\footnote{https://cran.r-project.org/web/packages/randomForest/randomForest.pdf}} in R, Weka, and \texttt{scikit learn} in Python. 

In the previous step we have generated feature files for each of the tone unigram, bigram and trigram category, giving rise to a total of $5 + 4^2 + 4^3 = 85$ data sets for the prediction task. To perform feature selection, we randomly selected five trigram data sets to carry out feature ablation experiments and feature importance ranking analysis in order to gain a deeper understanding of the set of features we are using. After this step, we use the subset of most effective features to run our classification algorithm on all data sets.

Concretely, we first perform feature ablation experiments by iteratively removing subsets of our features. For a trigram data set there are in total 37 features as indicated in \ref{tab:trigramFeatures}. 
We know from linguistic knowledge that these features are grouped into categories (syntactic, phonological, etc.), therefore it would make sense to select and remove feature subsets by category rather than testing features individually (which is what a feature selection algorithm that lacks domain knowledge would do, as in below). 

All feature ablation experiments are done using the Support Vector Machine (SVM), an effective algorithm for classifications.


\subsubsection{Feature selection results}



 
 

%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
\begin{table}
\small

\begin{center}
\begin{tabular}{ |c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Data & Condition & Accuracy(\%)\\
 \hline
\hline
1-3-4 & all & 57.82  \\
1-3-4 & no pos & 57.82 \\
1-3-4 & no pos/func & \textbf{61.88} \\
\hline
1-3-4 & *no entity/singleton & 61.59 \\
1-3-4 & *no entity & 61.01\\
1-3-4 & *no singleton & \textbf{62.32} \\
1-3-4 & *no tok bound & 60.86 \\
1-3-4 & *no phons & 60.00 \\
1-3-4 & *no sent pos & 62.17 \\ 
1-3-4 & *no prev/next tone & 60.14\\

\hline
\end{tabular}
 \caption{Feature ablation experimental results in data 1-3-4. Asterisk (*) indicates no pos and no pos/func also applied in that condition. }
  \label{tab:featureAblation134}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
\begin{table}
\small

\begin{center}
\begin{tabular}{ |c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Data & Condition & Accuracy(\%)\\
 \hline
\hline
3-1-4 & all & 52.09  \\
3-1-4 & no pos & 52.24 \\
3-1-4 & no pos/func & \textbf{57.31} \\
\hline
3-1-4 & *no entity/singleton & 57.74 \\
3-1-4 & *no entity & \textbf{58.32}\\
3-1-4 & *no singleton & 56.87 \\
3-1-4 & *no tok bound & 55.42 \\
3-1-4 & *no phons &  52.82\\
3-1-4 & *no sent pos & 55.57\\ 
3-1-4 & *no prev/next tone & 54.56\\

\hline
\end{tabular}
 \caption{Feature ablation experimental results in data 3-1-4. Asterisk (*) indicates no pos and no pos/func also applied in that condition. }
  \label{tab:featureAblation314}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
\begin{table}
\small

\begin{center}
\begin{tabular}{ |c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Data & Condition & Accuracy(\%)\\
 \hline
\hline
3-2-2 & all & 60.86  \\
3-2-2 & no pos & 60.11 \\
3-2-2 & no pos/func & \textbf{66.10} \\
\hline
3-2-2 & *no entity/singleton & 65.17 \\
3-2-2 & *no entity & 65.54\\
3-2-2 & *no singleton & 65.36 \\
3-2-2 & *no tok bound & 65.54 \\
3-2-2 & *no phons &  63.48\\
3-2-2 & *no sent pos & 64.04\\ 
3-2-2 & *no prev/next tone & 63.30\\

\hline
\end{tabular}
 \caption{Feature ablation experimental results in data 3-2-2. Asterisk (*) indicates no pos and no pos/func also applied in that condition. }
  \label{tab:featureAblation322}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
\begin{table}
\small

\begin{center}
\begin{tabular}{ |c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Data & Condition & Accuracy(\%)\\
 \hline
\hline
3-4-2 & all & 58.33  \\
3-4-2 & no pos & 58.17 \\
3-4-2 & no pos/func & \textbf{60.95} \\
\hline
3-4-2 & *no entity/singleton &  60.95 \\
3-4-2 & *no entity & 60.78\\
3-4-2 & *no singleton & \textbf{62.25} \\
3-4-2 & *no tok bound & 60.78 \\
3-4-2 & *no phons &  59.31\\
3-4-2 & *no sent pos & 61.11\\ 
3-4-2 & *no prev/next tone & 59.31\\

\hline
\end{tabular}
 \caption{Feature ablation experimental results in data 3-4-2. Asterisk (*) indicates no pos and no pos/func also applied in that condition. }
  \label{tab:featureAblation342}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
(1) \textbf{Feature ablations via SVM on randomly selected trigram datasets.} we present results on feature ablation experiments on the five trigram data sets in Tables \ref{tab:featureAblation134}, \ref{tab:featureAblation314},  \ref{tab:featureAblation322},  \ref{tab:featureAblation342}, \ref{tab:featureAblation421}.  From these experimental results we also summarize the feature strength in Table \ref{tab:good-bad-features}, where we group all features into three sets of weak, medium, and good features. First, we observe that the weakest features are syntactic features POS tags and dependency functions, as removing these features always results in a significant boost in classification accuracy. (This is true before and after we collapsed some categories to combat data sparseness problems.) Second, the medium features, including discourse features (entity and coreference - singleton) and sentence position are those that are in general having a mixed effect on classifier performance across different data sets - they could either boost or degrade performance in an insignificant way. In the result Tables, we have highlighted the result obtained by all features but the POS tag and dependency functions, as well as the best result obtained on any subset of the features. It is noteworthy that the former usually reaches near best or best results; otherwise the best results are often obtained by removing either the entity feature or the singleton feature (but not both).

Third, the 'Good' features are the most effective features, including phonological features (and tone context), token boundary features (morphological), and start and ending pitch of the contours. The phonological features are closely related to speech prosody production, even though it has not been investigated in this way before. Both morphological and start/ending pitch features have groundings in the intuition discussed above in the relation with tone production in spontaneous speech and is therefore expected to contribute positively to the prediction accuracy. Overall, we note that given the all classification results are significantly above chance (to see the number of classes in each data set, visit variable importance plot in the next chapter).



%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
\begin{table}
\small

\begin{center}
\begin{tabular}{ |c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline
Data & Condition & Accuracy(\%)\\
 \hline
\hline
4-2-1 & all & 58.94  \\
4-2-1 & no pos & 59.16 \\
4-2-1& no pos/func & \textbf{63.69} \\
\hline
4-2-1 & *no entity/singleton & 64.13 \\
4-2-1 & *no entity & \textbf{64.24}\\
4-2-1 & *no singleton & 64.02 \\
4-2-1 & *no tok bound & 63.02 \\
4-2-1 & *no phons &  62.03\\
4-2-1 & *no sent pos & 62.80\\ 
4-2-1 & *no prev/next tone & 62.58\\

\hline
\end{tabular}
 \caption{Feature ablation experimental results in data 4-2-1. Asterisk (*) indicates no pos and no pos/func also applied in that condition. }
  \label{tab:featureAblation421}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
\begin{table}
\small

\begin{center}
\begin{tabular}{ |c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline

Weak & Medium  & Good \\
 \hline
\hline
POS tag & sent position & phonological\\
dep func & is\_entity & start pitch \\
 & is\_singleton & end pitch \\
&  & tok\_bound\\
\hline
\end{tabular}
 \caption{Feature strength from ablation experiments }
  \label{tab:good-bad-features}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%



(2) \textbf{Support Vector Machine (SVM) linear kernel feature weight coefficients ranking on all unigram, bigram, and trigram datasets}. In SVM, a decision hyperplane can be defined by an intercept term $b$ and a decision hyperplane normal vector $\vec{w}$ which is perpendicular to the hyperplane. This vector is commonly referred to in the machine learning literature as the weight vector\cite{Manning:2008:IIR:1394399}. While the direction of the weight vector gives the predicted class (when taking a dot product with a input feature vector), \cite{Guyon2002} showed that in a linear SVM, the weight vector of a given classifier can be used as feature ranking coefficients, and those inputs with the largest weights correspond to the most informative features. 

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.75]{unigram_coef.pdf}}
 \caption{Feature weights for all unigram data sets}
  \label{fig:unigramcoef}

\end{figure}
%%%%%%%%

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.75]{unigram_coef_sel.pdf}}
 \caption{Feature weights for unigram data sets excluding starting pitch and ending pitch}
  \label{fig:unigramcoefsel}

\end{figure}
%%%%%%%%


Following  \cite{Guyon2002}, we therefore extracted weight vectors (coefficients) associated with all features in the SVM classification experiments (for the number of features in unigram, bigram, and trigrams, see Table \ref{tab:trigramFeatures}). We then visualize the feature weights for all data sets in each of the n-grams in order to have an estimate of the distribution of feature importance in all of our experiments. For each data set in a given n-gram, we trained a linear SVM classifier and obtained feature weight vectors for each of the output shape classes. We take the absolute values of feature weight vectors and normalize them to be comparable across data sets. We then aggregated feature weights for all output classes and then across all data sets in a given n-gram. 

For unigram data sets, Figure \ref{fig:unigramcoef} shows the distribution of feature weights (importance) for all features in boxplot. We note that the starting and ending pitch, as expected from previous experiments, are the most important features with weights in a much higher range than others. We therefore present an extra boxplot in order to show the ranking of other less important features in more detail in a more appropriate value range. This is shown in Figure \ref{fig:unigramcoefsel}. In addition, we give an overview of the distribution of number of output shape classes for unigram data sets (Figure \ref{fig:numclassuni}). We then present the same set of three plots for bigram (Figures \ref{fig:bigramcoef}, \ref{fig:bigramcoefsel},\ref{fig:numclassbi}) and trigram (Figures \ref{fig:trigramcoef}, \ref{fig:trigramcoefsel},\ref{fig:numclasstri}) data sets.

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{unigram_num_class.pdf}}
 \caption{Histogram of number of output shape classes in unigram datasets}
  \label{fig:numclassuni}

\end{figure}
%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.75]{bigram_coef.pdf}}
 \caption{Feature weights for all bigram data sets}
  \label{fig:bigramcoef}

\end{figure}
%%%%%%%%

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.75]{bigram_coef_sel.pdf}}
 \caption{Feature weights for bigram data sets excluding sentence position and ending pitch}
  \label{fig:bigramcoefsel}

\end{figure}
%%%%%%%%


Comparing to the previous ablation experiments, the result from the feature weights analysis gives us a more detailed and complete picture of feature importance. Overall, this set of result is largely consistent with the results obtained in the ablation experiments using a much smaller subset of data. First, we emphasize that this is an exhaustive result obtained by using all unigram, bigram, and trigram data sets available to us, whereas in the feature ablation experiments in the last chapter, we only utilized a subset of five trigram data sets. 

Second, in the ablation experiments, we removed feature in batch according to their linguistic domains, that is, for instance, for phonological features, we removed all phonological features as a group, and observed its impact on classifier performance. In that case, we are assuming (as a prior knowledge) that phonological features (or any other feature groups based on linguistic knowledge) worked as a whole, but there is no evidence that this is empirically so on the individual feature level (unless we try to remove individual features one by one). However, in the current experiments of feature weights, we see empirical evidence of feature behavior on the individual feature level that is consistent with linguistic domains. Concretely, we see that individual features that belong to a linguistic domain, such as phonological features, syntactic features, etc., do indeed exhibit group behavior. This is an unexpected byproduct of the machine learning model: the machine learning model itself, even though without knowledge of linguistic domains whatsoever, has naturally learned to assign similar weights to features that belong to the same linguistic domain. This provides empirical evidence of the behavior of feature groups based on linguistic knowledge, and it corroborates our analysis about feature importance based on linguistic domain grouping. 

Third, we observe that the feature (weight) importance distribution patterns are similar across unigram, bigram, and trigram data sets. More specifically, we observe consistently across different n-grams, that the top level important features include starting and ending pitch, and the position of a n-gram within the sentence (sent\_position). Next on the ranked list are phonological features and morphological token boundary features.  On the lower side of the ranked list are syntactic (pos tag, dependency functions) and contextual features (previous and next tone). Overall, this ranking is similar to the ranking produced by ablation experiments, with small inconsistencies (most obvious is the contextual features), possibly due to the change in the scale of the evaluation. Now we can be confident of the ranking of feature importance as listed in Table \ref{tab:good-bad-features} with only minor modifications. The final ranking is shown in Table \ref{tab:finalFeatImp}.




%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{bigram_num_class.pdf}}
 \caption{Histogram of number of output shape classes in bigram datasets}
  \label{fig:numclassbi}

\end{figure}
%%%%%%%%



%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.75]{trigram_coef.pdf}}
 \caption{Feature weights for all trigram data sets}
  \label{fig:trigramcoef}

\end{figure}
%%%%%%%%

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.75]{trigram_coef_sel.pdf}}
 \caption{Feature weights for trigram data sets excluding starting pitch and ending pitch}
  \label{fig:trigramcoefsel}

\end{figure}
%%%%%%%%

%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{trigram_num_class.pdf}}
 \caption{Histogram of number of output shape classes in trigram datasets}
  \label{fig:numclasstri}

\end{figure}
%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
\begin{table}
\small

\begin{center}
\begin{tabular}{ |c|c|c| } 

 \hline

Weak & Medium  & Strong \\
 \hline
\hline
POS tag & phonological & sent position\\
dep func & is\_entity & start pitch \\
 context & is\_singleton & end pitch \\
&  tok\_bound & \\
\hline
\end{tabular}
 \caption{Feature strength from feature weight analysis using all unigram, bigram and trigram data (un ordered within each column)}
  \label{tab:finalFeatImp}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%

\subsection{Evaluation}
\subsubsection{Experimental setup}
We carry out classification experiments on all tone unigrams, bigrams and trigram datasets \footnote{Excluding N-gram data sets that yielded very small data (i.e., less than 10 data points). These are low likelihood events in tone N-grams such as consecutive sequences of tone 0 or tone 3.}. We use SVM RBF kernel in our experiments with the feature set described in the last chapter. We evaluate the classifier performance directly on accuracy. As described above, even though each data set has a different number of classes, they are in general balanced in their sizes (a result naturally given by the network outlier filtering stage). Therefore accuracy is a sufficient metric of evaluation.

\subsubsection{Results}
We present the classification accuracies on all unigram (Figure \ref{fig:acc-unigram}), bigram (Figure \ref{fig:acc-bigram}) and trigram (Figure \ref{fig:acc-trigram}) data sets. In these plots, 'accuracies' (as in the legend) are computed with all strong and medium ranked features as described in Table \ref{tab:finalFeatImp}. As discussed previously, this usually brings accuracy scores close to the maximum but at times excluding entity or singleton features might give a slight gain in classifier performance. This is indeed what we see across all data sets, which supports our characterization of feature importance in the previous chapters. In the same plots we also give the random baseline (chance) that is computed by $1/num\_classes$ in that data set. We note that in all data sets, regardless of unigram, bigram or trigram, we obtain significantly better results than this baseline. This strongly supports the hypothesis that a variety of syntactic, morphological, phonological and contextual features are able to predict the realization of a particular category of tone N-grams in spontaneous speech production.


%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{accuracy-unigram.pdf}}
 \caption{Unigram data sets classification accuracy}
  \label{fig:acc-unigram}

\end{figure}
%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{accuracy_bigram.pdf}}
 \caption{Bigram data sets classification accuracy}
  \label{fig:acc-bigram}

\end{figure}
%%%%%%%%
%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.5]{accuracy_trigram.pdf}}
 \caption{Trigram data sets classification accuracy}
  \label{fig:acc-trigram}

\end{figure}
%%%%%%%%


%comparing bigram and trigram results
It is worth pointing out that the performances between unigram, trigram and bigram classifiers could not be directly compared unless we normalize by the number of classes in each data set. For instance, comparing to trigram data, there are less number of bigram combinations (thus data sets) but each data set is of a larger size than trigram. Therefore we typically see lower baseline values in bigrams than trigrams from the two accuracy plots. The same trend goes for bigram and unigram. Nevertheless, we observe from Table \ref{tab:bi-tri} that while bigram has a much lower baseline than trigram, the mean accuracy of the two data sets are actually comparable (if you take only two decimal points they are the same). This means that the predicting power of the classifier is stronger in bigram data sets than trigram, as suggested in the far right column (bigram classification accuracy is on average 3.8 times the baseline while trigram is 2.9). Similarly, the unigram has the strongest predicting powers given its lower baseline and highest classification accuracy.This may suggest that the longer the window of N-grams, the stronger an effect of other factors come into play (longer range prosodic events).

%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%
\begin{table}
\small

\begin{center}
\begin{tabular}{ |c|c|c|c| } 

 \hline
%Datasets & bi200 & bi100 & tri300 & tri200 & merged\_train\\
%\hline

data sets & mean accuracy & mean baseline & ratio \\
 \hline
\hline


trigram & 0.641 & 0.222 & 2.9\\
bigram & 0.637 & 0.172 & 3.8\\
unigram & 0.724 & 0.140 & 5.17\\

\hline
\end{tabular}
 \caption{Comparison of unigram, bigram and trigram classifier performance}
  \label{tab:bi-tri}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%table%%%%%%%%%%%



\subsubsection{Discussion} \label{sec:discussionML}

We have shown that features from syntactic, morphological, phonological and other domains can successfully predict the contour shape class a tone N-gram will take, without supplying any information about the contour $f_0$ trajectory in the feature set (i.e., as in $f_0$ based tone recognition). Furthermore, there are many prosodic and discourse phenomena we haven't taken into account due lack of annotated data, including focus, topic \cite{Wang2011}, information structure, etc. These factors have shown in previous work to correlate with the realization of $f_0$ contour shapes in tone production. Considering these factors, the current evidence points to strong contribution of non-prosodic predictors to the realization of prosodic events. Meanwhile, we've shown a negative correlation between N (as in N-gram) and the prediction power, suggesting stronger unaccounted factors at play when N increases. 

We may view this from an information theory point of view of speech production. As an example, two different sequences of three phonemes in a tone trigram technically convey the same number of bits (modulo phonotactic constraints, etc.). However, even if one takes two different CVC syllables with a phonologically valid shape in language L and similar phoneme frequencies, they never have the same information content. Some words are more likely than others, and if this is combined with contextual constraints (previous words, syntax, information structure, intonation...), suddenly a good amount of informational inequalities hold. This puts pressure on speakers optimizing phonation length, tenseness, stress, etc. as a function of predictability to adjust their pronunciation based on factors from all linguistic levels. If we accept this premise, then the opposite should apply too: if we have annotations corresponding to these constraints, they should have predictive power for the properties of the phonation.\footnote{Personal communication with Prof Amir Zeldes for the discussion on this point.}

%An interesting open questions is how much of this is just information theory, and how much is speakers' idiosyncratic/grammatical encoding independent of information theory. In information structure studies, this is the tension between processing-based explanations of IS phenomena, and grammatical ones.

Even though the methods and experiments we proposed here are novel in their own rights, in fact, this idea of information theoretic view of speech production has long existed in the previous works that studied the computational modeling of speech production and perception \cite{Jurafsky2002,Hu2015,Levy2007,Levy2008,Qian2012,Bell2009}. More formally, Shannon's information theory \cite{Shannon:1963:MTC:1102016} characterized an efficient communication system as one under which the rate of information transmission is maximized (i.e., information transmission per unit time is maximized). In the case of language communication, maximal efficiency can be achieved when the transmission rate of linguistic signals is relatively uniform and close to the channel capacity. Based on the Shannon's noisy channel theorem \cite{Shannon:1963:MTC:1102016} (as stated above),  recent works showed that an ideal code should keep the average amount of information conveyed per word constant across discourses \cite{Qian2012}. One simple example is Zipf's observation that more frequent words tend to have fewer syllables, in which case the entropy per letter (or per phoneme for speech) across words in the mental lexicon could be relatively constant, matching the pattern predicted by the noisy channel theorem. 

A number of studies in recent years have tested to what extent language and language use exhibit properties that are predicted by this theorem (see \cite{Qian2012} for an overview). For instance, \cite{Hu2015} discussed the effect of information structure on speech and discourse production with respect to referential form, morphology, syntax (word order), and prosody (intonation). The central idea is that, given numerous ways meaning can be mapped onto linguistic forms, speakers adjust the various aspects of linguistic forms in speech and discourse production based on the information structure. In the prosody domain, for example, speakers modulate prosody based on the information status of their words, using acoustic reduction (i.e. shorter, unaccented, and less intelligible pronunciations) for previously-mentioned words or entities. Similarly, listeners are faster to interpret references to given information if the word is unaccented \cite{Hu2015}. 

\cite{Aylett2004} extended the theory of constant information content across words (described above) to the speech domain. The central premise is that in speech production, the most efficient way of ensuring robust information transmission in noisy environments is to have smooth signal redundancy\footnote{Here redundancy is used to mean predictability. More redundant words are more predictable. } (which can be thought of in terms of a smooth distribution of the probability of recognition) throughout an utterance. They propose that an inverse relationship between syllable duration and predictability arising from lexical, syntactic, semantic and pragmatic factors (what we term language redundancy) is to be expected, since it provides an efficient way of ensuring that elements with low levels of language redundancy are produced for a longer period of time and perhaps with more salient acoustic characteristics, and will thus be likely to be recognized. 

In this context, the current work on predicting tone contour shapes has meaningful implications for information theory based accounts of speech and discourse production. It can be considered as providing another facet of evidence in support of such accounts. Previous works targeting information theory and information structure in prosody domain have largely looked at acoustic correlates directly, such as accent and duration, all of which may in turn have an impact on the shape of tone contours in speech production. Therefore looking at tone contour shapes can be thought of as a different level of manifestation of such phenomena, an amalgamation of single dimensioned acoustic correlates such as duration and intensity. It is also a level that is most difficult to quantify and measure in the traditional linguistic/phonetic investigations. 

Overall, we can outline three main contributions of the current investigation in the context of information theory accounts of speech production. First, the strong predicting power of our machine learning models provides good evidence for the information theory accounts of speech prosody (tone and intonation) production as discussed above. This evidence is striking considering that the information theory account, probabilistically linking prosody production to other linguistic domains, is a built-in (implicit) prior assumption of our experiments when we set up our model with feature engineering.  Second, we used network analysis and machine learning from the SPM toolkit to enable our analysis, i.e., these computational modeling methods have made it possible for us to quantify speech prosody tone/intonation contour shapes in an effective and meaningful way. Third, we leverage the power of big data in speech prosody so that large-scale statistical patterns emerge.

One possible future direction of research is to build models to test specific predictions of information theory account of speech production. In that case, we will need to build formal models and experiments to test specific ways information content inequalities impact dimensions of speech prosody production and its direction of impact. In doing so, we combine methods from the SPM toolkit with computational psycholinguistic approaches seen in previous work to leverage the power of bigger data in computational modeling of cognitive processes of linguistic production and comprehension.







\newpage
\part{Applications}
\newpage
\chapter{Applications}

\section{Computing speech prosody time-series similarity for other tone languages}
Throughout the thesis we have developed various methods and tasks aimed at the understanding and analysis of Mandarin tones. However, as we have discussed since the beginning chapters, these analytical methods are also generic and extensible in their application to other tone languages and other speech prosody phenomena/tasks that are of interest. 

In this chapter we extend our methodology on using symbolic representation to perform unsupervised learning of tones to other tone languages. Specifically, we will carry out experiments on Thai tones. 


\subsection{Data Collection}
The Thai tone system is slightly more complex than Mandarin. Thai has 5 lexical tones, Falling (F), Rising (R), High (H), Mid (M) and Low (L). The first two are contour tones, as they show distinct directional changes in their pitch trajectory; the Falling tone shows a rise followed by a fall, while the Rising shows a fall and then a rise. Though the other three are traditionally called level tones, we note that these tones are not characterized best by 'flat' pitch values, but actually have trajectories of their own, though less extreme in inflection than the contour tones\cite{Ramadoss2009}. Figure \ref{fig:thai} illustrates the pitch trajectories of Thai tones. The data collection used in this experiment is described in Section \ref{sec:manthaidata}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.4]{thai-tones.png}}
 \caption{Mean and std error of mean pitches in Thai from \cite{Ramadoss2009}}
  \label{fig:thai}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%








\subsection{Experimental Setup}
The Thai tone data set is preprocessed in a number of pitch preprocessing steps as described in Chapter \ref{sec:speech-proc}: pitch estimation; pitch normalization and log (Bark scale) transformation; finally, pitch downsampling into 30 point pitch vectors for each syllable tone contour. We use the 1-5 numeric scale to denote the five tone categories as ground truth labels.

We adopt the same Query By Content (QBC) experimental setup as discussed in Chapter \ref{sec:qbc}. In this setup, each time we randomly sample a group of $k$ queries and for each query $q$, we retrieve $r$ ranked tones according to their similarity (depending on the specific similarity measure used) to the queries. Among these $r$ tones we compute their Mean average precision (MAP) score on the top $n$ results, where $n$ is the number of total relevant tones belonging to the same tone category as $q$. Finally we average MAP scores for all $k$ queries $q_1,...,q_k$ and we return the final average MAP score for this iteration.


\subsection{Results}

Table \ref{tab:qbc-thai} shows the results for the different values of $k$ and $r$ at optimal SAX parameters $w=18,a=8$. Comparing this table with the Mandarin results in Chapter \ref{sec:qbc-results}, we see that the result is in general a bit lower due to the larger number of tone categories in Thai, which increases the chance of making a mistake in QBC. Moreover, we have noted above that the quality of this data set (as well as it being child-directed speech) also contributes to lowering the MAP score for QBC. Nonetheless we see that the results are reasonable comparing to the Mandarin and comparing to chance level. In particular, at $k=20, r=100$, we found that SAX consistently outperforms Euclidean distance on $f_0$ numeric representation. At $k=50, r=200$, a larger data set, we see more mixed results with SAX outperforming Euclidean distance on average (with comparable but slightly larger standard deviation on the average MAP score results). Overall, this result is consistent with results obtained from Mandarin: given optimal parameter settings, SAX achieves better MAP scores in the QBC task possibly due to its dimensionality and noise reduction mechanisms. As expected, there should be no reason that this doesn't generalize to another tone language such as Thai. It remains to be seen if SAX's advantage generalizes to other types of prosody tasks where similarity computation between speech prosody time-series is crucial.

%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}
\small
 \begin{center}
 \begin{tabular}{|c||c|c|}
\hline
evaluation/iteration &  EUCLIDEAN & SAX-MINDIST\\
\hline
MAP($k=20,r=100$) & 0.306 & 0.349\\

 & 0.317 & 0.364\\

& 0.258 & 0.265\\

& 0.311 & 0.315\\

& 0.284 & 0.354\\
\hline
mean & 0.295 & \textbf{0.329}\\

std & 0.021 & 0.03\\
\hline
\hline
MAP($k=50,r=200$)
 & 0.329 & 0.345\\

 & 0.301 & 0.268\\

 & 0.274 & 0.279\\
 & 0.281 & 0.298\\

 & 0.285 & 0.295\\
\hline
mean & 0.294 & \textbf{0.297}\\

std & 0.02 & 0.026\\


  \hline
  
  
 \end{tabular}

\caption{QBC results MAP scores, data: Thai data set, $k$=query size, $r$=retrieved size} \label{tab:qbc-thai}
\end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%










\section{Speech Prosody Query and Retrieval (SPQR) Tool}
A direct application of SPM is a Speech Prosody Query and Retrieval (SPQR) tool that can assist phonologists, phoneticians, and speech prosody time-series miners and researchers in their daily research tasks (that might be done manually otherwise). The basic functionality of this tool is for the user to query a speech prosody corpus using a seed pattern (to be defined using a meaningful prosodic unit, such as a syllabic tone, tone n-gram, an intonation phrase) and retrieve the top k similar patterns in the corpus. The seed pattern can be selected using examples  extracted from the corpus, or using a user-supplied pattern (numeric, symbolic data points, or audio files). The researcher can further assess the meaningfulness of the patterns discovered by means of intrinsic (i.e., within the
phonology/phonetics domain) or extrinsic evaluation (i.e., combined with annotations in other domains
such as syntax, semantics, and information structure in discourse). Extended functionalities of the SPQR tool will showcase the motif discovery and network community detection/machine learning of speech prosody time-series data. The application can be implemented with a GUI web interface and use pre-computed time-series similarity
indexes for faster retrieval.

Here we show a demo application of SPQR with its basic Q(uery) and R(etrieval) functionalities implemented as a web application running on a server. The user can access this application via a web browser and interact with the unigram tone time-series data set in the CMN corpus (or any corpus that is imported by the user/administrator). Currently the goal of the application is for users to be able to perform a query on a corpus of tones using a set of seed patterns (which can be a set of tones) and see the top K retrieved items that are similar to the query. Crucially, the user is able to select different parameters, including time-series representation ($f_0$, SAX, qTA, Bark, D1), distance measure (Euclidean, DTW, MIN-DIST), SAX parameters, and specify the number of query tones and retrieved tones. In this way, the user is able explore and interact with the speech prosody database with the ease of experimenting with different time-series retrieval methods, which may lead to further steps in their investigation after inspecting the results. The application enables researchers to do this efficiently without having to implement relevant algorithms from scratch. Meanwhile, it can provide an efficient speech prosody research tool for non-technical oriented users.



%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

\centerline{
 \includegraphics[scale=0.6]{spqr-config.png}}
 \caption{SPQR web tool configuration page screenshot}
  \label{fig:spqr-config}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%% F I G U R E %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\small

 \centerline{
 \includegraphics[scale=0.6]{spqr-results.png}}
 \caption{SPQR web tool QBC results page  (partial)  screenshot}
  \label{fig:spqr-results}

\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The SPQR application is implemented as a Python-CGI based web application running on a server, using SQLite as a local database and the GitHub platform itself for versioned XML file storage. We follow the static form-submit architecture, in which no running services are used: Python scripts are exposed via a Web server (e.g., Apache), and calling them from a browser accesses the DB to serialize HTML for the client. This means that no service needs to constantly run and 'listen' for an event while the application is being used, thereby minimizing server workload. Utilizing this framework, we are able to re-use the Python code base from earlier chapters in this thesis where we implemented algorithms for time-series representation and similarity computation (as well as QBC). 


Figure \ref{fig:spqr-config} shows the example configuration interface of the SPQR web tool. Using this interface, the user is able to configure the parameters of the query algorithm such as time-series representation and distance measure. Currently we are implementing more features to allow greater configurability for the users, such as the ability to import new corpora, query using audio files and user supplied pitch files, and other parameters related to the query and retrieval algorithm. 

Once the user selects appropriate configurations of query parameters, at the click of "QBC" button, the application will randomly sample $k$ tone time-series objects from the data base and perform the Query by Content task in the backend. This set up is identical to the QBC experiments we carried out throughout the thesis. After the computation is finished, the result is displayed. Figure \ref{fig:spqr-results} shows an example results of the QBC on a random set of 50 queries. On the top of the page we display the results of the current QBC experiment (i.e., results from retrieving tones using the query), including the configuration parameters of the experiment, random seed used, the average MAP score (of the 50 runs), etc. On the bottom half we show interactive features of the query and retrieval results: First we display the query time series\footnote{There are 50 queries in this experiment and here we show a random selected one.}, and then we show the top $K$ ($K=10$ in this case) results \footnote{Due to the visibility issues when producing this thesis, we only showed two out of the ten top results in the screenshot since showing all ten would make the text be ilegible.} from the retrieved set of tones. These visualizations give users an intuitive understanding of the retrieved results under the current parameter settings, and it also provides information such as the tone label of each query and retrieved result, distance of the result from the query, etc. Moreover, the user is able to click on the 'audio' hyperlink next to each visualization of the results, thereby listening to the tone time-series in question. This amalgamation of top query results from audio, visual, meta (tone label), and mathematical (distance) perspectives pools together relevant information from various sources, which facilitates a thorough understanding and analysis of the top similar items to the query in the database under the current experimental parameters and points possibly worth further investigation. 

As discussed above, the SQPR tool will continue to evolve by adapting to different speech prosody research tasks and by including a number of more advanced tools such as motif discovery and network analysis/machine learning. All subsequent development also depends on further use cases in speech prosody domain with input from and collaborations with speech prosody and phonetics researchers.


\section{A general framework for speech prosody mining (SPM)}
\subsection{SPM: Goals}
We have outlined the goal of Speech Prosody Mining (SPM) in the beginning of this thesis: "... to discover novel and robust knowledges by developing new methods to address the challenges posed by mining this [speech prosody] data. ... this approach harnesses the power in the big data in speech prosody and contribute a set of novel technologies for researchers in speech technology, speech prosody, and linguistics". 

Throughout this thesis, we have employed a variety of techniques and knowledge sources from linguistic domain knowledge, machine learning, time-series mining, speech prosody modeling, network analysis, etc., to address various tasks and challenges in the understanding and analysis of linguistic tone patterns (chiefly in Mandarin) from a large data collection. However, we are yet to speculate on why do we want to data mining speech prosody big data, and how (in what manner) do we achieve the goal of better understanding and analysis of prosody phenomena. Concretely,  we ask: what can data mining tell us about prosody, that traditional manual analysis of small data sets cannot? In this chapter, by linking perspectives from phonetics and phonological theory, we use one of the examples developed in this thesis to put this in perspective.

Here I quote a passage from a paper entitled "Speech melody as articulatorily implemented communicative function" \cite{Xu2005}, discussing the two different theories on phonological encoding and phonetic implementation: 

\begin{quote}
... In many experimental approaches, a different division is often assumed, namely, there is a direct link between communicative functions and surface acoustic forms. Thus the quest is typically to find the acoustic correlates of certain communicative functions, such as focus, stress, newness, questions, etc. (e.g., Cooper et al., 1985; Cooper and Sorenson, 1981; Fry, 1958). Such approaches have met criticisms from phonologists, who argue that prosodic meanings are not directly mapped onto acoustic correlates (Ladd, 1996; Liberman and Pierrehumbert, 1984). Instead, as they argued, intonational meanings should be first mapped onto phonological structures, which should in turn be linked to surface acoustic forms through phonetic implementation rules ... these two general approaches are both only partially right ...

\end{quote}

Given this paradox, this paper argues that communicative functions are indeed encoded in phonological structures and thus their sum cannot be directly observed in surface $f_0$ forms. That is, we cannot directly predict the exact realization of the $f_0$ contours given a set of underlying parameters in various linguistic domains. 

In the mean time, in this thesis, we have shown that using techniques from network analysis and machine learning, we can predict the contour shape classes of a prosodic category (such as a tone N-gram) using features from syntactic, morphological, discourse, phonological, etc., domains, even though we are not predicting its exact shape\footnote{To be exact, we are not directly talking about encoding communicative functions in their sense - nonetheless, the idea is similar, that is, to observe $f_0$ correlates of other linguistic functions.}. In doing so, we are finding a new middle ground between the two stances outlined above by being able to predict fuzzy classes of surface acoustic forms while in harmony with the phonological mapping theory. This is possible precisely because of the power of big data: if we have a large enough amount of observations of the surface $f_0$ realizations of a particular prosodic category, then we can leverage our SPM toolkit and analyze the relationships between those observations in order to derive plausible (however coarse and fuzzy) categories - namely, pattern discovery via network analysis and machine learning. The rationale behind this approach lies deep in the theory of inferential statistics such as the Central Limit Theorem: when our sample size is sufficiently large (while not approaching infinity in practice), we can approach the ground truth hidden in phonological encodings via surface realizations. Even though such phonological theories are not the main goal of this thesis, we use this point to illustrate the rationale and goal of SPM: with bigger data, we have greater ability and power to infer about the observations on many problems, and SPM algorithms allow us to efficiently and meaningfully leverage that power. As a result, SPM has the potential to contribute to research in a variety of related domains including phonetics, phonology, phonology-syntax/semantics interface, speech prosody, as well as computational modeling of psycholinguistic processes (in chapter \ref{sec:discussionML}, we showed how SPM toolkit can be leveraged to shed light on information theory based account of speech production). In the next chapter, we sketch a generalization of SPM framework by outlining a series of methodologies and research topics, and we discuss the potential future directions for research and application.

\subsection{SPM: Methods and Tasks}
In this chapter we outline a number of important SPM methods and tasks based on the results of this thesis.

\subsubsection{Similarity computation for speech prosody time-series}
We have shown in Part III that using time-series data mining techniques, we can improve similarity computation for the speech prosody domain. This includes representations from both speech prosody modeling and time-series mining communities:
\begin{enumerate}
\item{Time-series representation}
    \begin{enumerate}
    \item{Parametric model representations}
    \item {Non-parametric representations}
    \item{Time-series representations (real-valued)}
    \item{Time-series symbolic representations}
    \end{enumerate}
\item{Distance measure}
    \begin{enumerate}
    \item{Euclidean distance}
    \item {Dynamic Time Warping}
    \item{MIN-DIST(SAX)}
     \end{enumerate}
\item{Evaluation}
    \begin{enumerate}
    \item{Classification}
    \item {Clustering}
    \item{Query by Content (QBC)}
    \item{Mean Average Precision(IR)}
     \end{enumerate}
\end{enumerate}

The best similarity computation methods can be evaluated on a variety of data mining tasks such as classification, clustering, and query by content (QBC).


\subsubsection{Pattern discovery and category mapping}
We move to a higher level and analyze the relationships between time-series objects in the speech prosody database. In general, this includes two directions: 

\begin{enumerate}
\item{From contour shapes to categories: how can we discover similar contour shape patterns from the database and then go from the pattern clusters to analyze the categorical compositions of these clusters?}
\item{From categories to contour shapes: given a particular prosodic category, can we index/group its surface observations into contour shape classes? How can we predict if a category we take on which shape class?}
\end{enumerate}
%The problem of searching for the previously unknown patterns, known as motif discovery, is a highly costly operation and thus we improve upon existing motif discovery algorithms such as the MK algorithm by learning to re-rank the retrieved motif clusters to correct for the complexity bias in the speech prosody domain. In the 

In a general framework for SPM, we propose a three-step evaluation plan for analyzing and exploring the discovered patterns/classes/clusters, etc. Here is the process:

\begin{enumerate}
\item{Evaluation: How effective and efficient is the pattern discovery algorithm in speech prosody domain?}

\item{Analysis: analyze and characterize the patterns and their statistical properties beyond the evaluation step. This includes methods such as descriptive/inferential statistics, graph/network analysis, detection of communities, etc.}
\item{Assessment: Use pattern discovery to derive knowledge and guide research, whether previously known phenomena or new, e.g., use machine learning to map from various linguistic domains to the prosodic domain interface, etc.}


\end{enumerate}


\subsubsection{Correlations: linguistic domain interface}
One of the most interesting aspect of SPM is finding correlations not only between processes within the prosodic domain and the sound (phonology/phonetics) domain, but also outside of the sound domain into syntactic, semantic, discourse, etc. This was illustrated in the Assessment stage of the previous chapter. In the current thesis we demonstrated how we can predict the contour shape classes of tone N-grams by interfacing other linguistic domains and combining several stages of pipelines using network analysis and machine learning. In that regard, as we've discussed in Chapter \ref{sec:discussionML}, a potential area that SPM can contribute to is computational modeling of psycholinguistic processes. 

\subsubsection{Time-series data mining tasks}
We outlined several classic time-series mining tasks in chapter \ref{sec:tsmining-overview}. Classification, clustering and query by content are the most relevant to SPM. Another classic time-series data mining task is motif discovery in the speech prosody time-series database. In the network analysis module, we also demonstrated the use of anomaly detection/outlier pruning tasks. These tasks are not only useful in their own right in solving speech prosody related problems, they are also useful in evaluating various methods, such as distance measure and time-series representations.



\subsubsection{Assisting linguistic/prosody research}
Current investigations on the phonology of intonation
and tones (or pitch accent) typically employ
data-driven approaches by building research
on top of manual annotations of a large amount
of speech prosody data (for example, \cite{MorenZsiga2006,ZsigaZec2013} and many others).
Meanwhile, researchers are also limited by
the amount of resources invested in such expensive
endeavor of manual annotations. Given this paradox,
we believe that this type of data driven approach
in phonology-phonetics interface can benefit
from tools that can efficiently index, query, classify,
cluster, summarize, and discover meaningful
prosodic patterns from a large speech prosody corpus. Previously we have demonstrated the potential use of SPQR (query and retrieval) in the process of investigating a large prosody database, which may be followed by further steps of automated or manual analysis. The utility of pattern discovery is highly task dependent and is therefore subject to the researchers' goals and toolkits in developing task-specific methods, such as demonstrated in the Part IV of this thesis.


\section{Future directions}
The current work proposes a variety of tasks and technical solutions in SPM within a particular focus on Mandarin tones. While we have demonstrated the utility of SPM framework to extract meaningful patterns from the speech prosody data, there are many research questions and tasks that remain for future works. We propose several lines of future works that are outside of the scope of the current work. 

\begin{enumerate}

\item {\textbf{SPM with other speech prosody tasks.} In the current work we exclusively focus on Mandarin tones (with a small generalization to Thai tones). Meanwhile, there are many speech prosody tasks with a different nature than tone tasks that merit their specific investigations. Pitch movement analysis is only one dimension of speech prosody. We envision extending our SPM toolbox to other dimensions of prosody, such as rhythm and accent. Even within tone and intonation, each problem merits its own consideration in terms of methodologies for computational analysis, depending on the nature of the problem. The tone contour shape prediction problem, for instance, has a completely different structure and set of methods from the motif discovery problem. Therefore, we will continue to add to the SPM toolbox through further exploration of a diverse range of prosody domain problems. }

\item {\textbf{Other predictors of tone shapes.} Despite our success in predicting tone contour shape classes, we haven't completely accounted for the variability of tones in spontaneous speech. Concretely, communicative functions such as topic and focus have been shown to contribute greatly to tone shapes. However, due to the lack of high-precision method to detect such phenomena automatically, the study of these predictors will rely on manually annotated corpora, which is costly. Therefore we can also investigate how SPM can contribute to the development of such methods. }

\item {\textbf{Computational modeling of psycho-linguistic processes in speech production.} Previously we have shown how our experiments on predicting tone contour class shapes uncovered a new middle ground for the phonology and phonetic (acoustic) encoded model of tone production. We also showed its implications for the information theory based views of speech production. These successes demonstrates how computational methods can improve our understanding of mental processes of speech and language. In the mean time, these are not the main goals of the current thesis, and we are yet to build models to describe specific mechanisms of speaker's optimization of information transmission in tone and intonation production in detail.} 

\item {\textbf{Improving tone recognition.} While the primary goal of this thesis is the analysis and understanding of tone time-series data, the current work does not directly address the task of improving tone recognition algorithms (supervised learning) by using knowledge derived from data mining. This transfer will likely worthy of a separate line of effort independent of the current work (but will inevitably also build on this work).}

\item {\textbf{Extending to other languages.} Can SPM be used to investigate other tone or tone-like phenomena in other languages? What about intonations and pitch-accents? What can we learn from mining different tone languages and non-tone languages, with regard to the computational methods and linguistic theory? These are examples of how SPM can help answering cross-language and typological questions in linguistic research.}

\item{\textbf{Collaboration and interfacing targeting domain-motivated research questions.} SPM is ultimately targeted at advancing the understanding, analysis, and state-of-the-art technologies related to speech prosody. This may include linguistics interfaces, phonology, phonetics, speech prosody modeling, synthesis, prosody recognition, to name a few. Therefore, the true utility of SPM will only reveal itself through applying various computational techniques in SPM to real-world research tasks and projects in these domains and collaborations with colleagues from different disciplines. These problems are traditionally or otherwise done through manual analysis on a smaller data set, but can benefit from computational analysis on a larger corpus. Only in that case we are in a position to develop techniques and evaluate SPM with a deeper understanding of its ever evolving goals, methods, and utilities. Most importantly, linguistic domain knowledge and statistical-based tools to leverage big data will compliment each other to shed light on old and new challenges in speech prosody research. }

\end{enumerate}














\newpage









\bibliographystyle{alpha} 
\bibliography{shuo}


\end{document}

